
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="spotoptim - Sequential Parameter Optimization Toolbox in Python">
      
      
      
        <link rel="canonical" href="https://github.com/sequential-parameter-optimization/spotoptim/reference/spotoptim/SpotOptim/">
      
      
        <link rel="prev" href="../../..">
      
      
        <link rel="next" href="../data/diabetes/">
      
      
        
      
      
      <link rel="icon" href="../../../images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.0">
    
    
      
        <title>SpotOptim - spotoptim</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.618322db.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CFira+Code:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Fira Code"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="grey" data-md-color-accent="orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#spotoptim.SpotOptim" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="spotoptim" class="md-header__button md-logo" aria-label="spotoptim" data-md-component="logo">
      
  <img src="../../../images/spotlogo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            spotoptim
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              SpotOptim
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="grey" data-md-color-accent="orange"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="blue-grey" data-md-color-accent="orange"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/sequential-parameter-optimization/spotoptim/tree/main" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="spotoptim" class="md-nav__button md-logo" aria-label="spotoptim" data-md-component="logo">
      
  <img src="../../../images/spotlogo.png" alt="logo">

    </a>
    spotoptim
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/sequential-parameter-optimization/spotoptim/tree/main" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
    
    
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Code Reference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Code Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" checked>
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    spotoptim
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    spotoptim
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    SpotOptim
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    SpotOptim
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim" class="md-nav__link">
    <span class="md-ellipsis">
      
        SpotOptim
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim" class="md-nav__link">
    <span class="md-ellipsis">
      
        SpotOptim
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SpotOptim">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.load_experiment" class="md-nav__link">
    <span class="md-ellipsis">
      
        load_experiment
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.load_result" class="md-nav__link">
    <span class="md-ellipsis">
      
        load_result
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.optimize" class="md-nav__link">
    <span class="md-ellipsis">
      
        optimize
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.plot_surrogate" class="md-nav__link">
    <span class="md-ellipsis">
      
        plot_surrogate
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.save_experiment" class="md-nav__link">
    <span class="md-ellipsis">
      
        save_experiment
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.save_result" class="md-nav__link">
    <span class="md-ellipsis">
      
        save_result
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.to_all_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        to_all_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.to_red_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        to_red_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.update_stats" class="md-nav__link">
    <span class="md-ellipsis">
      
        update_stats
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../data/diabetes/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    data
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../nn/linear_regressor/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    nn
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../surrogate/kriging/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    surrogate
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../hyperparameter-tuning-cookbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Documentation
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../download/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Download
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Examples
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../manuals/reproducibility/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    Manuals
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../about/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    About
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim" class="md-nav__link">
    <span class="md-ellipsis">
      
        SpotOptim
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim" class="md-nav__link">
    <span class="md-ellipsis">
      
        SpotOptim
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SpotOptim">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.load_experiment" class="md-nav__link">
    <span class="md-ellipsis">
      
        load_experiment
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.load_result" class="md-nav__link">
    <span class="md-ellipsis">
      
        load_result
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.optimize" class="md-nav__link">
    <span class="md-ellipsis">
      
        optimize
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.plot_surrogate" class="md-nav__link">
    <span class="md-ellipsis">
      
        plot_surrogate
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.save_experiment" class="md-nav__link">
    <span class="md-ellipsis">
      
        save_experiment
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.save_result" class="md-nav__link">
    <span class="md-ellipsis">
      
        save_result
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.to_all_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        to_all_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.to_red_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        to_red_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.update_stats" class="md-nav__link">
    <span class="md-ellipsis">
      
        update_stats
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
                



  


  <nav class="md-path" aria-label="Navigation" >
    <ol class="md-path__list">
      
        
  
  
    <li class="md-path__item">
      <a href="../../.." class="md-path__link">
        
  <span class="md-ellipsis">
    Home
  </span>

      </a>
    </li>
  

      
      
        
  
  
    
    
      
  
  
    
    
      <li class="md-path__item">
        <a href="./" class="md-path__link">
          
  <span class="md-ellipsis">
    Code Reference
  </span>

        </a>
      </li>
    
  

    
  

      
        
  
  
    
    
      <li class="md-path__item">
        <a href="./" class="md-path__link">
          
  <span class="md-ellipsis">
    spotoptim
  </span>

        </a>
      </li>
    
  

      
    </ol>
  </nav>

              
              <article class="md-content__inner md-typeset">
                
                  


  
  


  <h1>SpotOptim</h1>

<div class="doc doc-object doc-module">



<a id="spotoptim.SpotOptim"></a>
    <div class="doc doc-contents first">










  <div class="doc doc-children">









<div class="doc doc-object doc-class">



<h2 id="spotoptim.SpotOptim.SpotOptim" class="doc doc-heading">
            <code>SpotOptim</code>


<a href="#spotoptim.SpotOptim.SpotOptim" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="sklearn.base.BaseEstimator">BaseEstimator</span></code></p>



        <p>SPOT optimizer compatible with scipy.optimize interface.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>fun</code>
            </td>
            <td>
                  <code><span title="callable">callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Objective function to minimize. Should accept array of shape (n_samples, n_features).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>bounds</code>
            </td>
            <td>
                  <code>list of tuple</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Bounds for each dimension as [(low, high), &hellip;].</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_iter</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum number of total function evaluations (including initial design).
For example, max_iter=30 with n_initial=10 will perform 10 initial evaluations plus
20 sequential optimization iterations. Defaults to 20.</p>
              </div>
            </td>
            <td>
                  <code>20</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>n_initial</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of initial design points. Defaults to 10.</p>
              </div>
            </td>
            <td>
                  <code>10</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>surrogate</code>
            </td>
            <td>
                  <code><span title="object">object</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Surrogate model. Defaults to Gaussian Process with Matern kernel.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>acquisition</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Acquisition function (&lsquo;ei&rsquo;, &lsquo;y&rsquo;, &lsquo;pi&rsquo;). Defaults to &lsquo;ei&rsquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;ei&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>var_type</code>
            </td>
            <td>
                  <code>list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Variable types for each dimension. Supported types:
- &lsquo;float&rsquo;: Python floats, continuous optimization (no rounding)
- &lsquo;int&rsquo;: Python int, float values will be rounded to integers
- &lsquo;factor&rsquo;: Unordered categorical data, internally mapped to int values
  (e.g., &ldquo;red&rdquo;-&gt;0, &ldquo;green&rdquo;-&gt;1, etc.)
Defaults to None (which sets all dimensions to &lsquo;float&rsquo;).</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>var_name</code>
            </td>
            <td>
                  <code>list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Variable names for each dimension.
If None, uses default names [&lsquo;x0&rsquo;, &lsquo;x1&rsquo;, &lsquo;x2&rsquo;, &hellip;]. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tolerance_x</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Minimum distance between points. Defaults to np.sqrt(np.spacing(1))</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_time</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum runtime in minutes. If np.inf (default), no time limit.
The optimization terminates when either max_iter evaluations are reached OR max_time
minutes have elapsed, whichever comes first. Defaults to np.inf.</p>
              </div>
            </td>
            <td>
                  <code><span title="numpy.inf">inf</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>repeats_initial</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of times to evaluate each initial design point.
Useful for noisy objective functions. If &gt; 1, noise handling is activated and
statistics (mean, variance) are tracked. Defaults to 1.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>repeats_surrogate</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of times to evaluate each surrogate-suggested point.
Useful for noisy objective functions. If &gt; 1, noise handling is activated and
statistics (mean, variance) are tracked. Defaults to 1.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ocba_delta</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of additional evaluations to allocate using Optimal Computing
Budget Allocation (OCBA) when noise handling is active. OCBA determines which existing
design points should be re-evaluated to best distinguish between alternatives. Only used
when noise=True (repeats &gt; 1) and ocba_delta &gt; 0. Requires at least 3 design points with
variance information. Defaults to 0 (no OCBA).</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tensorboard_log</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Enable TensorBoard logging. If True, optimization metrics
and hyperparameters are logged to TensorBoard. View logs by running:
<code>tensorboard --logdir=&lt;tensorboard_path&gt;</code> in a separate terminal. Defaults to False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tensorboard_path</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path for TensorBoard log files. If None and tensorboard_log
is True, creates a default path: runs/spotoptim_YYYYMMDD_HHMMSS. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tensorboard_clean</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, removes all old TensorBoard log directories from
the &lsquo;runs&rsquo; folder before starting optimization. Use with caution as this permanently
deletes all subdirectories in &lsquo;runs&rsquo;. Defaults to False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>fun_mo2so</code>
            </td>
            <td>
                  <code><span title="callable">callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Function to convert multi-objective values to single-objective.
Takes an array of shape (n_samples, n_objectives) and returns array of shape (n_samples,).
If None and objective function returns multi-objective values, uses first objective.
Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>seed</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Random seed for reproducibility. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>verbose</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Print progress information. Defaults to False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>warnings_filter</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Filter for warnings. One of &ldquo;error&rdquo;, &ldquo;ignore&rdquo;, &ldquo;always&rdquo;, &ldquo;all&rdquo;,
&ldquo;default&rdquo;, &ldquo;module&rdquo;, or &ldquo;once&rdquo;. Defaults to &ldquo;ignore&rdquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;ignore&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_surrogate_points</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum number of points to use for surrogate model fitting.
If None, all points are used. If the number of evaluated points exceeds this limit,
a subset is selected using the selection method. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>selection_method</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Method for selecting points when max_surrogate_points is exceeded.
Options: &lsquo;distant&rsquo; (Select points that are distant from each other via K-means clustering) or
&lsquo;best&rsquo; (Select all points from the cluster with the best mean objective value).
Defaults to &lsquo;distant&rsquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;distant&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>acquisition_failure_strategy</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Strategy for handling acquisition function failures.
Options: &lsquo;random&rsquo; (space-filling design via Latin Hypercube Sampling) or
&lsquo;mm&rsquo; (Morris-Mitchell phi minimizing point for maximal distance from existing points).
Defaults to &lsquo;random&rsquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;random&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.X_">X_</span></code></td>
            <td>
                  <code><span title="ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>All evaluated points, shape (n_samples, n_features).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.y_">y_</span></code></td>
            <td>
                  <code><span title="ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Function values at X_, shape (n_samples,). For multi-objective problems,
these are the converted single-objective values.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.y_mo">y_mo</span></code></td>
            <td>
                  <code><span title="ndarray">ndarray</span> or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Multi-objective function values, shape (n_samples, n_objectives).
None for single-objective problems.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.best_x_">best_x_</span></code></td>
            <td>
                  <code><span title="ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Best point found, shape (n_features,).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.best_y_">best_y_</span></code></td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Best function value found.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.n_iter_">n_iter_</span></code></td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of iterations performed.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.counter">counter</span></code></td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Total number of function evaluations.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.success_rate">success_rate</span></code></td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Rolling success rate over the last window_size evaluations.
A success is counted when a new evaluation improves upon the best value found so far.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.warnings_filter">warnings_filter</span></code></td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Filter for warnings during optimization.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.max_surrogate_points">max_surrogate_points</span></code></td>
            <td>
                  <code><span title="int">int</span> or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum number of points for surrogate fitting.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.selection_method">selection_method</span></code></td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Point selection method.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.acquisition_failure_strategy">acquisition_failure_strategy</span></code></td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Strategy for handling acquisition failures (&lsquo;random&rsquo; or &lsquo;mm&rsquo;).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.noise">noise</span></code></td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>True if noise handling is active (repeats &gt; 1).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.mean_X">mean_X</span></code></td>
            <td>
                  <code><span title="ndarray">ndarray</span> or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Aggregated unique design points (if noise=True).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.mean_y">mean_y</span></code></td>
            <td>
                  <code><span title="ndarray">ndarray</span> or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Mean y values per design point (if noise=True).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.var_y">var_y</span></code></td>
            <td>
                  <code><span title="ndarray">ndarray</span> or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Variance of y values per design point (if noise=True).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.min_mean_X">min_mean_X</span></code></td>
            <td>
                  <code><span title="ndarray">ndarray</span> or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>X value of best mean y (if noise=True).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.min_mean_y">min_mean_y</span></code></td>
            <td>
                  <code><span title="float">float</span> or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Best mean y value (if noise=True).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.min_var_y">min_var_y</span></code></td>
            <td>
                  <code><span title="float">float</span> or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Variance of best mean y (if noise=True).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">objective</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 1: Basic usage (deterministic function)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_initial</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best x:&quot;</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best f(x):&quot;</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">fun</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 2: With custom variable names</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">var_name</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;param1&quot;</span><span class="p">,</span> <span class="s2">&quot;param2&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">5</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">()</span>  <span class="c1"># Uses custom names in plot labels</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 3: Noisy function with repeated evaluations</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">noisy_objective</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">... </span>    <span class="n">base</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">base</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">base</span> <span class="o">+</span> <span class="n">noise</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="n">noisy_objective</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">repeats_initial</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>      <span class="c1"># Evaluate each initial point 3 times</span>
<span class="gp">... </span>    <span class="n">repeats_surrogate</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>    <span class="c1"># Evaluate each new point 2 times</span>
<span class="gp">... </span>    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>                <span class="c1"># For reproducibility</span>
<span class="gp">... </span>    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Access noise statistics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Unique design points:&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">mean_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best mean value:&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">min_mean_y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Variance at best point:&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">min_var_y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 4: Noisy function with OCBA (Optimal Computing Budget Allocation)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer_ocba</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="n">noisy_objective</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">repeats_initial</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>      <span class="c1"># Initial repeats</span>
<span class="gp">... </span>    <span class="n">repeats_surrogate</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>    <span class="c1"># Surrogate repeats</span>
<span class="gp">... </span>    <span class="n">ocba_delta</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>           <span class="c1"># Allocate 3 additional evaluations per iteration</span>
<span class="gp">... </span>    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">optimizer_ocba</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># OCBA intelligently re-evaluates promising points to reduce uncertainty</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total evaluations:&quot;</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">nfev</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Unique design points:&quot;</span><span class="p">,</span> <span class="n">optimizer_ocba</span><span class="o">.</span><span class="n">mean_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best mean value:&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">min_mean_y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Variance at best point:&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">min_var_y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 5: With TensorBoard logging</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer_tb</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">tensorboard_log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>   <span class="c1"># Enable TensorBoard</span>
<span class="gp">... </span>    <span class="n">tensorboard_path</span><span class="o">=</span><span class="s2">&quot;runs/my_optimization&quot;</span><span class="p">,</span>  <span class="c1"># Optional custom path</span>
<span class="gp">... </span>    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">optimizer_tb</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># View logs in browser: tensorboard --logdir=runs/my_optimization</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Logs saved to:&quot;</span><span class="p">,</span> <span class="n">optimizer_tb</span><span class="o">.</span><span class="n">tensorboard_path</span><span class="p">)</span>
</code></pre></div>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">  20</span>
<span class="normal">  21</span>
<span class="normal">  22</span>
<span class="normal">  23</span>
<span class="normal">  24</span>
<span class="normal">  25</span>
<span class="normal">  26</span>
<span class="normal">  27</span>
<span class="normal">  28</span>
<span class="normal">  29</span>
<span class="normal">  30</span>
<span class="normal">  31</span>
<span class="normal">  32</span>
<span class="normal">  33</span>
<span class="normal">  34</span>
<span class="normal">  35</span>
<span class="normal">  36</span>
<span class="normal">  37</span>
<span class="normal">  38</span>
<span class="normal">  39</span>
<span class="normal">  40</span>
<span class="normal">  41</span>
<span class="normal">  42</span>
<span class="normal">  43</span>
<span class="normal">  44</span>
<span class="normal">  45</span>
<span class="normal">  46</span>
<span class="normal">  47</span>
<span class="normal">  48</span>
<span class="normal">  49</span>
<span class="normal">  50</span>
<span class="normal">  51</span>
<span class="normal">  52</span>
<span class="normal">  53</span>
<span class="normal">  54</span>
<span class="normal">  55</span>
<span class="normal">  56</span>
<span class="normal">  57</span>
<span class="normal">  58</span>
<span class="normal">  59</span>
<span class="normal">  60</span>
<span class="normal">  61</span>
<span class="normal">  62</span>
<span class="normal">  63</span>
<span class="normal">  64</span>
<span class="normal">  65</span>
<span class="normal">  66</span>
<span class="normal">  67</span>
<span class="normal">  68</span>
<span class="normal">  69</span>
<span class="normal">  70</span>
<span class="normal">  71</span>
<span class="normal">  72</span>
<span class="normal">  73</span>
<span class="normal">  74</span>
<span class="normal">  75</span>
<span class="normal">  76</span>
<span class="normal">  77</span>
<span class="normal">  78</span>
<span class="normal">  79</span>
<span class="normal">  80</span>
<span class="normal">  81</span>
<span class="normal">  82</span>
<span class="normal">  83</span>
<span class="normal">  84</span>
<span class="normal">  85</span>
<span class="normal">  86</span>
<span class="normal">  87</span>
<span class="normal">  88</span>
<span class="normal">  89</span>
<span class="normal">  90</span>
<span class="normal">  91</span>
<span class="normal">  92</span>
<span class="normal">  93</span>
<span class="normal">  94</span>
<span class="normal">  95</span>
<span class="normal">  96</span>
<span class="normal">  97</span>
<span class="normal">  98</span>
<span class="normal">  99</span>
<span class="normal"> 100</span>
<span class="normal"> 101</span>
<span class="normal"> 102</span>
<span class="normal"> 103</span>
<span class="normal"> 104</span>
<span class="normal"> 105</span>
<span class="normal"> 106</span>
<span class="normal"> 107</span>
<span class="normal"> 108</span>
<span class="normal"> 109</span>
<span class="normal"> 110</span>
<span class="normal"> 111</span>
<span class="normal"> 112</span>
<span class="normal"> 113</span>
<span class="normal"> 114</span>
<span class="normal"> 115</span>
<span class="normal"> 116</span>
<span class="normal"> 117</span>
<span class="normal"> 118</span>
<span class="normal"> 119</span>
<span class="normal"> 120</span>
<span class="normal"> 121</span>
<span class="normal"> 122</span>
<span class="normal"> 123</span>
<span class="normal"> 124</span>
<span class="normal"> 125</span>
<span class="normal"> 126</span>
<span class="normal"> 127</span>
<span class="normal"> 128</span>
<span class="normal"> 129</span>
<span class="normal"> 130</span>
<span class="normal"> 131</span>
<span class="normal"> 132</span>
<span class="normal"> 133</span>
<span class="normal"> 134</span>
<span class="normal"> 135</span>
<span class="normal"> 136</span>
<span class="normal"> 137</span>
<span class="normal"> 138</span>
<span class="normal"> 139</span>
<span class="normal"> 140</span>
<span class="normal"> 141</span>
<span class="normal"> 142</span>
<span class="normal"> 143</span>
<span class="normal"> 144</span>
<span class="normal"> 145</span>
<span class="normal"> 146</span>
<span class="normal"> 147</span>
<span class="normal"> 148</span>
<span class="normal"> 149</span>
<span class="normal"> 150</span>
<span class="normal"> 151</span>
<span class="normal"> 152</span>
<span class="normal"> 153</span>
<span class="normal"> 154</span>
<span class="normal"> 155</span>
<span class="normal"> 156</span>
<span class="normal"> 157</span>
<span class="normal"> 158</span>
<span class="normal"> 159</span>
<span class="normal"> 160</span>
<span class="normal"> 161</span>
<span class="normal"> 162</span>
<span class="normal"> 163</span>
<span class="normal"> 164</span>
<span class="normal"> 165</span>
<span class="normal"> 166</span>
<span class="normal"> 167</span>
<span class="normal"> 168</span>
<span class="normal"> 169</span>
<span class="normal"> 170</span>
<span class="normal"> 171</span>
<span class="normal"> 172</span>
<span class="normal"> 173</span>
<span class="normal"> 174</span>
<span class="normal"> 175</span>
<span class="normal"> 176</span>
<span class="normal"> 177</span>
<span class="normal"> 178</span>
<span class="normal"> 179</span>
<span class="normal"> 180</span>
<span class="normal"> 181</span>
<span class="normal"> 182</span>
<span class="normal"> 183</span>
<span class="normal"> 184</span>
<span class="normal"> 185</span>
<span class="normal"> 186</span>
<span class="normal"> 187</span>
<span class="normal"> 188</span>
<span class="normal"> 189</span>
<span class="normal"> 190</span>
<span class="normal"> 191</span>
<span class="normal"> 192</span>
<span class="normal"> 193</span>
<span class="normal"> 194</span>
<span class="normal"> 195</span>
<span class="normal"> 196</span>
<span class="normal"> 197</span>
<span class="normal"> 198</span>
<span class="normal"> 199</span>
<span class="normal"> 200</span>
<span class="normal"> 201</span>
<span class="normal"> 202</span>
<span class="normal"> 203</span>
<span class="normal"> 204</span>
<span class="normal"> 205</span>
<span class="normal"> 206</span>
<span class="normal"> 207</span>
<span class="normal"> 208</span>
<span class="normal"> 209</span>
<span class="normal"> 210</span>
<span class="normal"> 211</span>
<span class="normal"> 212</span>
<span class="normal"> 213</span>
<span class="normal"> 214</span>
<span class="normal"> 215</span>
<span class="normal"> 216</span>
<span class="normal"> 217</span>
<span class="normal"> 218</span>
<span class="normal"> 219</span>
<span class="normal"> 220</span>
<span class="normal"> 221</span>
<span class="normal"> 222</span>
<span class="normal"> 223</span>
<span class="normal"> 224</span>
<span class="normal"> 225</span>
<span class="normal"> 226</span>
<span class="normal"> 227</span>
<span class="normal"> 228</span>
<span class="normal"> 229</span>
<span class="normal"> 230</span>
<span class="normal"> 231</span>
<span class="normal"> 232</span>
<span class="normal"> 233</span>
<span class="normal"> 234</span>
<span class="normal"> 235</span>
<span class="normal"> 236</span>
<span class="normal"> 237</span>
<span class="normal"> 238</span>
<span class="normal"> 239</span>
<span class="normal"> 240</span>
<span class="normal"> 241</span>
<span class="normal"> 242</span>
<span class="normal"> 243</span>
<span class="normal"> 244</span>
<span class="normal"> 245</span>
<span class="normal"> 246</span>
<span class="normal"> 247</span>
<span class="normal"> 248</span>
<span class="normal"> 249</span>
<span class="normal"> 250</span>
<span class="normal"> 251</span>
<span class="normal"> 252</span>
<span class="normal"> 253</span>
<span class="normal"> 254</span>
<span class="normal"> 255</span>
<span class="normal"> 256</span>
<span class="normal"> 257</span>
<span class="normal"> 258</span>
<span class="normal"> 259</span>
<span class="normal"> 260</span>
<span class="normal"> 261</span>
<span class="normal"> 262</span>
<span class="normal"> 263</span>
<span class="normal"> 264</span>
<span class="normal"> 265</span>
<span class="normal"> 266</span>
<span class="normal"> 267</span>
<span class="normal"> 268</span>
<span class="normal"> 269</span>
<span class="normal"> 270</span>
<span class="normal"> 271</span>
<span class="normal"> 272</span>
<span class="normal"> 273</span>
<span class="normal"> 274</span>
<span class="normal"> 275</span>
<span class="normal"> 276</span>
<span class="normal"> 277</span>
<span class="normal"> 278</span>
<span class="normal"> 279</span>
<span class="normal"> 280</span>
<span class="normal"> 281</span>
<span class="normal"> 282</span>
<span class="normal"> 283</span>
<span class="normal"> 284</span>
<span class="normal"> 285</span>
<span class="normal"> 286</span>
<span class="normal"> 287</span>
<span class="normal"> 288</span>
<span class="normal"> 289</span>
<span class="normal"> 290</span>
<span class="normal"> 291</span>
<span class="normal"> 292</span>
<span class="normal"> 293</span>
<span class="normal"> 294</span>
<span class="normal"> 295</span>
<span class="normal"> 296</span>
<span class="normal"> 297</span>
<span class="normal"> 298</span>
<span class="normal"> 299</span>
<span class="normal"> 300</span>
<span class="normal"> 301</span>
<span class="normal"> 302</span>
<span class="normal"> 303</span>
<span class="normal"> 304</span>
<span class="normal"> 305</span>
<span class="normal"> 306</span>
<span class="normal"> 307</span>
<span class="normal"> 308</span>
<span class="normal"> 309</span>
<span class="normal"> 310</span>
<span class="normal"> 311</span>
<span class="normal"> 312</span>
<span class="normal"> 313</span>
<span class="normal"> 314</span>
<span class="normal"> 315</span>
<span class="normal"> 316</span>
<span class="normal"> 317</span>
<span class="normal"> 318</span>
<span class="normal"> 319</span>
<span class="normal"> 320</span>
<span class="normal"> 321</span>
<span class="normal"> 322</span>
<span class="normal"> 323</span>
<span class="normal"> 324</span>
<span class="normal"> 325</span>
<span class="normal"> 326</span>
<span class="normal"> 327</span>
<span class="normal"> 328</span>
<span class="normal"> 329</span>
<span class="normal"> 330</span>
<span class="normal"> 331</span>
<span class="normal"> 332</span>
<span class="normal"> 333</span>
<span class="normal"> 334</span>
<span class="normal"> 335</span>
<span class="normal"> 336</span>
<span class="normal"> 337</span>
<span class="normal"> 338</span>
<span class="normal"> 339</span>
<span class="normal"> 340</span>
<span class="normal"> 341</span>
<span class="normal"> 342</span>
<span class="normal"> 343</span>
<span class="normal"> 344</span>
<span class="normal"> 345</span>
<span class="normal"> 346</span>
<span class="normal"> 347</span>
<span class="normal"> 348</span>
<span class="normal"> 349</span>
<span class="normal"> 350</span>
<span class="normal"> 351</span>
<span class="normal"> 352</span>
<span class="normal"> 353</span>
<span class="normal"> 354</span>
<span class="normal"> 355</span>
<span class="normal"> 356</span>
<span class="normal"> 357</span>
<span class="normal"> 358</span>
<span class="normal"> 359</span>
<span class="normal"> 360</span>
<span class="normal"> 361</span>
<span class="normal"> 362</span>
<span class="normal"> 363</span>
<span class="normal"> 364</span>
<span class="normal"> 365</span>
<span class="normal"> 366</span>
<span class="normal"> 367</span>
<span class="normal"> 368</span>
<span class="normal"> 369</span>
<span class="normal"> 370</span>
<span class="normal"> 371</span>
<span class="normal"> 372</span>
<span class="normal"> 373</span>
<span class="normal"> 374</span>
<span class="normal"> 375</span>
<span class="normal"> 376</span>
<span class="normal"> 377</span>
<span class="normal"> 378</span>
<span class="normal"> 379</span>
<span class="normal"> 380</span>
<span class="normal"> 381</span>
<span class="normal"> 382</span>
<span class="normal"> 383</span>
<span class="normal"> 384</span>
<span class="normal"> 385</span>
<span class="normal"> 386</span>
<span class="normal"> 387</span>
<span class="normal"> 388</span>
<span class="normal"> 389</span>
<span class="normal"> 390</span>
<span class="normal"> 391</span>
<span class="normal"> 392</span>
<span class="normal"> 393</span>
<span class="normal"> 394</span>
<span class="normal"> 395</span>
<span class="normal"> 396</span>
<span class="normal"> 397</span>
<span class="normal"> 398</span>
<span class="normal"> 399</span>
<span class="normal"> 400</span>
<span class="normal"> 401</span>
<span class="normal"> 402</span>
<span class="normal"> 403</span>
<span class="normal"> 404</span>
<span class="normal"> 405</span>
<span class="normal"> 406</span>
<span class="normal"> 407</span>
<span class="normal"> 408</span>
<span class="normal"> 409</span>
<span class="normal"> 410</span>
<span class="normal"> 411</span>
<span class="normal"> 412</span>
<span class="normal"> 413</span>
<span class="normal"> 414</span>
<span class="normal"> 415</span>
<span class="normal"> 416</span>
<span class="normal"> 417</span>
<span class="normal"> 418</span>
<span class="normal"> 419</span>
<span class="normal"> 420</span>
<span class="normal"> 421</span>
<span class="normal"> 422</span>
<span class="normal"> 423</span>
<span class="normal"> 424</span>
<span class="normal"> 425</span>
<span class="normal"> 426</span>
<span class="normal"> 427</span>
<span class="normal"> 428</span>
<span class="normal"> 429</span>
<span class="normal"> 430</span>
<span class="normal"> 431</span>
<span class="normal"> 432</span>
<span class="normal"> 433</span>
<span class="normal"> 434</span>
<span class="normal"> 435</span>
<span class="normal"> 436</span>
<span class="normal"> 437</span>
<span class="normal"> 438</span>
<span class="normal"> 439</span>
<span class="normal"> 440</span>
<span class="normal"> 441</span>
<span class="normal"> 442</span>
<span class="normal"> 443</span>
<span class="normal"> 444</span>
<span class="normal"> 445</span>
<span class="normal"> 446</span>
<span class="normal"> 447</span>
<span class="normal"> 448</span>
<span class="normal"> 449</span>
<span class="normal"> 450</span>
<span class="normal"> 451</span>
<span class="normal"> 452</span>
<span class="normal"> 453</span>
<span class="normal"> 454</span>
<span class="normal"> 455</span>
<span class="normal"> 456</span>
<span class="normal"> 457</span>
<span class="normal"> 458</span>
<span class="normal"> 459</span>
<span class="normal"> 460</span>
<span class="normal"> 461</span>
<span class="normal"> 462</span>
<span class="normal"> 463</span>
<span class="normal"> 464</span>
<span class="normal"> 465</span>
<span class="normal"> 466</span>
<span class="normal"> 467</span>
<span class="normal"> 468</span>
<span class="normal"> 469</span>
<span class="normal"> 470</span>
<span class="normal"> 471</span>
<span class="normal"> 472</span>
<span class="normal"> 473</span>
<span class="normal"> 474</span>
<span class="normal"> 475</span>
<span class="normal"> 476</span>
<span class="normal"> 477</span>
<span class="normal"> 478</span>
<span class="normal"> 479</span>
<span class="normal"> 480</span>
<span class="normal"> 481</span>
<span class="normal"> 482</span>
<span class="normal"> 483</span>
<span class="normal"> 484</span>
<span class="normal"> 485</span>
<span class="normal"> 486</span>
<span class="normal"> 487</span>
<span class="normal"> 488</span>
<span class="normal"> 489</span>
<span class="normal"> 490</span>
<span class="normal"> 491</span>
<span class="normal"> 492</span>
<span class="normal"> 493</span>
<span class="normal"> 494</span>
<span class="normal"> 495</span>
<span class="normal"> 496</span>
<span class="normal"> 497</span>
<span class="normal"> 498</span>
<span class="normal"> 499</span>
<span class="normal"> 500</span>
<span class="normal"> 501</span>
<span class="normal"> 502</span>
<span class="normal"> 503</span>
<span class="normal"> 504</span>
<span class="normal"> 505</span>
<span class="normal"> 506</span>
<span class="normal"> 507</span>
<span class="normal"> 508</span>
<span class="normal"> 509</span>
<span class="normal"> 510</span>
<span class="normal"> 511</span>
<span class="normal"> 512</span>
<span class="normal"> 513</span>
<span class="normal"> 514</span>
<span class="normal"> 515</span>
<span class="normal"> 516</span>
<span class="normal"> 517</span>
<span class="normal"> 518</span>
<span class="normal"> 519</span>
<span class="normal"> 520</span>
<span class="normal"> 521</span>
<span class="normal"> 522</span>
<span class="normal"> 523</span>
<span class="normal"> 524</span>
<span class="normal"> 525</span>
<span class="normal"> 526</span>
<span class="normal"> 527</span>
<span class="normal"> 528</span>
<span class="normal"> 529</span>
<span class="normal"> 530</span>
<span class="normal"> 531</span>
<span class="normal"> 532</span>
<span class="normal"> 533</span>
<span class="normal"> 534</span>
<span class="normal"> 535</span>
<span class="normal"> 536</span>
<span class="normal"> 537</span>
<span class="normal"> 538</span>
<span class="normal"> 539</span>
<span class="normal"> 540</span>
<span class="normal"> 541</span>
<span class="normal"> 542</span>
<span class="normal"> 543</span>
<span class="normal"> 544</span>
<span class="normal"> 545</span>
<span class="normal"> 546</span>
<span class="normal"> 547</span>
<span class="normal"> 548</span>
<span class="normal"> 549</span>
<span class="normal"> 550</span>
<span class="normal"> 551</span>
<span class="normal"> 552</span>
<span class="normal"> 553</span>
<span class="normal"> 554</span>
<span class="normal"> 555</span>
<span class="normal"> 556</span>
<span class="normal"> 557</span>
<span class="normal"> 558</span>
<span class="normal"> 559</span>
<span class="normal"> 560</span>
<span class="normal"> 561</span>
<span class="normal"> 562</span>
<span class="normal"> 563</span>
<span class="normal"> 564</span>
<span class="normal"> 565</span>
<span class="normal"> 566</span>
<span class="normal"> 567</span>
<span class="normal"> 568</span>
<span class="normal"> 569</span>
<span class="normal"> 570</span>
<span class="normal"> 571</span>
<span class="normal"> 572</span>
<span class="normal"> 573</span>
<span class="normal"> 574</span>
<span class="normal"> 575</span>
<span class="normal"> 576</span>
<span class="normal"> 577</span>
<span class="normal"> 578</span>
<span class="normal"> 579</span>
<span class="normal"> 580</span>
<span class="normal"> 581</span>
<span class="normal"> 582</span>
<span class="normal"> 583</span>
<span class="normal"> 584</span>
<span class="normal"> 585</span>
<span class="normal"> 586</span>
<span class="normal"> 587</span>
<span class="normal"> 588</span>
<span class="normal"> 589</span>
<span class="normal"> 590</span>
<span class="normal"> 591</span>
<span class="normal"> 592</span>
<span class="normal"> 593</span>
<span class="normal"> 594</span>
<span class="normal"> 595</span>
<span class="normal"> 596</span>
<span class="normal"> 597</span>
<span class="normal"> 598</span>
<span class="normal"> 599</span>
<span class="normal"> 600</span>
<span class="normal"> 601</span>
<span class="normal"> 602</span>
<span class="normal"> 603</span>
<span class="normal"> 604</span>
<span class="normal"> 605</span>
<span class="normal"> 606</span>
<span class="normal"> 607</span>
<span class="normal"> 608</span>
<span class="normal"> 609</span>
<span class="normal"> 610</span>
<span class="normal"> 611</span>
<span class="normal"> 612</span>
<span class="normal"> 613</span>
<span class="normal"> 614</span>
<span class="normal"> 615</span>
<span class="normal"> 616</span>
<span class="normal"> 617</span>
<span class="normal"> 618</span>
<span class="normal"> 619</span>
<span class="normal"> 620</span>
<span class="normal"> 621</span>
<span class="normal"> 622</span>
<span class="normal"> 623</span>
<span class="normal"> 624</span>
<span class="normal"> 625</span>
<span class="normal"> 626</span>
<span class="normal"> 627</span>
<span class="normal"> 628</span>
<span class="normal"> 629</span>
<span class="normal"> 630</span>
<span class="normal"> 631</span>
<span class="normal"> 632</span>
<span class="normal"> 633</span>
<span class="normal"> 634</span>
<span class="normal"> 635</span>
<span class="normal"> 636</span>
<span class="normal"> 637</span>
<span class="normal"> 638</span>
<span class="normal"> 639</span>
<span class="normal"> 640</span>
<span class="normal"> 641</span>
<span class="normal"> 642</span>
<span class="normal"> 643</span>
<span class="normal"> 644</span>
<span class="normal"> 645</span>
<span class="normal"> 646</span>
<span class="normal"> 647</span>
<span class="normal"> 648</span>
<span class="normal"> 649</span>
<span class="normal"> 650</span>
<span class="normal"> 651</span>
<span class="normal"> 652</span>
<span class="normal"> 653</span>
<span class="normal"> 654</span>
<span class="normal"> 655</span>
<span class="normal"> 656</span>
<span class="normal"> 657</span>
<span class="normal"> 658</span>
<span class="normal"> 659</span>
<span class="normal"> 660</span>
<span class="normal"> 661</span>
<span class="normal"> 662</span>
<span class="normal"> 663</span>
<span class="normal"> 664</span>
<span class="normal"> 665</span>
<span class="normal"> 666</span>
<span class="normal"> 667</span>
<span class="normal"> 668</span>
<span class="normal"> 669</span>
<span class="normal"> 670</span>
<span class="normal"> 671</span>
<span class="normal"> 672</span>
<span class="normal"> 673</span>
<span class="normal"> 674</span>
<span class="normal"> 675</span>
<span class="normal"> 676</span>
<span class="normal"> 677</span>
<span class="normal"> 678</span>
<span class="normal"> 679</span>
<span class="normal"> 680</span>
<span class="normal"> 681</span>
<span class="normal"> 682</span>
<span class="normal"> 683</span>
<span class="normal"> 684</span>
<span class="normal"> 685</span>
<span class="normal"> 686</span>
<span class="normal"> 687</span>
<span class="normal"> 688</span>
<span class="normal"> 689</span>
<span class="normal"> 690</span>
<span class="normal"> 691</span>
<span class="normal"> 692</span>
<span class="normal"> 693</span>
<span class="normal"> 694</span>
<span class="normal"> 695</span>
<span class="normal"> 696</span>
<span class="normal"> 697</span>
<span class="normal"> 698</span>
<span class="normal"> 699</span>
<span class="normal"> 700</span>
<span class="normal"> 701</span>
<span class="normal"> 702</span>
<span class="normal"> 703</span>
<span class="normal"> 704</span>
<span class="normal"> 705</span>
<span class="normal"> 706</span>
<span class="normal"> 707</span>
<span class="normal"> 708</span>
<span class="normal"> 709</span>
<span class="normal"> 710</span>
<span class="normal"> 711</span>
<span class="normal"> 712</span>
<span class="normal"> 713</span>
<span class="normal"> 714</span>
<span class="normal"> 715</span>
<span class="normal"> 716</span>
<span class="normal"> 717</span>
<span class="normal"> 718</span>
<span class="normal"> 719</span>
<span class="normal"> 720</span>
<span class="normal"> 721</span>
<span class="normal"> 722</span>
<span class="normal"> 723</span>
<span class="normal"> 724</span>
<span class="normal"> 725</span>
<span class="normal"> 726</span>
<span class="normal"> 727</span>
<span class="normal"> 728</span>
<span class="normal"> 729</span>
<span class="normal"> 730</span>
<span class="normal"> 731</span>
<span class="normal"> 732</span>
<span class="normal"> 733</span>
<span class="normal"> 734</span>
<span class="normal"> 735</span>
<span class="normal"> 736</span>
<span class="normal"> 737</span>
<span class="normal"> 738</span>
<span class="normal"> 739</span>
<span class="normal"> 740</span>
<span class="normal"> 741</span>
<span class="normal"> 742</span>
<span class="normal"> 743</span>
<span class="normal"> 744</span>
<span class="normal"> 745</span>
<span class="normal"> 746</span>
<span class="normal"> 747</span>
<span class="normal"> 748</span>
<span class="normal"> 749</span>
<span class="normal"> 750</span>
<span class="normal"> 751</span>
<span class="normal"> 752</span>
<span class="normal"> 753</span>
<span class="normal"> 754</span>
<span class="normal"> 755</span>
<span class="normal"> 756</span>
<span class="normal"> 757</span>
<span class="normal"> 758</span>
<span class="normal"> 759</span>
<span class="normal"> 760</span>
<span class="normal"> 761</span>
<span class="normal"> 762</span>
<span class="normal"> 763</span>
<span class="normal"> 764</span>
<span class="normal"> 765</span>
<span class="normal"> 766</span>
<span class="normal"> 767</span>
<span class="normal"> 768</span>
<span class="normal"> 769</span>
<span class="normal"> 770</span>
<span class="normal"> 771</span>
<span class="normal"> 772</span>
<span class="normal"> 773</span>
<span class="normal"> 774</span>
<span class="normal"> 775</span>
<span class="normal"> 776</span>
<span class="normal"> 777</span>
<span class="normal"> 778</span>
<span class="normal"> 779</span>
<span class="normal"> 780</span>
<span class="normal"> 781</span>
<span class="normal"> 782</span>
<span class="normal"> 783</span>
<span class="normal"> 784</span>
<span class="normal"> 785</span>
<span class="normal"> 786</span>
<span class="normal"> 787</span>
<span class="normal"> 788</span>
<span class="normal"> 789</span>
<span class="normal"> 790</span>
<span class="normal"> 791</span>
<span class="normal"> 792</span>
<span class="normal"> 793</span>
<span class="normal"> 794</span>
<span class="normal"> 795</span>
<span class="normal"> 796</span>
<span class="normal"> 797</span>
<span class="normal"> 798</span>
<span class="normal"> 799</span>
<span class="normal"> 800</span>
<span class="normal"> 801</span>
<span class="normal"> 802</span>
<span class="normal"> 803</span>
<span class="normal"> 804</span>
<span class="normal"> 805</span>
<span class="normal"> 806</span>
<span class="normal"> 807</span>
<span class="normal"> 808</span>
<span class="normal"> 809</span>
<span class="normal"> 810</span>
<span class="normal"> 811</span>
<span class="normal"> 812</span>
<span class="normal"> 813</span>
<span class="normal"> 814</span>
<span class="normal"> 815</span>
<span class="normal"> 816</span>
<span class="normal"> 817</span>
<span class="normal"> 818</span>
<span class="normal"> 819</span>
<span class="normal"> 820</span>
<span class="normal"> 821</span>
<span class="normal"> 822</span>
<span class="normal"> 823</span>
<span class="normal"> 824</span>
<span class="normal"> 825</span>
<span class="normal"> 826</span>
<span class="normal"> 827</span>
<span class="normal"> 828</span>
<span class="normal"> 829</span>
<span class="normal"> 830</span>
<span class="normal"> 831</span>
<span class="normal"> 832</span>
<span class="normal"> 833</span>
<span class="normal"> 834</span>
<span class="normal"> 835</span>
<span class="normal"> 836</span>
<span class="normal"> 837</span>
<span class="normal"> 838</span>
<span class="normal"> 839</span>
<span class="normal"> 840</span>
<span class="normal"> 841</span>
<span class="normal"> 842</span>
<span class="normal"> 843</span>
<span class="normal"> 844</span>
<span class="normal"> 845</span>
<span class="normal"> 846</span>
<span class="normal"> 847</span>
<span class="normal"> 848</span>
<span class="normal"> 849</span>
<span class="normal"> 850</span>
<span class="normal"> 851</span>
<span class="normal"> 852</span>
<span class="normal"> 853</span>
<span class="normal"> 854</span>
<span class="normal"> 855</span>
<span class="normal"> 856</span>
<span class="normal"> 857</span>
<span class="normal"> 858</span>
<span class="normal"> 859</span>
<span class="normal"> 860</span>
<span class="normal"> 861</span>
<span class="normal"> 862</span>
<span class="normal"> 863</span>
<span class="normal"> 864</span>
<span class="normal"> 865</span>
<span class="normal"> 866</span>
<span class="normal"> 867</span>
<span class="normal"> 868</span>
<span class="normal"> 869</span>
<span class="normal"> 870</span>
<span class="normal"> 871</span>
<span class="normal"> 872</span>
<span class="normal"> 873</span>
<span class="normal"> 874</span>
<span class="normal"> 875</span>
<span class="normal"> 876</span>
<span class="normal"> 877</span>
<span class="normal"> 878</span>
<span class="normal"> 879</span>
<span class="normal"> 880</span>
<span class="normal"> 881</span>
<span class="normal"> 882</span>
<span class="normal"> 883</span>
<span class="normal"> 884</span>
<span class="normal"> 885</span>
<span class="normal"> 886</span>
<span class="normal"> 887</span>
<span class="normal"> 888</span>
<span class="normal"> 889</span>
<span class="normal"> 890</span>
<span class="normal"> 891</span>
<span class="normal"> 892</span>
<span class="normal"> 893</span>
<span class="normal"> 894</span>
<span class="normal"> 895</span>
<span class="normal"> 896</span>
<span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span>
<span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span>
<span class="normal">1279</span>
<span class="normal">1280</span>
<span class="normal">1281</span>
<span class="normal">1282</span>
<span class="normal">1283</span>
<span class="normal">1284</span>
<span class="normal">1285</span>
<span class="normal">1286</span>
<span class="normal">1287</span>
<span class="normal">1288</span>
<span class="normal">1289</span>
<span class="normal">1290</span>
<span class="normal">1291</span>
<span class="normal">1292</span>
<span class="normal">1293</span>
<span class="normal">1294</span>
<span class="normal">1295</span>
<span class="normal">1296</span>
<span class="normal">1297</span>
<span class="normal">1298</span>
<span class="normal">1299</span>
<span class="normal">1300</span>
<span class="normal">1301</span>
<span class="normal">1302</span>
<span class="normal">1303</span>
<span class="normal">1304</span>
<span class="normal">1305</span>
<span class="normal">1306</span>
<span class="normal">1307</span>
<span class="normal">1308</span>
<span class="normal">1309</span>
<span class="normal">1310</span>
<span class="normal">1311</span>
<span class="normal">1312</span>
<span class="normal">1313</span>
<span class="normal">1314</span>
<span class="normal">1315</span>
<span class="normal">1316</span>
<span class="normal">1317</span>
<span class="normal">1318</span>
<span class="normal">1319</span>
<span class="normal">1320</span>
<span class="normal">1321</span>
<span class="normal">1322</span>
<span class="normal">1323</span>
<span class="normal">1324</span>
<span class="normal">1325</span>
<span class="normal">1326</span>
<span class="normal">1327</span>
<span class="normal">1328</span>
<span class="normal">1329</span>
<span class="normal">1330</span>
<span class="normal">1331</span>
<span class="normal">1332</span>
<span class="normal">1333</span>
<span class="normal">1334</span>
<span class="normal">1335</span>
<span class="normal">1336</span>
<span class="normal">1337</span>
<span class="normal">1338</span>
<span class="normal">1339</span>
<span class="normal">1340</span>
<span class="normal">1341</span>
<span class="normal">1342</span>
<span class="normal">1343</span>
<span class="normal">1344</span>
<span class="normal">1345</span>
<span class="normal">1346</span>
<span class="normal">1347</span>
<span class="normal">1348</span>
<span class="normal">1349</span>
<span class="normal">1350</span>
<span class="normal">1351</span>
<span class="normal">1352</span>
<span class="normal">1353</span>
<span class="normal">1354</span>
<span class="normal">1355</span>
<span class="normal">1356</span>
<span class="normal">1357</span>
<span class="normal">1358</span>
<span class="normal">1359</span>
<span class="normal">1360</span>
<span class="normal">1361</span>
<span class="normal">1362</span>
<span class="normal">1363</span>
<span class="normal">1364</span>
<span class="normal">1365</span>
<span class="normal">1366</span>
<span class="normal">1367</span>
<span class="normal">1368</span>
<span class="normal">1369</span>
<span class="normal">1370</span>
<span class="normal">1371</span>
<span class="normal">1372</span>
<span class="normal">1373</span>
<span class="normal">1374</span>
<span class="normal">1375</span>
<span class="normal">1376</span>
<span class="normal">1377</span>
<span class="normal">1378</span>
<span class="normal">1379</span>
<span class="normal">1380</span>
<span class="normal">1381</span>
<span class="normal">1382</span>
<span class="normal">1383</span>
<span class="normal">1384</span>
<span class="normal">1385</span>
<span class="normal">1386</span>
<span class="normal">1387</span>
<span class="normal">1388</span>
<span class="normal">1389</span>
<span class="normal">1390</span>
<span class="normal">1391</span>
<span class="normal">1392</span>
<span class="normal">1393</span>
<span class="normal">1394</span>
<span class="normal">1395</span>
<span class="normal">1396</span>
<span class="normal">1397</span>
<span class="normal">1398</span>
<span class="normal">1399</span>
<span class="normal">1400</span>
<span class="normal">1401</span>
<span class="normal">1402</span>
<span class="normal">1403</span>
<span class="normal">1404</span>
<span class="normal">1405</span>
<span class="normal">1406</span>
<span class="normal">1407</span>
<span class="normal">1408</span>
<span class="normal">1409</span>
<span class="normal">1410</span>
<span class="normal">1411</span>
<span class="normal">1412</span>
<span class="normal">1413</span>
<span class="normal">1414</span>
<span class="normal">1415</span>
<span class="normal">1416</span>
<span class="normal">1417</span>
<span class="normal">1418</span>
<span class="normal">1419</span>
<span class="normal">1420</span>
<span class="normal">1421</span>
<span class="normal">1422</span>
<span class="normal">1423</span>
<span class="normal">1424</span>
<span class="normal">1425</span>
<span class="normal">1426</span>
<span class="normal">1427</span>
<span class="normal">1428</span>
<span class="normal">1429</span>
<span class="normal">1430</span>
<span class="normal">1431</span>
<span class="normal">1432</span>
<span class="normal">1433</span>
<span class="normal">1434</span>
<span class="normal">1435</span>
<span class="normal">1436</span>
<span class="normal">1437</span>
<span class="normal">1438</span>
<span class="normal">1439</span>
<span class="normal">1440</span>
<span class="normal">1441</span>
<span class="normal">1442</span>
<span class="normal">1443</span>
<span class="normal">1444</span>
<span class="normal">1445</span>
<span class="normal">1446</span>
<span class="normal">1447</span>
<span class="normal">1448</span>
<span class="normal">1449</span>
<span class="normal">1450</span>
<span class="normal">1451</span>
<span class="normal">1452</span>
<span class="normal">1453</span>
<span class="normal">1454</span>
<span class="normal">1455</span>
<span class="normal">1456</span>
<span class="normal">1457</span>
<span class="normal">1458</span>
<span class="normal">1459</span>
<span class="normal">1460</span>
<span class="normal">1461</span>
<span class="normal">1462</span>
<span class="normal">1463</span>
<span class="normal">1464</span>
<span class="normal">1465</span>
<span class="normal">1466</span>
<span class="normal">1467</span>
<span class="normal">1468</span>
<span class="normal">1469</span>
<span class="normal">1470</span>
<span class="normal">1471</span>
<span class="normal">1472</span>
<span class="normal">1473</span>
<span class="normal">1474</span>
<span class="normal">1475</span>
<span class="normal">1476</span>
<span class="normal">1477</span>
<span class="normal">1478</span>
<span class="normal">1479</span>
<span class="normal">1480</span>
<span class="normal">1481</span>
<span class="normal">1482</span>
<span class="normal">1483</span>
<span class="normal">1484</span>
<span class="normal">1485</span>
<span class="normal">1486</span>
<span class="normal">1487</span>
<span class="normal">1488</span>
<span class="normal">1489</span>
<span class="normal">1490</span>
<span class="normal">1491</span>
<span class="normal">1492</span>
<span class="normal">1493</span>
<span class="normal">1494</span>
<span class="normal">1495</span>
<span class="normal">1496</span>
<span class="normal">1497</span>
<span class="normal">1498</span>
<span class="normal">1499</span>
<span class="normal">1500</span>
<span class="normal">1501</span>
<span class="normal">1502</span>
<span class="normal">1503</span>
<span class="normal">1504</span>
<span class="normal">1505</span>
<span class="normal">1506</span>
<span class="normal">1507</span>
<span class="normal">1508</span>
<span class="normal">1509</span>
<span class="normal">1510</span>
<span class="normal">1511</span>
<span class="normal">1512</span>
<span class="normal">1513</span>
<span class="normal">1514</span>
<span class="normal">1515</span>
<span class="normal">1516</span>
<span class="normal">1517</span>
<span class="normal">1518</span>
<span class="normal">1519</span>
<span class="normal">1520</span>
<span class="normal">1521</span>
<span class="normal">1522</span>
<span class="normal">1523</span>
<span class="normal">1524</span>
<span class="normal">1525</span>
<span class="normal">1526</span>
<span class="normal">1527</span>
<span class="normal">1528</span>
<span class="normal">1529</span>
<span class="normal">1530</span>
<span class="normal">1531</span>
<span class="normal">1532</span>
<span class="normal">1533</span>
<span class="normal">1534</span>
<span class="normal">1535</span>
<span class="normal">1536</span>
<span class="normal">1537</span>
<span class="normal">1538</span>
<span class="normal">1539</span>
<span class="normal">1540</span>
<span class="normal">1541</span>
<span class="normal">1542</span>
<span class="normal">1543</span>
<span class="normal">1544</span>
<span class="normal">1545</span>
<span class="normal">1546</span>
<span class="normal">1547</span>
<span class="normal">1548</span>
<span class="normal">1549</span>
<span class="normal">1550</span>
<span class="normal">1551</span>
<span class="normal">1552</span>
<span class="normal">1553</span>
<span class="normal">1554</span>
<span class="normal">1555</span>
<span class="normal">1556</span>
<span class="normal">1557</span>
<span class="normal">1558</span>
<span class="normal">1559</span>
<span class="normal">1560</span>
<span class="normal">1561</span>
<span class="normal">1562</span>
<span class="normal">1563</span>
<span class="normal">1564</span>
<span class="normal">1565</span>
<span class="normal">1566</span>
<span class="normal">1567</span>
<span class="normal">1568</span>
<span class="normal">1569</span>
<span class="normal">1570</span>
<span class="normal">1571</span>
<span class="normal">1572</span>
<span class="normal">1573</span>
<span class="normal">1574</span>
<span class="normal">1575</span>
<span class="normal">1576</span>
<span class="normal">1577</span>
<span class="normal">1578</span>
<span class="normal">1579</span>
<span class="normal">1580</span>
<span class="normal">1581</span>
<span class="normal">1582</span>
<span class="normal">1583</span>
<span class="normal">1584</span>
<span class="normal">1585</span>
<span class="normal">1586</span>
<span class="normal">1587</span>
<span class="normal">1588</span>
<span class="normal">1589</span>
<span class="normal">1590</span>
<span class="normal">1591</span>
<span class="normal">1592</span>
<span class="normal">1593</span>
<span class="normal">1594</span>
<span class="normal">1595</span>
<span class="normal">1596</span>
<span class="normal">1597</span>
<span class="normal">1598</span>
<span class="normal">1599</span>
<span class="normal">1600</span>
<span class="normal">1601</span>
<span class="normal">1602</span>
<span class="normal">1603</span>
<span class="normal">1604</span>
<span class="normal">1605</span>
<span class="normal">1606</span>
<span class="normal">1607</span>
<span class="normal">1608</span>
<span class="normal">1609</span>
<span class="normal">1610</span>
<span class="normal">1611</span>
<span class="normal">1612</span>
<span class="normal">1613</span>
<span class="normal">1614</span>
<span class="normal">1615</span>
<span class="normal">1616</span>
<span class="normal">1617</span>
<span class="normal">1618</span>
<span class="normal">1619</span>
<span class="normal">1620</span>
<span class="normal">1621</span>
<span class="normal">1622</span>
<span class="normal">1623</span>
<span class="normal">1624</span>
<span class="normal">1625</span>
<span class="normal">1626</span>
<span class="normal">1627</span>
<span class="normal">1628</span>
<span class="normal">1629</span>
<span class="normal">1630</span>
<span class="normal">1631</span>
<span class="normal">1632</span>
<span class="normal">1633</span>
<span class="normal">1634</span>
<span class="normal">1635</span>
<span class="normal">1636</span>
<span class="normal">1637</span>
<span class="normal">1638</span>
<span class="normal">1639</span>
<span class="normal">1640</span>
<span class="normal">1641</span>
<span class="normal">1642</span>
<span class="normal">1643</span>
<span class="normal">1644</span>
<span class="normal">1645</span>
<span class="normal">1646</span>
<span class="normal">1647</span>
<span class="normal">1648</span>
<span class="normal">1649</span>
<span class="normal">1650</span>
<span class="normal">1651</span>
<span class="normal">1652</span>
<span class="normal">1653</span>
<span class="normal">1654</span>
<span class="normal">1655</span>
<span class="normal">1656</span>
<span class="normal">1657</span>
<span class="normal">1658</span>
<span class="normal">1659</span>
<span class="normal">1660</span>
<span class="normal">1661</span>
<span class="normal">1662</span>
<span class="normal">1663</span>
<span class="normal">1664</span>
<span class="normal">1665</span>
<span class="normal">1666</span>
<span class="normal">1667</span>
<span class="normal">1668</span>
<span class="normal">1669</span>
<span class="normal">1670</span>
<span class="normal">1671</span>
<span class="normal">1672</span>
<span class="normal">1673</span>
<span class="normal">1674</span>
<span class="normal">1675</span>
<span class="normal">1676</span>
<span class="normal">1677</span>
<span class="normal">1678</span>
<span class="normal">1679</span>
<span class="normal">1680</span>
<span class="normal">1681</span>
<span class="normal">1682</span>
<span class="normal">1683</span>
<span class="normal">1684</span>
<span class="normal">1685</span>
<span class="normal">1686</span>
<span class="normal">1687</span>
<span class="normal">1688</span>
<span class="normal">1689</span>
<span class="normal">1690</span>
<span class="normal">1691</span>
<span class="normal">1692</span>
<span class="normal">1693</span>
<span class="normal">1694</span>
<span class="normal">1695</span>
<span class="normal">1696</span>
<span class="normal">1697</span>
<span class="normal">1698</span>
<span class="normal">1699</span>
<span class="normal">1700</span>
<span class="normal">1701</span>
<span class="normal">1702</span>
<span class="normal">1703</span>
<span class="normal">1704</span>
<span class="normal">1705</span>
<span class="normal">1706</span>
<span class="normal">1707</span>
<span class="normal">1708</span>
<span class="normal">1709</span>
<span class="normal">1710</span>
<span class="normal">1711</span>
<span class="normal">1712</span>
<span class="normal">1713</span>
<span class="normal">1714</span>
<span class="normal">1715</span>
<span class="normal">1716</span>
<span class="normal">1717</span>
<span class="normal">1718</span>
<span class="normal">1719</span>
<span class="normal">1720</span>
<span class="normal">1721</span>
<span class="normal">1722</span>
<span class="normal">1723</span>
<span class="normal">1724</span>
<span class="normal">1725</span>
<span class="normal">1726</span>
<span class="normal">1727</span>
<span class="normal">1728</span>
<span class="normal">1729</span>
<span class="normal">1730</span>
<span class="normal">1731</span>
<span class="normal">1732</span>
<span class="normal">1733</span>
<span class="normal">1734</span>
<span class="normal">1735</span>
<span class="normal">1736</span>
<span class="normal">1737</span>
<span class="normal">1738</span>
<span class="normal">1739</span>
<span class="normal">1740</span>
<span class="normal">1741</span>
<span class="normal">1742</span>
<span class="normal">1743</span>
<span class="normal">1744</span>
<span class="normal">1745</span>
<span class="normal">1746</span>
<span class="normal">1747</span>
<span class="normal">1748</span>
<span class="normal">1749</span>
<span class="normal">1750</span>
<span class="normal">1751</span>
<span class="normal">1752</span>
<span class="normal">1753</span>
<span class="normal">1754</span>
<span class="normal">1755</span>
<span class="normal">1756</span>
<span class="normal">1757</span>
<span class="normal">1758</span>
<span class="normal">1759</span>
<span class="normal">1760</span>
<span class="normal">1761</span>
<span class="normal">1762</span>
<span class="normal">1763</span>
<span class="normal">1764</span>
<span class="normal">1765</span>
<span class="normal">1766</span>
<span class="normal">1767</span>
<span class="normal">1768</span>
<span class="normal">1769</span>
<span class="normal">1770</span>
<span class="normal">1771</span>
<span class="normal">1772</span>
<span class="normal">1773</span>
<span class="normal">1774</span>
<span class="normal">1775</span>
<span class="normal">1776</span>
<span class="normal">1777</span>
<span class="normal">1778</span>
<span class="normal">1779</span>
<span class="normal">1780</span>
<span class="normal">1781</span>
<span class="normal">1782</span>
<span class="normal">1783</span>
<span class="normal">1784</span>
<span class="normal">1785</span>
<span class="normal">1786</span>
<span class="normal">1787</span>
<span class="normal">1788</span>
<span class="normal">1789</span>
<span class="normal">1790</span>
<span class="normal">1791</span>
<span class="normal">1792</span>
<span class="normal">1793</span>
<span class="normal">1794</span>
<span class="normal">1795</span>
<span class="normal">1796</span>
<span class="normal">1797</span>
<span class="normal">1798</span>
<span class="normal">1799</span>
<span class="normal">1800</span>
<span class="normal">1801</span>
<span class="normal">1802</span>
<span class="normal">1803</span>
<span class="normal">1804</span>
<span class="normal">1805</span>
<span class="normal">1806</span>
<span class="normal">1807</span>
<span class="normal">1808</span>
<span class="normal">1809</span>
<span class="normal">1810</span>
<span class="normal">1811</span>
<span class="normal">1812</span>
<span class="normal">1813</span>
<span class="normal">1814</span>
<span class="normal">1815</span>
<span class="normal">1816</span>
<span class="normal">1817</span>
<span class="normal">1818</span>
<span class="normal">1819</span>
<span class="normal">1820</span>
<span class="normal">1821</span>
<span class="normal">1822</span>
<span class="normal">1823</span>
<span class="normal">1824</span>
<span class="normal">1825</span>
<span class="normal">1826</span>
<span class="normal">1827</span>
<span class="normal">1828</span>
<span class="normal">1829</span>
<span class="normal">1830</span>
<span class="normal">1831</span>
<span class="normal">1832</span>
<span class="normal">1833</span>
<span class="normal">1834</span>
<span class="normal">1835</span>
<span class="normal">1836</span>
<span class="normal">1837</span>
<span class="normal">1838</span>
<span class="normal">1839</span>
<span class="normal">1840</span>
<span class="normal">1841</span>
<span class="normal">1842</span>
<span class="normal">1843</span>
<span class="normal">1844</span>
<span class="normal">1845</span>
<span class="normal">1846</span>
<span class="normal">1847</span>
<span class="normal">1848</span>
<span class="normal">1849</span>
<span class="normal">1850</span>
<span class="normal">1851</span>
<span class="normal">1852</span>
<span class="normal">1853</span>
<span class="normal">1854</span>
<span class="normal">1855</span>
<span class="normal">1856</span>
<span class="normal">1857</span>
<span class="normal">1858</span>
<span class="normal">1859</span>
<span class="normal">1860</span>
<span class="normal">1861</span>
<span class="normal">1862</span>
<span class="normal">1863</span>
<span class="normal">1864</span>
<span class="normal">1865</span>
<span class="normal">1866</span>
<span class="normal">1867</span>
<span class="normal">1868</span>
<span class="normal">1869</span>
<span class="normal">1870</span>
<span class="normal">1871</span>
<span class="normal">1872</span>
<span class="normal">1873</span>
<span class="normal">1874</span>
<span class="normal">1875</span>
<span class="normal">1876</span>
<span class="normal">1877</span>
<span class="normal">1878</span>
<span class="normal">1879</span>
<span class="normal">1880</span>
<span class="normal">1881</span>
<span class="normal">1882</span>
<span class="normal">1883</span>
<span class="normal">1884</span>
<span class="normal">1885</span>
<span class="normal">1886</span>
<span class="normal">1887</span>
<span class="normal">1888</span>
<span class="normal">1889</span>
<span class="normal">1890</span>
<span class="normal">1891</span>
<span class="normal">1892</span>
<span class="normal">1893</span>
<span class="normal">1894</span>
<span class="normal">1895</span>
<span class="normal">1896</span>
<span class="normal">1897</span>
<span class="normal">1898</span>
<span class="normal">1899</span>
<span class="normal">1900</span>
<span class="normal">1901</span>
<span class="normal">1902</span>
<span class="normal">1903</span>
<span class="normal">1904</span>
<span class="normal">1905</span>
<span class="normal">1906</span>
<span class="normal">1907</span>
<span class="normal">1908</span>
<span class="normal">1909</span>
<span class="normal">1910</span>
<span class="normal">1911</span>
<span class="normal">1912</span>
<span class="normal">1913</span>
<span class="normal">1914</span>
<span class="normal">1915</span>
<span class="normal">1916</span>
<span class="normal">1917</span>
<span class="normal">1918</span>
<span class="normal">1919</span>
<span class="normal">1920</span>
<span class="normal">1921</span>
<span class="normal">1922</span>
<span class="normal">1923</span>
<span class="normal">1924</span>
<span class="normal">1925</span>
<span class="normal">1926</span>
<span class="normal">1927</span>
<span class="normal">1928</span>
<span class="normal">1929</span>
<span class="normal">1930</span>
<span class="normal">1931</span>
<span class="normal">1932</span>
<span class="normal">1933</span>
<span class="normal">1934</span>
<span class="normal">1935</span>
<span class="normal">1936</span>
<span class="normal">1937</span>
<span class="normal">1938</span>
<span class="normal">1939</span>
<span class="normal">1940</span>
<span class="normal">1941</span>
<span class="normal">1942</span>
<span class="normal">1943</span>
<span class="normal">1944</span>
<span class="normal">1945</span>
<span class="normal">1946</span>
<span class="normal">1947</span>
<span class="normal">1948</span>
<span class="normal">1949</span>
<span class="normal">1950</span>
<span class="normal">1951</span>
<span class="normal">1952</span>
<span class="normal">1953</span>
<span class="normal">1954</span>
<span class="normal">1955</span>
<span class="normal">1956</span>
<span class="normal">1957</span>
<span class="normal">1958</span>
<span class="normal">1959</span>
<span class="normal">1960</span>
<span class="normal">1961</span>
<span class="normal">1962</span>
<span class="normal">1963</span>
<span class="normal">1964</span>
<span class="normal">1965</span>
<span class="normal">1966</span>
<span class="normal">1967</span>
<span class="normal">1968</span>
<span class="normal">1969</span>
<span class="normal">1970</span>
<span class="normal">1971</span>
<span class="normal">1972</span>
<span class="normal">1973</span>
<span class="normal">1974</span>
<span class="normal">1975</span>
<span class="normal">1976</span>
<span class="normal">1977</span>
<span class="normal">1978</span>
<span class="normal">1979</span>
<span class="normal">1980</span>
<span class="normal">1981</span>
<span class="normal">1982</span>
<span class="normal">1983</span>
<span class="normal">1984</span>
<span class="normal">1985</span>
<span class="normal">1986</span>
<span class="normal">1987</span>
<span class="normal">1988</span>
<span class="normal">1989</span>
<span class="normal">1990</span>
<span class="normal">1991</span>
<span class="normal">1992</span>
<span class="normal">1993</span>
<span class="normal">1994</span>
<span class="normal">1995</span>
<span class="normal">1996</span>
<span class="normal">1997</span>
<span class="normal">1998</span>
<span class="normal">1999</span>
<span class="normal">2000</span>
<span class="normal">2001</span>
<span class="normal">2002</span>
<span class="normal">2003</span>
<span class="normal">2004</span>
<span class="normal">2005</span>
<span class="normal">2006</span>
<span class="normal">2007</span>
<span class="normal">2008</span>
<span class="normal">2009</span>
<span class="normal">2010</span>
<span class="normal">2011</span>
<span class="normal">2012</span>
<span class="normal">2013</span>
<span class="normal">2014</span>
<span class="normal">2015</span>
<span class="normal">2016</span>
<span class="normal">2017</span>
<span class="normal">2018</span>
<span class="normal">2019</span>
<span class="normal">2020</span>
<span class="normal">2021</span>
<span class="normal">2022</span>
<span class="normal">2023</span>
<span class="normal">2024</span>
<span class="normal">2025</span>
<span class="normal">2026</span>
<span class="normal">2027</span>
<span class="normal">2028</span>
<span class="normal">2029</span>
<span class="normal">2030</span>
<span class="normal">2031</span>
<span class="normal">2032</span>
<span class="normal">2033</span>
<span class="normal">2034</span>
<span class="normal">2035</span>
<span class="normal">2036</span>
<span class="normal">2037</span>
<span class="normal">2038</span>
<span class="normal">2039</span>
<span class="normal">2040</span>
<span class="normal">2041</span>
<span class="normal">2042</span>
<span class="normal">2043</span>
<span class="normal">2044</span>
<span class="normal">2045</span>
<span class="normal">2046</span>
<span class="normal">2047</span>
<span class="normal">2048</span>
<span class="normal">2049</span>
<span class="normal">2050</span>
<span class="normal">2051</span>
<span class="normal">2052</span>
<span class="normal">2053</span>
<span class="normal">2054</span>
<span class="normal">2055</span>
<span class="normal">2056</span>
<span class="normal">2057</span>
<span class="normal">2058</span>
<span class="normal">2059</span>
<span class="normal">2060</span>
<span class="normal">2061</span>
<span class="normal">2062</span>
<span class="normal">2063</span>
<span class="normal">2064</span>
<span class="normal">2065</span>
<span class="normal">2066</span>
<span class="normal">2067</span>
<span class="normal">2068</span>
<span class="normal">2069</span>
<span class="normal">2070</span>
<span class="normal">2071</span>
<span class="normal">2072</span>
<span class="normal">2073</span>
<span class="normal">2074</span>
<span class="normal">2075</span>
<span class="normal">2076</span>
<span class="normal">2077</span>
<span class="normal">2078</span>
<span class="normal">2079</span>
<span class="normal">2080</span>
<span class="normal">2081</span>
<span class="normal">2082</span>
<span class="normal">2083</span>
<span class="normal">2084</span>
<span class="normal">2085</span>
<span class="normal">2086</span>
<span class="normal">2087</span>
<span class="normal">2088</span>
<span class="normal">2089</span>
<span class="normal">2090</span>
<span class="normal">2091</span>
<span class="normal">2092</span>
<span class="normal">2093</span>
<span class="normal">2094</span>
<span class="normal">2095</span>
<span class="normal">2096</span>
<span class="normal">2097</span>
<span class="normal">2098</span>
<span class="normal">2099</span>
<span class="normal">2100</span>
<span class="normal">2101</span>
<span class="normal">2102</span>
<span class="normal">2103</span>
<span class="normal">2104</span>
<span class="normal">2105</span>
<span class="normal">2106</span>
<span class="normal">2107</span>
<span class="normal">2108</span>
<span class="normal">2109</span>
<span class="normal">2110</span>
<span class="normal">2111</span>
<span class="normal">2112</span>
<span class="normal">2113</span>
<span class="normal">2114</span>
<span class="normal">2115</span>
<span class="normal">2116</span>
<span class="normal">2117</span>
<span class="normal">2118</span>
<span class="normal">2119</span>
<span class="normal">2120</span>
<span class="normal">2121</span>
<span class="normal">2122</span>
<span class="normal">2123</span>
<span class="normal">2124</span>
<span class="normal">2125</span>
<span class="normal">2126</span>
<span class="normal">2127</span>
<span class="normal">2128</span>
<span class="normal">2129</span>
<span class="normal">2130</span>
<span class="normal">2131</span>
<span class="normal">2132</span>
<span class="normal">2133</span>
<span class="normal">2134</span>
<span class="normal">2135</span>
<span class="normal">2136</span>
<span class="normal">2137</span>
<span class="normal">2138</span>
<span class="normal">2139</span>
<span class="normal">2140</span>
<span class="normal">2141</span>
<span class="normal">2142</span>
<span class="normal">2143</span>
<span class="normal">2144</span>
<span class="normal">2145</span>
<span class="normal">2146</span>
<span class="normal">2147</span>
<span class="normal">2148</span>
<span class="normal">2149</span>
<span class="normal">2150</span>
<span class="normal">2151</span>
<span class="normal">2152</span>
<span class="normal">2153</span>
<span class="normal">2154</span>
<span class="normal">2155</span>
<span class="normal">2156</span>
<span class="normal">2157</span>
<span class="normal">2158</span>
<span class="normal">2159</span>
<span class="normal">2160</span>
<span class="normal">2161</span>
<span class="normal">2162</span>
<span class="normal">2163</span>
<span class="normal">2164</span>
<span class="normal">2165</span>
<span class="normal">2166</span>
<span class="normal">2167</span>
<span class="normal">2168</span>
<span class="normal">2169</span>
<span class="normal">2170</span>
<span class="normal">2171</span>
<span class="normal">2172</span>
<span class="normal">2173</span>
<span class="normal">2174</span>
<span class="normal">2175</span>
<span class="normal">2176</span>
<span class="normal">2177</span>
<span class="normal">2178</span>
<span class="normal">2179</span>
<span class="normal">2180</span>
<span class="normal">2181</span>
<span class="normal">2182</span>
<span class="normal">2183</span>
<span class="normal">2184</span>
<span class="normal">2185</span>
<span class="normal">2186</span>
<span class="normal">2187</span>
<span class="normal">2188</span>
<span class="normal">2189</span>
<span class="normal">2190</span>
<span class="normal">2191</span>
<span class="normal">2192</span>
<span class="normal">2193</span>
<span class="normal">2194</span>
<span class="normal">2195</span>
<span class="normal">2196</span>
<span class="normal">2197</span>
<span class="normal">2198</span>
<span class="normal">2199</span>
<span class="normal">2200</span>
<span class="normal">2201</span>
<span class="normal">2202</span>
<span class="normal">2203</span>
<span class="normal">2204</span>
<span class="normal">2205</span>
<span class="normal">2206</span>
<span class="normal">2207</span>
<span class="normal">2208</span>
<span class="normal">2209</span>
<span class="normal">2210</span>
<span class="normal">2211</span>
<span class="normal">2212</span>
<span class="normal">2213</span>
<span class="normal">2214</span>
<span class="normal">2215</span>
<span class="normal">2216</span>
<span class="normal">2217</span>
<span class="normal">2218</span>
<span class="normal">2219</span>
<span class="normal">2220</span>
<span class="normal">2221</span>
<span class="normal">2222</span>
<span class="normal">2223</span>
<span class="normal">2224</span>
<span class="normal">2225</span>
<span class="normal">2226</span>
<span class="normal">2227</span>
<span class="normal">2228</span>
<span class="normal">2229</span>
<span class="normal">2230</span>
<span class="normal">2231</span>
<span class="normal">2232</span>
<span class="normal">2233</span>
<span class="normal">2234</span>
<span class="normal">2235</span>
<span class="normal">2236</span>
<span class="normal">2237</span>
<span class="normal">2238</span>
<span class="normal">2239</span>
<span class="normal">2240</span>
<span class="normal">2241</span>
<span class="normal">2242</span>
<span class="normal">2243</span>
<span class="normal">2244</span>
<span class="normal">2245</span>
<span class="normal">2246</span>
<span class="normal">2247</span>
<span class="normal">2248</span>
<span class="normal">2249</span>
<span class="normal">2250</span>
<span class="normal">2251</span>
<span class="normal">2252</span>
<span class="normal">2253</span>
<span class="normal">2254</span>
<span class="normal">2255</span>
<span class="normal">2256</span>
<span class="normal">2257</span>
<span class="normal">2258</span>
<span class="normal">2259</span>
<span class="normal">2260</span>
<span class="normal">2261</span>
<span class="normal">2262</span>
<span class="normal">2263</span>
<span class="normal">2264</span>
<span class="normal">2265</span>
<span class="normal">2266</span>
<span class="normal">2267</span>
<span class="normal">2268</span>
<span class="normal">2269</span>
<span class="normal">2270</span>
<span class="normal">2271</span>
<span class="normal">2272</span>
<span class="normal">2273</span>
<span class="normal">2274</span>
<span class="normal">2275</span>
<span class="normal">2276</span>
<span class="normal">2277</span>
<span class="normal">2278</span>
<span class="normal">2279</span>
<span class="normal">2280</span>
<span class="normal">2281</span>
<span class="normal">2282</span>
<span class="normal">2283</span>
<span class="normal">2284</span>
<span class="normal">2285</span>
<span class="normal">2286</span>
<span class="normal">2287</span>
<span class="normal">2288</span>
<span class="normal">2289</span>
<span class="normal">2290</span>
<span class="normal">2291</span>
<span class="normal">2292</span>
<span class="normal">2293</span>
<span class="normal">2294</span>
<span class="normal">2295</span>
<span class="normal">2296</span>
<span class="normal">2297</span>
<span class="normal">2298</span>
<span class="normal">2299</span>
<span class="normal">2300</span>
<span class="normal">2301</span>
<span class="normal">2302</span>
<span class="normal">2303</span>
<span class="normal">2304</span>
<span class="normal">2305</span>
<span class="normal">2306</span>
<span class="normal">2307</span>
<span class="normal">2308</span>
<span class="normal">2309</span>
<span class="normal">2310</span>
<span class="normal">2311</span>
<span class="normal">2312</span>
<span class="normal">2313</span>
<span class="normal">2314</span>
<span class="normal">2315</span>
<span class="normal">2316</span>
<span class="normal">2317</span>
<span class="normal">2318</span>
<span class="normal">2319</span>
<span class="normal">2320</span>
<span class="normal">2321</span>
<span class="normal">2322</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">SpotOptim</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;SPOT optimizer compatible with scipy.optimize interface.</span>

<span class="sd">    Args:</span>
<span class="sd">        fun (callable): Objective function to minimize. Should accept array of shape (n_samples, n_features).</span>
<span class="sd">        bounds (list of tuple): Bounds for each dimension as [(low, high), ...].</span>
<span class="sd">        max_iter (int, optional): Maximum number of total function evaluations (including initial design).</span>
<span class="sd">            For example, max_iter=30 with n_initial=10 will perform 10 initial evaluations plus</span>
<span class="sd">            20 sequential optimization iterations. Defaults to 20.</span>
<span class="sd">        n_initial (int, optional): Number of initial design points. Defaults to 10.</span>
<span class="sd">        surrogate (object, optional): Surrogate model. Defaults to Gaussian Process with Matern kernel.</span>
<span class="sd">        acquisition (str, optional): Acquisition function (&#39;ei&#39;, &#39;y&#39;, &#39;pi&#39;). Defaults to &#39;ei&#39;.</span>
<span class="sd">        var_type (list of str, optional): Variable types for each dimension. Supported types:</span>
<span class="sd">            - &#39;float&#39;: Python floats, continuous optimization (no rounding)</span>
<span class="sd">            - &#39;int&#39;: Python int, float values will be rounded to integers</span>
<span class="sd">            - &#39;factor&#39;: Unordered categorical data, internally mapped to int values</span>
<span class="sd">              (e.g., &quot;red&quot;-&gt;0, &quot;green&quot;-&gt;1, etc.)</span>
<span class="sd">            Defaults to None (which sets all dimensions to &#39;float&#39;).</span>
<span class="sd">        var_name (list of str, optional): Variable names for each dimension.</span>
<span class="sd">            If None, uses default names [&#39;x0&#39;, &#39;x1&#39;, &#39;x2&#39;, ...]. Defaults to None.</span>
<span class="sd">        tolerance_x (float, optional): Minimum distance between points. Defaults to np.sqrt(np.spacing(1))</span>
<span class="sd">        max_time (float, optional): Maximum runtime in minutes. If np.inf (default), no time limit.</span>
<span class="sd">            The optimization terminates when either max_iter evaluations are reached OR max_time</span>
<span class="sd">            minutes have elapsed, whichever comes first. Defaults to np.inf.</span>
<span class="sd">        repeats_initial (int, optional): Number of times to evaluate each initial design point.</span>
<span class="sd">            Useful for noisy objective functions. If &gt; 1, noise handling is activated and</span>
<span class="sd">            statistics (mean, variance) are tracked. Defaults to 1.</span>
<span class="sd">        repeats_surrogate (int, optional): Number of times to evaluate each surrogate-suggested point.</span>
<span class="sd">            Useful for noisy objective functions. If &gt; 1, noise handling is activated and</span>
<span class="sd">            statistics (mean, variance) are tracked. Defaults to 1.</span>
<span class="sd">        ocba_delta (int, optional): Number of additional evaluations to allocate using Optimal Computing</span>
<span class="sd">            Budget Allocation (OCBA) when noise handling is active. OCBA determines which existing</span>
<span class="sd">            design points should be re-evaluated to best distinguish between alternatives. Only used</span>
<span class="sd">            when noise=True (repeats &gt; 1) and ocba_delta &gt; 0. Requires at least 3 design points with</span>
<span class="sd">            variance information. Defaults to 0 (no OCBA).</span>
<span class="sd">        tensorboard_log (bool, optional): Enable TensorBoard logging. If True, optimization metrics</span>
<span class="sd">            and hyperparameters are logged to TensorBoard. View logs by running:</span>
<span class="sd">            `tensorboard --logdir=&lt;tensorboard_path&gt;` in a separate terminal. Defaults to False.</span>
<span class="sd">        tensorboard_path (str, optional): Path for TensorBoard log files. If None and tensorboard_log</span>
<span class="sd">            is True, creates a default path: runs/spotoptim_YYYYMMDD_HHMMSS. Defaults to None.</span>
<span class="sd">        tensorboard_clean (bool, optional): If True, removes all old TensorBoard log directories from</span>
<span class="sd">            the &#39;runs&#39; folder before starting optimization. Use with caution as this permanently</span>
<span class="sd">            deletes all subdirectories in &#39;runs&#39;. Defaults to False.</span>
<span class="sd">        fun_mo2so (callable, optional): Function to convert multi-objective values to single-objective.</span>
<span class="sd">            Takes an array of shape (n_samples, n_objectives) and returns array of shape (n_samples,).</span>
<span class="sd">            If None and objective function returns multi-objective values, uses first objective.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        seed (int, optional): Random seed for reproducibility. Defaults to None.</span>
<span class="sd">        verbose (bool, optional): Print progress information. Defaults to False.</span>
<span class="sd">        warnings_filter (str, optional): Filter for warnings. One of &quot;error&quot;, &quot;ignore&quot;, &quot;always&quot;, &quot;all&quot;,</span>
<span class="sd">            &quot;default&quot;, &quot;module&quot;, or &quot;once&quot;. Defaults to &quot;ignore&quot;.</span>
<span class="sd">        max_surrogate_points (int, optional): Maximum number of points to use for surrogate model fitting.</span>
<span class="sd">            If None, all points are used. If the number of evaluated points exceeds this limit,</span>
<span class="sd">            a subset is selected using the selection method. Defaults to None.</span>
<span class="sd">        selection_method (str, optional): Method for selecting points when max_surrogate_points is exceeded.</span>
<span class="sd">            Options: &#39;distant&#39; (Select points that are distant from each other via K-means clustering) or</span>
<span class="sd">            &#39;best&#39; (Select all points from the cluster with the best mean objective value).</span>
<span class="sd">            Defaults to &#39;distant&#39;.</span>
<span class="sd">        acquisition_failure_strategy (str, optional): Strategy for handling acquisition function failures.</span>
<span class="sd">            Options: &#39;random&#39; (space-filling design via Latin Hypercube Sampling) or</span>
<span class="sd">            &#39;mm&#39; (Morris-Mitchell phi minimizing point for maximal distance from existing points).</span>
<span class="sd">            Defaults to &#39;random&#39;.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        X_ (ndarray): All evaluated points, shape (n_samples, n_features).</span>
<span class="sd">        y_ (ndarray): Function values at X_, shape (n_samples,). For multi-objective problems,</span>
<span class="sd">            these are the converted single-objective values.</span>
<span class="sd">        y_mo (ndarray or None): Multi-objective function values, shape (n_samples, n_objectives).</span>
<span class="sd">            None for single-objective problems.</span>
<span class="sd">        best_x_ (ndarray): Best point found, shape (n_features,).</span>
<span class="sd">        best_y_ (float): Best function value found.</span>
<span class="sd">        n_iter_ (int): Number of iterations performed.</span>
<span class="sd">        counter (int): Total number of function evaluations.</span>
<span class="sd">        success_rate (float): Rolling success rate over the last window_size evaluations.</span>
<span class="sd">            A success is counted when a new evaluation improves upon the best value found so far.</span>
<span class="sd">        warnings_filter (str): Filter for warnings during optimization.</span>
<span class="sd">        max_surrogate_points (int or None): Maximum number of points for surrogate fitting.</span>
<span class="sd">        selection_method (str): Point selection method.</span>
<span class="sd">        acquisition_failure_strategy (str): Strategy for handling acquisition failures (&#39;random&#39; or &#39;mm&#39;).</span>
<span class="sd">        noise (bool): True if noise handling is active (repeats &gt; 1).</span>
<span class="sd">        mean_X (ndarray or None): Aggregated unique design points (if noise=True).</span>
<span class="sd">        mean_y (ndarray or None): Mean y values per design point (if noise=True).</span>
<span class="sd">        var_y (ndarray or None): Variance of y values per design point (if noise=True).</span>
<span class="sd">        min_mean_X (ndarray or None): X value of best mean y (if noise=True).</span>
<span class="sd">        min_mean_y (float or None): Best mean y value (if noise=True).</span>
<span class="sd">        min_var_y (float or None): Variance of best mean y (if noise=True).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; def objective(X):</span>
<span class="sd">        ...     return np.sum(X**2, axis=1)</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # Example 1: Basic usage (deterministic function)</span>
<span class="sd">        &gt;&gt;&gt; bounds = [(-5, 5), (-5, 5)]</span>
<span class="sd">        &gt;&gt;&gt; optimizer = SpotOptim(fun=objective, bounds=bounds, max_iter=10, n_initial=5, verbose=True)</span>
<span class="sd">        &gt;&gt;&gt; result = optimizer.optimize()</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Best x:&quot;, result.x)</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Best f(x):&quot;, result.fun)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 2: With custom variable names</span>
<span class="sd">        &gt;&gt;&gt; optimizer = SpotOptim(</span>
<span class="sd">        ...     fun=objective,</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...     var_name=[&quot;param1&quot;, &quot;param2&quot;],</span>
<span class="sd">        ...     max_iter=10,</span>
<span class="sd">        ...     n_initial=5</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; result = optimizer.optimize()</span>
<span class="sd">        &gt;&gt;&gt; optimizer.plot_surrogate()  # Uses custom names in plot labels</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 3: Noisy function with repeated evaluations</span>
<span class="sd">        &gt;&gt;&gt; def noisy_objective(X):</span>
<span class="sd">        ...     import numpy as np</span>
<span class="sd">        ...     base = np.sum(X**2, axis=1)</span>
<span class="sd">        ...     noise = np.random.normal(0, 0.1, size=base.shape)</span>
<span class="sd">        ...     return base + noise</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; optimizer = SpotOptim(</span>
<span class="sd">        ...     fun=noisy_objective,</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...     max_iter=30,</span>
<span class="sd">        ...     n_initial=10,</span>
<span class="sd">        ...     repeats_initial=3,      # Evaluate each initial point 3 times</span>
<span class="sd">        ...     repeats_surrogate=2,    # Evaluate each new point 2 times</span>
<span class="sd">        ...     seed=42,                # For reproducibility</span>
<span class="sd">        ...     verbose=True</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; result = optimizer.optimize()</span>
<span class="sd">        &gt;&gt;&gt; # Access noise statistics</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Unique design points:&quot;, optimizer.mean_X.shape[0])</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Best mean value:&quot;, optimizer.min_mean_y)</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Variance at best point:&quot;, optimizer.min_var_y)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 4: Noisy function with OCBA (Optimal Computing Budget Allocation)</span>
<span class="sd">        &gt;&gt;&gt; optimizer_ocba = SpotOptim(</span>
<span class="sd">        ...     fun=noisy_objective,</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...     max_iter=50,</span>
<span class="sd">        ...     n_initial=10,</span>
<span class="sd">        ...     repeats_initial=2,      # Initial repeats</span>
<span class="sd">        ...     repeats_surrogate=1,    # Surrogate repeats</span>
<span class="sd">        ...     ocba_delta=3,           # Allocate 3 additional evaluations per iteration</span>
<span class="sd">        ...     seed=42,</span>
<span class="sd">        ...     verbose=True</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; result = optimizer_ocba.optimize()</span>
<span class="sd">        &gt;&gt;&gt; # OCBA intelligently re-evaluates promising points to reduce uncertainty</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Total evaluations:&quot;, result.nfev)</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Unique design points:&quot;, optimizer_ocba.mean_X.shape[0])</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Best mean value:&quot;, optimizer.min_mean_y)</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Variance at best point:&quot;, optimizer.min_var_y)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 5: With TensorBoard logging</span>
<span class="sd">        &gt;&gt;&gt; optimizer_tb = SpotOptim(</span>
<span class="sd">        ...     fun=objective,</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...     max_iter=30,</span>
<span class="sd">        ...     n_initial=10,</span>
<span class="sd">        ...     tensorboard_log=True,   # Enable TensorBoard</span>
<span class="sd">        ...     tensorboard_path=&quot;runs/my_optimization&quot;,  # Optional custom path</span>
<span class="sd">        ...     verbose=True</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; result = optimizer_tb.optimize()</span>
<span class="sd">        &gt;&gt;&gt; # View logs in browser: tensorboard --logdir=runs/my_optimization</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Logs saved to:&quot;, optimizer_tb.tensorboard_path)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">fun</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
        <span class="n">bounds</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
        <span class="n">n_initial</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">surrogate</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">object</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">acquisition</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;ei&quot;</span><span class="p">,</span>
        <span class="n">var_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">var_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tolerance_x</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_time</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span>
        <span class="n">repeats_initial</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">repeats_surrogate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">ocba_delta</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">tensorboard_log</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">tensorboard_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tensorboard_clean</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">fun_mo2so</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">warnings_filter</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;ignore&quot;</span><span class="p">,</span>
        <span class="n">max_surrogate_points</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">selection_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;distant&quot;</span><span class="p">,</span>
        <span class="n">acquisition_failure_strategy</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;random&quot;</span><span class="p">,</span>
    <span class="p">):</span>

        <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="n">warnings_filter</span><span class="p">)</span>

        <span class="c1"># small value, converted to float</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">spacing</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">tolerance_x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tolerance_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tolerance_x</span> <span class="o">=</span> <span class="n">tolerance_x</span>

        <span class="c1"># Validate parameters</span>
        <span class="k">if</span> <span class="n">max_iter</span> <span class="o">&lt;</span> <span class="n">n_initial</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;max_iter (</span><span class="si">{</span><span class="n">max_iter</span><span class="si">}</span><span class="s2">) must be &gt;= n_initial (</span><span class="si">{</span><span class="n">n_initial</span><span class="si">}</span><span class="s2">). &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;max_iter represents the total function evaluation budget including initial design.&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">fun</span> <span class="o">=</span> <span class="n">fun</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span> <span class="o">=</span> <span class="n">bounds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_initial</span> <span class="o">=</span> <span class="n">n_initial</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span> <span class="o">=</span> <span class="n">surrogate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">acquisition</span> <span class="o">=</span> <span class="n">acquisition</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span> <span class="o">=</span> <span class="n">var_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span> <span class="o">=</span> <span class="n">var_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_time</span> <span class="o">=</span> <span class="n">max_time</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">repeats_initial</span> <span class="o">=</span> <span class="n">repeats_initial</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">repeats_surrogate</span> <span class="o">=</span> <span class="n">repeats_surrogate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ocba_delta</span> <span class="o">=</span> <span class="n">ocba_delta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_log</span> <span class="o">=</span> <span class="n">tensorboard_log</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_path</span> <span class="o">=</span> <span class="n">tensorboard_path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_clean</span> <span class="o">=</span> <span class="n">tensorboard_clean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fun_mo2so</span> <span class="o">=</span> <span class="n">fun_mo2so</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_surrogate_points</span> <span class="o">=</span> <span class="n">max_surrogate_points</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">selection_method</span> <span class="o">=</span> <span class="n">selection_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_failure_strategy</span> <span class="o">=</span> <span class="n">acquisition_failure_strategy</span>

        <span class="c1"># Determine if noise handling is active</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise</span> <span class="o">=</span> <span class="p">(</span><span class="n">repeats_initial</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">repeats_surrogate</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Derived attributes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">bounds</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lower</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">bounds</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">upper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">bounds</span><span class="p">])</span>

        <span class="c1"># Default variable types</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;float&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span>

        <span class="c1"># Default variable names</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">)]</span>

        <span class="c1"># Dimension reduction: backup original bounds and identify fixed dimensions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setup_dimension_reduction</span><span class="p">()</span>

        <span class="c1"># Initialize surrogate if not provided</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">kernel</span> <span class="o">=</span> <span class="n">ConstantKernel</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="p">(</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e3</span><span class="p">))</span> <span class="o">*</span> <span class="n">Matern</span><span class="p">(</span>
                <span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">length_scale_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">1e-2</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">),</span> <span class="n">nu</span><span class="o">=</span><span class="mf">2.5</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span>
                <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span>
                <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                <span class="n">normalize_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Design generator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lhs_sampler</span> <span class="o">=</span> <span class="n">LatinHypercube</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="c1"># Storage for results</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_mo</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Multi-objective values (if applicable)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Noise handling attributes (initialized in update_stats if noise=True)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_X</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_y</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">var_y</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_X</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_y</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_var_y</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_X</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_y</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Success rate tracking (similar to Spot class)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">success_rate</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">success_counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">=</span> <span class="mi">100</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_success_history</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Clean old TensorBoard logs if requested</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_clean_tensorboard_logs</span><span class="p">()</span>

        <span class="c1"># Initialize TensorBoard writer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_tensorboard_writer</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_setup_dimension_reduction</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set up dimension reduction by identifying fixed dimensions.</span>

<span class="sd">        This method identifies dimensions where lower and upper bounds are equal,</span>
<span class="sd">        indicating fixed (constant) variables. It stores:</span>
<span class="sd">        - Original bounds and metadata in `all_*` attributes</span>
<span class="sd">        - Boolean mask of fixed dimensions in `ident`</span>
<span class="sd">        - Reduced bounds, types, and names for optimization</span>
<span class="sd">        - `red_dim` flag indicating if reduction occurred</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Backup original values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_lower</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_upper</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upper</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_var_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="c1"># Identify fixed dimensions (lower == upper)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ident</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upper</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>

        <span class="c1"># Check if any dimension is fixed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span><span class="p">:</span>
            <span class="c1"># Reduce bounds to only varying dimensions</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lower</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">[</span><span class="o">~</span><span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">upper</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upper</span><span class="p">[</span><span class="o">~</span><span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">]</span>

            <span class="c1"># Update dimension count</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="o">.</span><span class="n">size</span>

            <span class="c1"># Reduce variable types and names</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">vtype</span>
                <span class="k">for</span> <span class="n">vtype</span><span class="p">,</span> <span class="n">fixed</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_var_type</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">fixed</span>
            <span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">vname</span>
                <span class="k">for</span> <span class="n">vname</span><span class="p">,</span> <span class="n">fixed</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">fixed</span>
            <span class="p">]</span>

            <span class="c1"># Update bounds list for reduced dimensions</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span> <span class="o">=</span> <span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">upper</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">)]</span>

            <span class="c1"># Recreate LHS sampler with reduced dimensions</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lhs_sampler</span> <span class="o">=</span> <span class="n">LatinHypercube</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">to_all_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_red</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Expand reduced-dimensional points to full-dimensional representation.</span>

<span class="sd">        This method restores points from the reduced optimization space to the</span>
<span class="sd">        full-dimensional space by inserting fixed values for constant dimensions.</span>

<span class="sd">        Args:</span>
<span class="sd">            X_red (ndarray): Points in reduced space, shape (n_samples, n_reduced_dims).</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Points in full space, shape (n_samples, n_original_dims).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; # Create problem with one fixed dimension</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (2, 2), (-5, 5)],  # x1 is fixed at 2</span>
<span class="sd">            ...     max_iter=1,</span>
<span class="sd">            ...     n_initial=3</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; X_red = np.array([[1.0, 3.0], [2.0, 4.0]])  # Only x0 and x2</span>
<span class="sd">            &gt;&gt;&gt; X_full = opt.to_all_dim(X_red)</span>
<span class="sd">            &gt;&gt;&gt; X_full.shape</span>
<span class="sd">            (2, 3)</span>
<span class="sd">            &gt;&gt;&gt; X_full[:, 1]  # Middle dimension should be 2.0</span>
<span class="sd">            array([2., 2.])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span><span class="p">:</span>
            <span class="c1"># No reduction occurred, return as-is</span>
            <span class="k">return</span> <span class="n">X_red</span>

        <span class="c1"># Number of samples and full dimensions</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X_red</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">n_full_dims</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">)</span>

        <span class="c1"># Initialize full-dimensional array</span>
        <span class="n">X_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_full_dims</span><span class="p">))</span>

        <span class="c1"># Track index in reduced array</span>
        <span class="n">red_idx</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Fill in values dimension by dimension</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_full_dims</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                <span class="c1"># Fixed dimension: use stored value</span>
                <span class="n">X_full</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_lower</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Varying dimension: use value from reduced array</span>
                <span class="n">X_full</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_red</span><span class="p">[:,</span> <span class="n">red_idx</span><span class="p">]</span>
                <span class="n">red_idx</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">X_full</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">to_red_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_full</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reduce full-dimensional points to optimization space.</span>

<span class="sd">        This method removes fixed dimensions from full-dimensional points,</span>
<span class="sd">        extracting only the varying dimensions used in optimization.</span>

<span class="sd">        Args:</span>
<span class="sd">            X_full (ndarray): Points in full space, shape (n_samples, n_original_dims).</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Points in reduced space, shape (n_samples, n_reduced_dims).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; # Create problem with one fixed dimension</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (2, 2), (-5, 5)],  # x1 is fixed at 2</span>
<span class="sd">            ...     max_iter=1,</span>
<span class="sd">            ...     n_initial=3</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; X_full = np.array([[1.0, 2.0, 3.0], [4.0, 2.0, 5.0]])</span>
<span class="sd">            &gt;&gt;&gt; X_red = opt.to_red_dim(X_full)</span>
<span class="sd">            &gt;&gt;&gt; X_red.shape</span>
<span class="sd">            (2, 2)</span>
<span class="sd">            &gt;&gt;&gt; np.array_equal(X_red, np.array([[1.0, 3.0], [4.0, 5.0]]))</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span><span class="p">:</span>
            <span class="c1"># No reduction occurred, return as-is</span>
            <span class="k">return</span> <span class="n">X_full</span>

        <span class="c1"># Select only non-fixed dimensions</span>
        <span class="k">return</span> <span class="n">X_full</span><span class="p">[:,</span> <span class="o">~</span><span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_aggregate_mean_var</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Aggregate X and y values to compute mean and variance per group.</span>

<span class="sd">        For repeated evaluations at the same design point, this method computes</span>
<span class="sd">        the mean function value and variance (using population variance, ddof=0).</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): Design points, shape (n_samples, n_features).</span>
<span class="sd">            y (ndarray): Function values, shape (n_samples,).</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: A tuple containing:</span>
<span class="sd">                - X_agg (ndarray): Unique design points, shape (n_groups, n_features)</span>
<span class="sd">                - y_mean (ndarray): Mean y values per group, shape (n_groups,)</span>
<span class="sd">                - y_var (ndarray): Variance of y values per group, shape (n_groups,)</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...                 bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...                 repeats_initial=2)</span>
<span class="sd">            &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2]])</span>
<span class="sd">            &gt;&gt;&gt; y = np.array([1, 2, 3])</span>
<span class="sd">            &gt;&gt;&gt; X_agg, y_mean, y_var = opt._aggregate_mean_var(X, y)</span>
<span class="sd">            &gt;&gt;&gt; X_agg.shape</span>
<span class="sd">            (2, 2)</span>
<span class="sd">            &gt;&gt;&gt; y_mean</span>
<span class="sd">            array([2., 2.])</span>
<span class="sd">            &gt;&gt;&gt; y_var</span>
<span class="sd">            array([1., 0.])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Input validation</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span> <span class="ow">or</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid input shapes for _aggregate_mean_var&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>

        <span class="c1"># Find unique rows and group indices</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">unique_idx</span><span class="p">,</span> <span class="n">inverse_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">return_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

        <span class="n">X_agg</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">unique_idx</span><span class="p">]</span>

        <span class="c1"># Calculate mean and variance for each group</span>
        <span class="n">n_groups</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_idx</span><span class="p">)</span>
        <span class="n">y_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_groups</span><span class="p">)</span>
        <span class="n">y_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_groups</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_groups</span><span class="p">):</span>
            <span class="n">group_mask</span> <span class="o">=</span> <span class="n">inverse_idx</span> <span class="o">==</span> <span class="n">i</span>
            <span class="n">group_y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">group_mask</span><span class="p">]</span>
            <span class="n">y_mean</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">group_y</span><span class="p">)</span>
            <span class="c1"># Use population variance (ddof=0) for consistency with Spot</span>
            <span class="n">y_var</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">group_y</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">X_agg</span><span class="p">,</span> <span class="n">y_mean</span><span class="p">,</span> <span class="n">y_var</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">update_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update optimization statistics.</span>

<span class="sd">        Updates:</span>
<span class="sd">        1. `min_y`: Minimum y value found so far</span>
<span class="sd">        2. `min_X`: X value corresponding to minimum y</span>
<span class="sd">        3. `counter`: Total number of function evaluations</span>

<span class="sd">        Note: `success_rate` is updated separately via `_update_success_rate()` method,</span>
<span class="sd">        which is called after each batch of function evaluations.</span>

<span class="sd">        If `noise` is True (repeats &gt; 1), additionally computes:</span>
<span class="sd">        1. `mean_X`: Unique design points (aggregated from repeated evaluations)</span>
<span class="sd">        2. `mean_y`: Mean y values per design point</span>
<span class="sd">        3. `var_y`: Variance of y values per design point</span>
<span class="sd">        4. `min_mean_X`: X value of the best mean y value</span>
<span class="sd">        5. `min_mean_y`: Best mean y value</span>
<span class="sd">        6. `min_var_y`: Variance of the best mean y value</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; # Without noise</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...                 bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...                 max_iter=10, n_initial=5)</span>
<span class="sd">            &gt;&gt;&gt; opt.X_ = np.array([[1, 2], [3, 4], [0, 1]])</span>
<span class="sd">            &gt;&gt;&gt; opt.y_ = np.array([5.0, 25.0, 1.0])</span>
<span class="sd">            &gt;&gt;&gt; opt.update_stats()</span>
<span class="sd">            &gt;&gt;&gt; opt.min_y</span>
<span class="sd">            1.0</span>
<span class="sd">            &gt;&gt;&gt; opt.min_X</span>
<span class="sd">            array([0, 1])</span>
<span class="sd">            &gt;&gt;&gt; opt.counter</span>
<span class="sd">            3</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # With noise</span>
<span class="sd">            &gt;&gt;&gt; opt_noise = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...                       bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...                       repeats_initial=2)</span>
<span class="sd">            &gt;&gt;&gt; opt_noise.X_ = np.array([[1, 2], [1, 2], [3, 4]])</span>
<span class="sd">            &gt;&gt;&gt; opt_noise.y_ = np.array([4.0, 6.0, 25.0])</span>
<span class="sd">            &gt;&gt;&gt; opt_noise.update_stats()</span>
<span class="sd">            &gt;&gt;&gt; opt_noise.min_y</span>
<span class="sd">            4.0</span>
<span class="sd">            &gt;&gt;&gt; opt_noise.mean_y</span>
<span class="sd">            array([ 5., 25.])</span>
<span class="sd">            &gt;&gt;&gt; opt_noise.var_y</span>
<span class="sd">            array([1., 0.])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="c1"># Basic stats</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>

        <span class="c1"># Aggregated stats for noisy functions</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mean_X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_mean_var</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span>
            <span class="p">)</span>
            <span class="c1"># X value of the best mean y value so far</span>
            <span class="n">best_mean_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean_y</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_X</span><span class="p">[</span><span class="n">best_mean_idx</span><span class="p">]</span>
            <span class="c1"># Best mean y value so far</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_y</span><span class="p">[</span><span class="n">best_mean_idx</span><span class="p">]</span>
            <span class="c1"># Variance of the best mean y value so far</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">min_var_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_y</span><span class="p">[</span><span class="n">best_mean_idx</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_update_success_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_new</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update the rolling success rate of the optimization process.</span>

<span class="sd">        A success is counted only if the new value is better (smaller) than the best</span>
<span class="sd">        found y value so far. The success rate is calculated based on the last</span>
<span class="sd">        `window_size` successes.</span>

<span class="sd">        Important: This method should be called BEFORE updating self.y_ to correctly</span>
<span class="sd">        track improvements against the previous best value.</span>

<span class="sd">        Args:</span>
<span class="sd">            y_new (ndarray): The new function values to consider for the success rate update.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...                 bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...                 max_iter=10, n_initial=5)</span>
<span class="sd">            &gt;&gt;&gt; opt.X_ = np.array([[1, 2], [3, 4], [0, 1]])</span>
<span class="sd">            &gt;&gt;&gt; opt.y_ = np.array([5.0, 3.0, 2.0])</span>
<span class="sd">            &gt;&gt;&gt; opt._update_success_rate(np.array([1.5, 2.5]))</span>
<span class="sd">            &gt;&gt;&gt; opt.success_rate &gt; 0</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Initialize or update the rolling history of successes (1 for success, 0 for failure)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_success_history&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_success_history</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_success_history</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Get the best y value so far (before adding new evaluations)</span>
        <span class="c1"># Since this is called BEFORE updating self.y_, we can safely use min(self.y_)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">best_y_before</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># This is the initial design, no previous best</span>
            <span class="n">best_y_before</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>

        <span class="n">successes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">current_best</span> <span class="o">=</span> <span class="n">best_y_before</span>

        <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">y_new</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">val</span> <span class="o">&lt;</span> <span class="n">current_best</span><span class="p">:</span>
                <span class="n">successes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">current_best</span> <span class="o">=</span> <span class="n">val</span>  <span class="c1"># Update for next comparison within this batch</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">successes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Add new successes to the history</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_success_history</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">successes</span><span class="p">)</span>
        <span class="c1"># Keep only the last window_size successes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_success_history</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_success_history</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="p">:]</span>

        <span class="c1"># Calculate the rolling success rate</span>
        <span class="n">window_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_success_history</span><span class="p">)</span>
        <span class="n">num_successes</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_success_history</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">success_rate</span> <span class="o">=</span> <span class="n">num_successes</span> <span class="o">/</span> <span class="n">window_size</span> <span class="k">if</span> <span class="n">window_size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.0</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_success_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the current success rate of the optimization process.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: The current success rate.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda x: x,</span>
<span class="sd">            ...                 bounds=[(-5, 5), (-5, 5)])</span>
<span class="sd">            &gt;&gt;&gt; print(opt._get_success_rate())</span>
<span class="sd">            0.0</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;success_rate&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span> <span class="ow">or</span> <span class="mf">0.0</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_clean_tensorboard_logs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Clean old TensorBoard log directories from the runs folder.</span>

<span class="sd">        Removes all subdirectories in the &#39;runs&#39; directory if tensorboard_clean is True.</span>
<span class="sd">        This is useful for removing old logs before starting a new optimization run.</span>

<span class="sd">        Warning:</span>
<span class="sd">            This will permanently delete all subdirectories in the &#39;runs&#39; folder.</span>
<span class="sd">            Use with caution.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     tensorboard_log=True,</span>
<span class="sd">            ...     tensorboard_clean=True</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # Old logs in &#39;runs&#39; will be removed before optimization starts</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_clean</span><span class="p">:</span>
            <span class="n">runs_dir</span> <span class="o">=</span> <span class="s2">&quot;runs&quot;</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">runs_dir</span><span class="p">)</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">runs_dir</span><span class="p">):</span>
                <span class="c1"># Get all subdirectories in runs</span>
                <span class="n">subdirs</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">runs_dir</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">runs_dir</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">runs_dir</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>
                <span class="p">]</span>

                <span class="k">if</span> <span class="n">subdirs</span><span class="p">:</span>
                    <span class="n">removed_count</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="k">for</span> <span class="n">subdir</span> <span class="ow">in</span> <span class="n">subdirs</span><span class="p">:</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">subdir</span><span class="p">)</span>
                            <span class="n">removed_count</span> <span class="o">+=</span> <span class="mi">1</span>
                            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Removed old TensorBoard logs: </span><span class="si">{</span><span class="n">subdir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: Could not remove </span><span class="si">{</span><span class="n">subdir</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="ow">and</span> <span class="n">removed_count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Cleaned </span><span class="si">{</span><span class="n">removed_count</span><span class="si">}</span><span class="s2"> old TensorBoard log director</span><span class="si">{</span><span class="s1">&#39;y&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">removed_count</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;ies&#39;</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No old TensorBoard logs to clean in &#39;runs&#39; directory&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&#39;runs&#39; directory does not exist, nothing to clean&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_init_tensorboard_writer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize TensorBoard SummaryWriter if logging is enabled.</span>

<span class="sd">        Creates a unique log directory based on timestamp if tensorboard_log is True.</span>
<span class="sd">        The log directory will be in the format: runs/spotoptim_YYYYMMDD_HHMMSS</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     tensorboard_log=True</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; hasattr(opt, &#39;tb_writer&#39;)</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_log</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Create default path with timestamp</span>
                <span class="n">timestamp</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y%m</span><span class="si">%d</span><span class="s2">_%H%M%S&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;runs/spotoptim_</span><span class="si">{</span><span class="n">timestamp</span><span class="si">}</span><span class="s2">&quot;</span>

            <span class="c1"># Create directory if it doesn&#39;t exist</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_path</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TensorBoard logging enabled: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TensorBoard logging disabled&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_write_tensorboard_scalars</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Write scalar metrics to TensorBoard.</span>

<span class="sd">        Logs the following metrics:</span>
<span class="sd">        - Best y value found so far (min_y)</span>
<span class="sd">        - Last y value evaluated</span>
<span class="sd">        - Best X coordinates (for each dimension)</span>
<span class="sd">        - If noise=True: also logs mean values and variance</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="n">step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span>
        <span class="n">y_last</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span><span class="p">:</span>
            <span class="c1"># Non-noisy optimization</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">add_scalars</span><span class="p">(</span>
                <span class="s2">&quot;y_values&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;min&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_y</span><span class="p">,</span> <span class="s2">&quot;last&quot;</span><span class="p">:</span> <span class="n">y_last</span><span class="p">},</span> <span class="n">step</span>
            <span class="p">)</span>
            <span class="c1"># Log success rate</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;success_rate&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">success_rate</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
            <span class="c1"># Log best X coordinates</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;X_best/x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">step</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Noisy optimization</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">add_scalars</span><span class="p">(</span>
                <span class="s2">&quot;y_values&quot;</span><span class="p">,</span>
                <span class="p">{</span><span class="s2">&quot;min&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_y</span><span class="p">,</span> <span class="s2">&quot;mean_best&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_y</span><span class="p">,</span> <span class="s2">&quot;last&quot;</span><span class="p">:</span> <span class="n">y_last</span><span class="p">},</span>
                <span class="n">step</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># Log variance of best mean</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;y_variance_at_best&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_var_y</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
            <span class="c1"># Log success rate</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;success_rate&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">success_rate</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>

            <span class="c1"># Log best X coordinates (by mean)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;X_mean_best/x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">step</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_write_tensorboard_hparams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Write hyperparameters and metric to TensorBoard.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): Design point coordinates, shape (n_features,)</span>
<span class="sd">            y (float): Function value at X</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="c1"># Create hyperparameter dict with variable names</span>
        <span class="n">hparam_dict</span> <span class="o">=</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">var_name</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> <span class="nb">float</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">)}</span>
        <span class="n">metric_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;hp_metric&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">y</span><span class="p">)}</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">add_hparams</span><span class="p">(</span><span class="n">hparam_dict</span><span class="p">,</span> <span class="n">metric_dict</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_close_tensorboard_writer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Close TensorBoard writer and cleanup.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;tb_writer&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;TensorBoard writer closed. View logs with: tensorboard --logdir=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_path</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the shape of the objective function output.</span>

<span class="sd">        Args:</span>
<span class="sd">            y (ndarray): Objective function output, shape (n_samples,) or (n_samples, n_objectives).</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: (n_samples, n_objectives) where n_objectives is None for single-objective.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     max_iter=10,</span>
<span class="sd">            ...     n_initial=5</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; y_single = np.array([1.0, 2.0, 3.0])</span>
<span class="sd">            &gt;&gt;&gt; n, m = opt._get_shape(y_single)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;n={n}, m={m}&quot;)</span>
<span class="sd">            n=3, m=None</span>
<span class="sd">            &gt;&gt;&gt; y_multi = np.array([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])</span>
<span class="sd">            &gt;&gt;&gt; n, m = opt._get_shape(y_multi)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;n={n}, m={m}&quot;)</span>
<span class="sd">            n=3, m=2</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="kc">None</span>
        <span class="k">elif</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># For higher dimensions, flatten to 1D</span>
            <span class="k">return</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_store_mo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_mo</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Store multi-objective values in self.y_mo.</span>

<span class="sd">        If multi-objective values are present (ndim==2), they are stored in self.y_mo.</span>
<span class="sd">        New values are appended to existing ones. For single-objective problems,</span>
<span class="sd">        self.y_mo remains None.</span>

<span class="sd">        Args:</span>
<span class="sd">            y_mo (ndarray): If multi-objective, shape (n_samples, n_objectives).</span>
<span class="sd">                           If single-objective, shape (n_samples,).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.column_stack([</span>
<span class="sd">            ...         np.sum(X**2, axis=1),</span>
<span class="sd">            ...         np.sum((X-1)**2, axis=1)</span>
<span class="sd">            ...     ]),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     max_iter=10,</span>
<span class="sd">            ...     n_initial=5</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; y_mo_1 = np.array([[1.0, 2.0], [3.0, 4.0]])</span>
<span class="sd">            &gt;&gt;&gt; opt._store_mo(y_mo_1)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;y_mo after first call: {opt.y_mo}&quot;)</span>
<span class="sd">            y_mo after first call: [[1. 2.]</span>
<span class="sd">             [3. 4.]]</span>
<span class="sd">            &gt;&gt;&gt; y_mo_2 = np.array([[5.0, 6.0], [7.0, 8.0]])</span>
<span class="sd">            &gt;&gt;&gt; opt._store_mo(y_mo_2)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;y_mo after second call: {opt.y_mo}&quot;)</span>
<span class="sd">            y_mo after second call: [[1. 2.]</span>
<span class="sd">             [3. 4.]</span>
<span class="sd">             [5. 6.]</span>
<span class="sd">             [7. 8.]]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Store y_mo in self.y_mo (append new values) if multi-objective</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_mo</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y_mo</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_mo</span> <span class="o">=</span> <span class="n">y_mo</span>
        <span class="k">elif</span> <span class="n">y_mo</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_mo</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">y_mo</span><span class="p">,</span> <span class="n">y_mo</span><span class="p">])</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_mo2so</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_mo</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert multi-objective values to single-objective.</span>

<span class="sd">        Converts multi-objective values to a single-objective value by applying a user-defined</span>
<span class="sd">        function from `fun_mo2so`. If no user-defined function is given, the</span>
<span class="sd">        values in the first objective column are used.</span>

<span class="sd">        This method is called after the objective function evaluation. It returns a 1D array</span>
<span class="sd">        with the single-objective values.</span>

<span class="sd">        Args:</span>
<span class="sd">            y_mo (ndarray): If multi-objective, shape (n_samples, n_objectives).</span>
<span class="sd">                           If single-objective, shape (n_samples,).</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Single-objective values, shape (n_samples,).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; # Multi-objective function</span>
<span class="sd">            &gt;&gt;&gt; def mo_fun(X):</span>
<span class="sd">            ...     return np.column_stack([</span>
<span class="sd">            ...         np.sum(X**2, axis=1),</span>
<span class="sd">            ...         np.sum((X-1)**2, axis=1)</span>
<span class="sd">            ...     ])</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Example 1: Default behavior (use first objective)</span>
<span class="sd">            &gt;&gt;&gt; opt1 = SpotOptim(</span>
<span class="sd">            ...     fun=mo_fun,</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     max_iter=10,</span>
<span class="sd">            ...     n_initial=5</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; y_mo = np.array([[1.0, 2.0], [3.0, 4.0]])</span>
<span class="sd">            &gt;&gt;&gt; y_so = opt1._mo2so(y_mo)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;Single-objective (default): {y_so}&quot;)</span>
<span class="sd">            Single-objective (default): [1. 3.]</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Example 2: Custom conversion function (sum of objectives)</span>
<span class="sd">            &gt;&gt;&gt; def custom_mo2so(y_mo):</span>
<span class="sd">            ...     return y_mo[:, 0] + y_mo[:, 1]</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; opt2 = SpotOptim(</span>
<span class="sd">            ...     fun=mo_fun,</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     max_iter=10,</span>
<span class="sd">            ...     n_initial=5,</span>
<span class="sd">            ...     fun_mo2so=custom_mo2so</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; y_so_custom = opt2._mo2so(y_mo)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;Single-objective (custom): {y_so_custom}&quot;)</span>
<span class="sd">            Single-objective (custom): [3. 7.]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_shape</span><span class="p">(</span><span class="n">y_mo</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_store_mo</span><span class="p">(</span><span class="n">y_mo</span><span class="p">)</span>

        <span class="c1"># Use ndim to check if multi-objective</span>
        <span class="k">if</span> <span class="n">y_mo</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fun_mo2so</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Apply user-defined conversion function</span>
                <span class="n">y0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fun_mo2so</span><span class="p">(</span><span class="n">y_mo</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Default: use first column</span>
                <span class="k">if</span> <span class="n">y_mo</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">y0</span> <span class="o">=</span> <span class="n">y_mo</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">y0</span> <span class="o">=</span> <span class="n">y_mo</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Single-objective, return as-is</span>
            <span class="n">y0</span> <span class="o">=</span> <span class="n">y_mo</span>

        <span class="k">return</span> <span class="n">y0</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_ranks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns ranks of numbers within input array x.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (ndarray): Input array.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Ranks array where ranks[i] is the rank of x[i].</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1), bounds=[(-5, 5)])</span>
<span class="sd">            &gt;&gt;&gt; opt._get_ranks(np.array([2, 1]))</span>
<span class="sd">            array([1, 0])</span>
<span class="sd">            &gt;&gt;&gt; opt._get_ranks(np.array([20, 10, 100]))</span>
<span class="sd">            array([1, 0, 2])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ts</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">argsort</span><span class="p">()</span>
        <span class="n">ranks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">ts</span><span class="p">)</span>
        <span class="n">ranks</span><span class="p">[</span><span class="n">ts</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">ranks</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_ocba</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">means</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">vars</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">delta</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Optimal Computing Budget Allocation (OCBA).</span>

<span class="sd">        Calculates budget recommendations for given means, variances, and incremental</span>
<span class="sd">        budget using the OCBA algorithm.</span>

<span class="sd">        References:</span>
<span class="sd">            [1] Chun-Hung Chen and Loo Hay Lee: Stochastic Simulation Optimization:</span>
<span class="sd">                An Optimal Computer Budget Allocation, pp. 49 and pp. 215</span>

<span class="sd">        Args:</span>
<span class="sd">            means (ndarray): Array of means.</span>
<span class="sd">            vars (ndarray): Array of variances.</span>
<span class="sd">            delta (int): Incremental budget.</span>
<span class="sd">            verbose (bool): If True, print debug information. Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Array of budget recommendations, or None if conditions not met.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1), bounds=[(-5, 5)])</span>
<span class="sd">            &gt;&gt;&gt; means = np.array([1, 2, 3, 4, 5])</span>
<span class="sd">            &gt;&gt;&gt; vars = np.array([1, 1, 9, 9, 4])</span>
<span class="sd">            &gt;&gt;&gt; allocations = opt._get_ocba(means, vars, 50)</span>
<span class="sd">            &gt;&gt;&gt; allocations</span>
<span class="sd">            array([11,  9, 19,  9,  2])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="nb">vars</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">means</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">):</span>
            <span class="n">n_designs</span> <span class="o">=</span> <span class="n">means</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">allocations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_designs</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="n">ratios</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_designs</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="n">budget</span> <span class="o">=</span> <span class="n">delta</span>
            <span class="n">ranks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_ranks</span><span class="p">(</span><span class="n">means</span><span class="p">)</span>
            <span class="n">best</span><span class="p">,</span> <span class="n">second_best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argpartition</span><span class="p">(</span><span class="n">ranks</span><span class="p">,</span> <span class="mi">2</span><span class="p">)[:</span><span class="mi">2</span><span class="p">]</span>
            <span class="n">ratios</span><span class="p">[</span><span class="n">second_best</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="n">select</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_designs</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">best</span><span class="p">,</span> <span class="n">second_best</span><span class="p">]]</span>
            <span class="n">temp</span> <span class="o">=</span> <span class="p">(</span><span class="n">means</span><span class="p">[</span><span class="n">best</span><span class="p">]</span> <span class="o">-</span> <span class="n">means</span><span class="p">[</span><span class="n">second_best</span><span class="p">])</span> <span class="o">/</span> <span class="p">(</span><span class="n">means</span><span class="p">[</span><span class="n">best</span><span class="p">]</span> <span class="o">-</span> <span class="n">means</span><span class="p">[</span><span class="n">select</span><span class="p">])</span>
            <span class="n">ratios</span><span class="p">[</span><span class="n">select</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="nb">vars</span><span class="p">[</span><span class="n">select</span><span class="p">]</span> <span class="o">/</span> <span class="nb">vars</span><span class="p">[</span><span class="n">second_best</span><span class="p">])</span>
            <span class="n">select</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_designs</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">best</span><span class="p">]]</span>
            <span class="n">temp</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">ratios</span><span class="p">[</span><span class="n">select</span><span class="p">])</span> <span class="o">/</span> <span class="nb">vars</span><span class="p">[</span><span class="n">select</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">ratios</span><span class="p">[</span><span class="n">best</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">vars</span><span class="p">[</span><span class="n">best</span><span class="p">]</span> <span class="o">*</span> <span class="n">temp</span><span class="p">)</span>
            <span class="n">more_runs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">n_designs</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
            <span class="n">add_budget</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_designs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
            <span class="n">more_alloc</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">In _get_ocba():&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;means: </span><span class="si">{</span><span class="n">means</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;vars: </span><span class="si">{</span><span class="nb">vars</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;delta: </span><span class="si">{</span><span class="n">delta</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_designs: </span><span class="si">{</span><span class="n">n_designs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ratios: </span><span class="si">{</span><span class="n">ratios</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best: </span><span class="si">{</span><span class="n">best</span><span class="si">}</span><span class="s2">, Second best: </span><span class="si">{</span><span class="n">second_best</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">while</span> <span class="n">more_alloc</span><span class="p">:</span>
                <span class="n">more_alloc</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">ratio_s</span> <span class="o">=</span> <span class="p">(</span><span class="n">more_runs</span> <span class="o">*</span> <span class="n">ratios</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                <span class="n">add_budget</span><span class="p">[</span><span class="n">more_runs</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">budget</span> <span class="o">/</span> <span class="n">ratio_s</span><span class="p">)</span> <span class="o">*</span> <span class="n">ratios</span><span class="p">[</span><span class="n">more_runs</span><span class="p">]</span>
                <span class="n">add_budget</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">around</span><span class="p">(</span><span class="n">add_budget</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
                <span class="n">mask</span> <span class="o">=</span> <span class="n">add_budget</span> <span class="o">&lt;</span> <span class="n">allocations</span>
                <span class="n">add_budget</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">allocations</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
                <span class="n">more_runs</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

                <span class="k">if</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">more_alloc</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">if</span> <span class="n">more_alloc</span><span class="p">:</span>
                    <span class="n">budget</span> <span class="o">=</span> <span class="n">allocations</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">delta</span>
                    <span class="n">budget</span> <span class="o">-=</span> <span class="p">(</span><span class="n">add_budget</span> <span class="o">*</span> <span class="o">~</span><span class="n">more_runs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="n">t_budget</span> <span class="o">=</span> <span class="n">add_budget</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">add_budget</span><span class="p">[</span><span class="n">best</span><span class="p">]</span> <span class="o">+=</span> <span class="n">allocations</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">delta</span> <span class="o">-</span> <span class="n">t_budget</span>
            <span class="k">return</span> <span class="n">add_budget</span> <span class="o">-</span> <span class="n">allocations</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_ocba_X</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">means</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="nb">vars</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">delta</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate OCBA allocation and repeat input array X.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): Input array to be repeated, shape (n_designs, n_features).</span>
<span class="sd">            means (ndarray): Array of means for each design.</span>
<span class="sd">            vars (ndarray): Array of variances for each design.</span>
<span class="sd">            delta (int): Incremental budget.</span>
<span class="sd">            verbose (bool): If True, print debug information. Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Repeated array of X based on OCBA allocation, or None if</span>
<span class="sd">                     conditions not met.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1), bounds=[(-5, 5)])</span>
<span class="sd">            &gt;&gt;&gt; X = np.array([[1, 2], [4, 5], [7, 8]])</span>
<span class="sd">            &gt;&gt;&gt; means = np.array([1.5, 35, 550])</span>
<span class="sd">            &gt;&gt;&gt; vars = np.array([0.5, 50, 5000])</span>
<span class="sd">            &gt;&gt;&gt; X_new = opt._get_ocba_X(X, means, vars, delta=5, verbose=False)</span>
<span class="sd">            &gt;&gt;&gt; X_new.shape[0] == 5  # Should have 5 additional evaluations</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="nb">vars</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">means</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">):</span>
            <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_ocba</span><span class="p">(</span><span class="n">means</span><span class="o">=</span><span class="n">means</span><span class="p">,</span> <span class="nb">vars</span><span class="o">=</span><span class="nb">vars</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="n">delta</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_evaluate_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate objective function at points X.</span>

<span class="sd">        If dimension reduction is active, expands X to full dimensions before evaluation.</span>
<span class="sd">        Supports both single-objective and multi-objective functions. For multi-objective</span>
<span class="sd">        functions, converts to single-objective using _mo2so method.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): Points to evaluate in reduced space, shape (n_samples, n_reduced_features).</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Function values, shape (n_samples,).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; # Single-objective function</span>
<span class="sd">            &gt;&gt;&gt; opt_so = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     max_iter=10,</span>
<span class="sd">            ...     n_initial=5</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; X = np.array([[1.0, 2.0], [3.0, 4.0]])</span>
<span class="sd">            &gt;&gt;&gt; y = opt_so._evaluate_function(X)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;Single-objective output: {y}&quot;)</span>
<span class="sd">            Single-objective output: [ 5. 25.]</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Multi-objective function (default: use first objective)</span>
<span class="sd">            &gt;&gt;&gt; opt_mo = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.column_stack([</span>
<span class="sd">            ...         np.sum(X**2, axis=1),</span>
<span class="sd">            ...         np.sum((X-1)**2, axis=1)</span>
<span class="sd">            ...     ]),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     max_iter=10,</span>
<span class="sd">            ...     n_initial=5</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; y_mo = opt_mo._evaluate_function(X)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;Multi-objective output (first obj): {y_mo}&quot;)</span>
<span class="sd">            Multi-objective output (first obj): [ 5. 25.]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Ensure X is 2D</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="c1"># Expand to full dimensions if needed</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_all_dim</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="c1"># Evaluate function</span>
        <span class="n">y_raw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fun</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="c1"># Convert to numpy array if needed</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_raw</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">y_raw</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y_raw</span><span class="p">])</span>

        <span class="c1"># Handle multi-objective case</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mo2so</span><span class="p">(</span><span class="n">y_raw</span><span class="p">)</span>

        <span class="c1"># Ensure y is 1D</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">y</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_initial_design</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate initial space-filling design using Latin Hypercube Sampling.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Initial design points, shape (n_initial, n_features).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...                 bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...                 n_initial=10)</span>
<span class="sd">            &gt;&gt;&gt; X0 = opt._generate_initial_design()</span>
<span class="sd">            &gt;&gt;&gt; X0.shape</span>
<span class="sd">            (10, 2)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Generate samples in [0, 1]^d</span>
        <span class="n">X0_unit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lhs_sampler</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_initial</span><span class="p">)</span>

        <span class="c1"># Scale to [lower, upper]</span>
        <span class="n">X0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span> <span class="o">+</span> <span class="n">X0_unit</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upper</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repair_non_numeric</span><span class="p">(</span><span class="n">X0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_select_distant_points</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Selects k points that are distant from each other using K-means clustering.</span>

<span class="sd">        This method performs K-means clustering to find k clusters, then selects</span>
<span class="sd">        the point closest to each cluster center. This ensures a space-filling</span>
<span class="sd">        subset of points for surrogate model training.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): Design points, shape (n_samples, n_features).</span>
<span class="sd">            y (ndarray): Function values at X, shape (n_samples,).</span>
<span class="sd">            k (int): Number of points to select.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: A tuple containing:</span>
<span class="sd">                - selected_X (ndarray): Selected design points, shape (k, n_features).</span>
<span class="sd">                - selected_y (ndarray): Function values at selected points, shape (k,).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...                 bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...                 max_surrogate_points=5)</span>
<span class="sd">            &gt;&gt;&gt; X = np.random.rand(100, 2)</span>
<span class="sd">            &gt;&gt;&gt; y = np.random.rand(100)</span>
<span class="sd">            &gt;&gt;&gt; X_sel, y_sel = opt._select_distant_points(X, y, 5)</span>
<span class="sd">            &gt;&gt;&gt; X_sel.shape</span>
<span class="sd">            (5, 2)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>

        <span class="c1"># Perform k-means clustering</span>
        <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="c1"># Find the closest point to each cluster center</span>
        <span class="n">selected_indices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">center</span> <span class="ow">in</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">:</span>
            <span class="n">distances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">center</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">closest_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>
            <span class="n">selected_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">closest_idx</span><span class="p">)</span>

        <span class="n">selected_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">selected_indices</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">[</span><span class="n">selected_indices</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">selected_indices</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_select_best_cluster</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Selects all points from the cluster with the smallest mean y value.</span>

<span class="sd">        This method performs K-means clustering and selects all points from the</span>
<span class="sd">        cluster whose center corresponds to the best (smallest) mean objective</span>
<span class="sd">        function value.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): Design points, shape (n_samples, n_features).</span>
<span class="sd">            y (ndarray): Function values at X, shape (n_samples,).</span>
<span class="sd">            k (int): Number of clusters.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: A tuple containing:</span>
<span class="sd">                - selected_X (ndarray): Selected design points from best cluster, shape (m, n_features).</span>
<span class="sd">                - selected_y (ndarray): Function values at selected points, shape (m,).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...                 bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...                 max_surrogate_points=5,</span>
<span class="sd">            ...                 selection_method=&#39;best&#39;)</span>
<span class="sd">            &gt;&gt;&gt; X = np.random.rand(100, 2)</span>
<span class="sd">            &gt;&gt;&gt; y = np.random.rand(100)</span>
<span class="sd">            &gt;&gt;&gt; X_sel, y_sel = opt._select_best_cluster(X, y, 5)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>

        <span class="c1"># Perform k-means clustering</span>
        <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>

        <span class="c1"># Compute mean y for each cluster</span>
        <span class="n">cluster_means</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">cluster_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
            <span class="n">cluster_y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">labels</span> <span class="o">==</span> <span class="n">cluster_idx</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cluster_y</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">cluster_means</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">cluster_means</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cluster_y</span><span class="p">))</span>

        <span class="c1"># Find cluster with smallest mean y</span>
        <span class="n">best_cluster</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">cluster_means</span><span class="p">)</span>

        <span class="c1"># Select all points from the best cluster</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">==</span> <span class="n">best_cluster</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">[</span><span class="n">mask</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_selection_dispatcher</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Dispatcher for selection methods.</span>

<span class="sd">        Depending on the value of `self.selection_method`, this method calls</span>
<span class="sd">        the appropriate selection function to choose a subset of points for</span>
<span class="sd">        surrogate model training when the total number of points exceeds</span>
<span class="sd">        `self.max_surrogate_points`.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): Design points, shape (n_samples, n_features).</span>
<span class="sd">            y (ndarray): Function values at X, shape (n_samples,).</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: A tuple containing:</span>
<span class="sd">                - selected_X (ndarray): Selected design points.</span>
<span class="sd">                - selected_y (ndarray): Function values at selected points.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...                 bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...                 max_surrogate_points=5)</span>
<span class="sd">            &gt;&gt;&gt; X = np.random.rand(100, 2)</span>
<span class="sd">            &gt;&gt;&gt; y = np.random.rand(100)</span>
<span class="sd">            &gt;&gt;&gt; X_sel, y_sel = opt._selection_dispatcher(X, y)</span>
<span class="sd">            &gt;&gt;&gt; X_sel.shape[0] &lt;= 5</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_surrogate_points</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">selection_method</span> <span class="o">==</span> <span class="s2">&quot;distant&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_distant_points</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_surrogate_points</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">selection_method</span> <span class="o">==</span> <span class="s2">&quot;best&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_best_cluster</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_surrogate_points</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If no valid selection method, return all points</span>
            <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_fit_surrogate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit surrogate model to data.</span>

<span class="sd">        If the number of points exceeds `self.max_surrogate_points`,</span>
<span class="sd">        a subset of points is selected using the selection dispatcher.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): Design points, shape (n_samples, n_features).</span>
<span class="sd">            y (ndarray): Function values at X, shape (n_samples,).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X_fit</span> <span class="o">=</span> <span class="n">X</span>
        <span class="n">y_fit</span> <span class="o">=</span> <span class="n">y</span>

        <span class="c1"># Select subset if needed</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">max_surrogate_points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_surrogate_points</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Selecting subset of </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_surrogate_points</span><span class="si">}</span><span class="s2"> points &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;from </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> total points for surrogate fitting.&quot;</span>
                <span class="p">)</span>
            <span class="n">X_fit</span><span class="p">,</span> <span class="n">y_fit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_selection_dispatcher</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_fit</span><span class="p">,</span> <span class="n">y_fit</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_select_new</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">A</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">tolerance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Select rows from A that are not in X.</span>

<span class="sd">        Args:</span>
<span class="sd">            A (ndarray): Array with new values.</span>
<span class="sd">            X (ndarray): Array with known values.</span>
<span class="sd">            tolerance (float, optional): Tolerance value for comparison. Defaults to 0.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: A tuple containing:</span>
<span class="sd">                - ndarray: Array with unknown (new) values.</span>
<span class="sd">                - ndarray: Array with True if value is new, otherwise False.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">A</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="p">)</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">B</span> <span class="o">&lt;=</span> <span class="n">tolerance</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">A</span><span class="p">[</span><span class="o">~</span><span class="n">ind</span><span class="p">],</span> <span class="o">~</span><span class="n">ind</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_repair_non_numeric</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">var_type</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Round non-numeric values to integers based on variable type.</span>

<span class="sd">        This method applies rounding to variables that are not continuous:</span>
<span class="sd">        - &#39;float&#39;: No rounding (continuous values)</span>
<span class="sd">        - &#39;int&#39;: Rounded to integers</span>
<span class="sd">        - &#39;factor&#39;: Rounded to integers (representing categorical values)</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): X array with values to potentially round.</span>
<span class="sd">            var_type (list of str): List with type information for each dimension.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: X array with non-continuous values rounded to integers.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">var_type</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;float&quot;</span><span class="p">],</span> <span class="n">invert</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">X</span><span class="p">[:,</span> <span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">around</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">mask</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">X</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_handle_acquisition_failure</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Handle acquisition failure by proposing new design points.</span>

<span class="sd">        This method is called when no new design points can be suggested</span>
<span class="sd">        by the surrogate model (e.g., when the proposed point is too close</span>
<span class="sd">        to existing points). Depending on the specified strategy, it either</span>
<span class="sd">        proposes a Morris-Mitchell minimizing point or generates a new</span>
<span class="sd">        space-filling design as a fallback.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: New design point as a fallback, shape (n_features,).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     acquisition_failure_strategy=&#39;random&#39;</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; opt.X_ = np.array([[0, 0], [1, 1]])</span>
<span class="sd">            &gt;&gt;&gt; opt.y_ = np.array([0, 2])</span>
<span class="sd">            &gt;&gt;&gt; x_fallback = opt._handle_acquisition_failure()</span>
<span class="sd">            &gt;&gt;&gt; x_fallback.shape</span>
<span class="sd">            (2,)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_failure_strategy</span> <span class="o">==</span> <span class="s2">&quot;mm&quot;</span><span class="p">:</span>
            <span class="c1"># Morris-Mitchell phi minimizing point</span>
            <span class="c1"># This strategy finds a point that maximizes the minimum distance</span>
            <span class="c1"># to all existing points, providing good space-filling properties</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="s2">&quot;Acquisition failure: Using Morris-Mitchell minimizing point as fallback.&quot;</span>
                <span class="p">)</span>

            <span class="c1"># Calculate distances from all possible candidates to existing points</span>
            <span class="c1"># We&#39;ll use a simple approach: generate many random candidates and pick the one</span>
            <span class="c1"># with maximum minimum distance to existing points</span>
            <span class="n">n_candidates</span> <span class="o">=</span> <span class="mi">100</span>
            <span class="n">candidates_unit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lhs_sampler</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n_candidates</span><span class="p">)</span>
            <span class="n">candidates</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span> <span class="o">+</span> <span class="n">candidates_unit</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upper</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">)</span>

            <span class="c1"># Calculate minimum distance from each candidate to existing points</span>
            <span class="n">min_distances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_candidates</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">candidate</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">candidates</span><span class="p">):</span>
                <span class="n">distances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="o">-</span> <span class="n">candidate</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">min_distances</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>

            <span class="c1"># Select candidate with maximum minimum distance</span>
            <span class="n">best_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">min_distances</span><span class="p">)</span>
            <span class="n">x_new</span> <span class="o">=</span> <span class="n">candidates</span><span class="p">[</span><span class="n">best_idx</span><span class="p">]</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Default: random space-filling design (Latin Hypercube Sampling)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="s2">&quot;Acquisition failure: Using random space-filling design as fallback.&quot;</span>
                <span class="p">)</span>

            <span class="n">x_new_unit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lhs_sampler</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">x_new</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span> <span class="o">+</span> <span class="n">x_new_unit</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upper</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repair_non_numeric</span><span class="p">(</span><span class="n">x_new</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_acquisition_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute acquisition function value.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (ndarray): Point to evaluate, shape (n_features,).</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: Acquisition function value (to be minimized).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition</span> <span class="o">==</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span>
            <span class="c1"># Predicted mean</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition</span> <span class="o">==</span> <span class="s2">&quot;ei&quot;</span><span class="p">:</span>
            <span class="c1"># Expected Improvement</span>
            <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">sigma</span> <span class="o">&lt;</span> <span class="mf">1e-10</span><span class="p">:</span>
                <span class="k">return</span> <span class="mf">0.0</span>

            <span class="n">y_best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>
            <span class="n">improvement</span> <span class="o">=</span> <span class="n">y_best</span> <span class="o">-</span> <span class="n">mu</span>
            <span class="n">Z</span> <span class="o">=</span> <span class="n">improvement</span> <span class="o">/</span> <span class="n">sigma</span>

            <span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">norm</span>

            <span class="n">ei</span> <span class="o">=</span> <span class="n">improvement</span> <span class="o">*</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span> <span class="o">+</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">ei</span>  <span class="c1"># Minimize negative EI</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition</span> <span class="o">==</span> <span class="s2">&quot;pi&quot;</span><span class="p">:</span>
            <span class="c1"># Probability of Improvement</span>
            <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">sigma</span> <span class="o">&lt;</span> <span class="mf">1e-10</span><span class="p">:</span>
                <span class="k">return</span> <span class="mf">0.0</span>

            <span class="n">y_best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>
            <span class="n">Z</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_best</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span>

            <span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">norm</span>

            <span class="n">pi</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">pi</span>  <span class="c1"># Minimize negative PI</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown acquisition function: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">acquisition</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_suggest_next_point</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Suggest next point to evaluate using acquisition function optimization.</span>

<span class="sd">        If the acquisition function optimization fails to find a sufficiently distant</span>
<span class="sd">        point, falls back to the strategy specified by acquisition_failure_strategy.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Next point to evaluate, shape (n_features,).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">differential_evolution</span><span class="p">(</span>
            <span class="n">func</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_acquisition_function</span><span class="p">,</span>
            <span class="n">bounds</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
            <span class="n">maxiter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">x_next</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span>

        <span class="c1"># Ensure minimum distance to existing points</span>
        <span class="n">x_next_2d</span> <span class="o">=</span> <span class="n">x_next</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x_new</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_new</span><span class="p">(</span><span class="n">A</span><span class="o">=</span><span class="n">x_next_2d</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tolerance_x</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">x_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># No new point found on surrogate - use fallback strategy</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_handle_acquisition_failure</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repair_non_numeric</span><span class="p">(</span><span class="n">x_next</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">optimize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X0</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OptimizeResult</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run the optimization process.</span>

<span class="sd">        The optimization terminates when either:</span>
<span class="sd">        - Total function evaluations reach max_iter (including initial design), OR</span>
<span class="sd">        - Runtime exceeds max_time minutes</span>

<span class="sd">        Args:</span>
<span class="sd">            X0 (ndarray, optional): Initial design points, shape (n_initial, n_features).</span>
<span class="sd">                If None, generates space-filling design. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            OptimizeResult: Optimization result with fields:</span>
<span class="sd">                - x: best point found</span>
<span class="sd">                - fun: best function value</span>
<span class="sd">                - nfev: number of function evaluations (including initial design)</span>
<span class="sd">                - nit: number of sequential optimization iterations (after initial design)</span>
<span class="sd">                - success: whether optimization succeeded</span>
<span class="sd">                - message: termination message indicating reason for stopping</span>
<span class="sd">                - X: all evaluated points</span>
<span class="sd">                - y: all function values</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; # Example 1: Budget-based termination</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=objective, bounds=bounds, max_iter=30, n_initial=10)</span>
<span class="sd">            &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">            &gt;&gt;&gt; # Will perform 10 initial + 20 sequential iterations = 30 total evaluations</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Example 2: Time-based termination</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=expensive_objective, bounds=bounds,</span>
<span class="sd">            ...                 max_iter=1000, max_time=5.0)  # 5 minutes max</span>
<span class="sd">            &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">            &gt;&gt;&gt; # Will stop after 5 minutes OR 1000 evaluations, whichever comes first</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Generate or use provided initial design</span>
        <span class="k">if</span> <span class="n">X0</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_initial_design</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">X0</span><span class="p">)</span>
            <span class="c1"># If X0 is in full dimensions and we have dimension reduction, reduce it</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span> <span class="ow">and</span> <span class="n">X0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">):</span>
                <span class="n">X0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_red_dim</span><span class="p">(</span><span class="n">X0</span><span class="p">)</span>
            <span class="n">X0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repair_non_numeric</span><span class="p">(</span><span class="n">X0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">)</span>

        <span class="c1"># Repeat initial design points if repeats_initial &gt; 1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">repeats_initial</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">X0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">X0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">repeats_initial</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Evaluate initial design</span>
        <span class="n">y0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate_function</span><span class="p">(</span><span class="n">X0</span><span class="p">)</span>

        <span class="c1"># Update success rate BEFORE updating storage (initial design - all should be successes since starting from scratch)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_success_rate</span><span class="p">(</span><span class="n">y0</span><span class="p">)</span>

        <span class="c1"># Initialize storage</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="o">=</span> <span class="n">X0</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">y0</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Update stats after initial design</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_stats</span><span class="p">()</span>

        <span class="c1"># Log initial design to TensorBoard</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_write_tensorboard_hparams</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_write_tensorboard_scalars</span><span class="p">()</span>

        <span class="c1"># Initial best</span>
        <span class="n">best_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">[</span><span class="n">best_idx</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">[</span><span class="n">best_idx</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Initial best: f(x) = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">, mean best: f(x) = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">min_mean_y</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initial best: f(x) = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Start timer for max_time check</span>
        <span class="n">timeout_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1"># Main optimization loop</span>
        <span class="c1"># Termination: continue while (total_evals &lt; max_iter) AND (elapsed_time &lt; max_time)</span>
        <span class="k">while</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">timeout_start</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_time</span> <span class="o">*</span> <span class="mi">60</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># Fit surrogate (use mean_y if noise, otherwise y_)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_fit_surrogate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean_X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_y</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_fit_surrogate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>

            <span class="c1"># OCBA: Compute optimal budget allocation for noisy functions</span>
            <span class="c1"># This determines which existing design points should be re-evaluated</span>
            <span class="n">X_ocba</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">ocba_delta</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># Check conditions for OCBA (need variance &gt; 0 and at least 3 points)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">):</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Warning: OCBA skipped (need &gt;2 points with variance &gt; 0)&quot;</span>
                        <span class="p">)</span>
                <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">):</span>
                    <span class="c1"># Get OCBA allocation</span>
                    <span class="n">X_ocba</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_ocba_X</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">mean_X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ocba_delta</span>
                    <span class="p">)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="ow">and</span> <span class="n">X_ocba</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  OCBA: Adding </span><span class="si">{</span><span class="n">X_ocba</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> re-evaluation(s)&quot;</span><span class="p">)</span>

            <span class="c1"># Suggest next point</span>
            <span class="n">x_next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_suggest_next_point</span><span class="p">()</span>

            <span class="c1"># Repeat next point if repeats_surrogate &gt; 1</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">repeats_surrogate</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">x_next_repeated</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
                    <span class="n">x_next</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">repeats_surrogate</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x_next_repeated</span> <span class="o">=</span> <span class="n">x_next</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Append OCBA points to new design points (if applicable)</span>
            <span class="k">if</span> <span class="n">X_ocba</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">x_next_repeated</span> <span class="o">=</span> <span class="n">append</span><span class="p">(</span><span class="n">X_ocba</span><span class="p">,</span> <span class="n">x_next_repeated</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="c1"># Evaluate next point(s) including OCBA points</span>
            <span class="n">y_next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate_function</span><span class="p">(</span><span class="n">x_next_repeated</span><span class="p">)</span>

            <span class="c1"># Update success rate BEFORE updating storage (so it compares against previous best)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_update_success_rate</span><span class="p">(</span><span class="n">y_next</span><span class="p">)</span>

            <span class="c1"># Update storage</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">,</span> <span class="n">x_next_repeated</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">,</span> <span class="n">y_next</span><span class="p">)</span>

            <span class="c1"># Update stats</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_stats</span><span class="p">()</span>

            <span class="c1"># Log to TensorBoard</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Log each new evaluation</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_next</span><span class="p">)):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_write_tensorboard_hparams</span><span class="p">(</span><span class="n">x_next_repeated</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_next</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_write_tensorboard_scalars</span><span class="p">()</span>

            <span class="c1"># Update best</span>
            <span class="n">current_best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y_next</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">current_best</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="p">:</span>
                <span class="n">best_idx_in_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">y_next</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span> <span class="o">=</span> <span class="n">x_next_repeated</span><span class="p">[</span><span class="n">best_idx_in_new</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span> <span class="o">=</span> <span class="n">current_best</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span><span class="si">}</span><span class="s2">: New best f(x) = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">, mean best: f(x) = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">min_mean_y</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span><span class="si">}</span><span class="s2">: New best f(x) = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span><span class="p">:</span>
                    <span class="n">mean_y_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_next</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span><span class="si">}</span><span class="s2">: mean f(x) = </span><span class="si">{</span><span class="n">mean_y_new</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span><span class="si">}</span><span class="s2">: f(x) = </span><span class="si">{</span><span class="n">y_next</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Expand results to full dimensions if needed</span>
        <span class="n">best_x_full</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">to_all_dim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span>
            <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span>
        <span class="p">)</span>
        <span class="n">X_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_all_dim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span>

        <span class="c1"># Determine termination reason</span>
        <span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">timeout_start</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Optimization terminated: maximum evaluations (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="si">}</span><span class="s2">) reached&quot;</span>
        <span class="k">elif</span> <span class="n">elapsed_time</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_time</span> <span class="o">*</span> <span class="mi">60</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Optimization terminated: time limit (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> min) reached&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="s2">&quot;Optimization finished successfully&quot;</span>

        <span class="c1"># Close TensorBoard writer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_close_tensorboard_writer</span><span class="p">()</span>

        <span class="c1"># Return scipy-style result</span>
        <span class="k">return</span> <span class="n">OptimizeResult</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">best_x_full</span><span class="p">,</span>
            <span class="n">fun</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="p">,</span>
            <span class="n">nfev</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">),</span>
            <span class="n">nit</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span><span class="p">,</span>
            <span class="n">success</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">message</span><span class="o">=</span><span class="n">message</span><span class="p">,</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X_full</span><span class="p">,</span>
            <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">plot_surrogate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">i</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">j</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">show</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
        <span class="n">var_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cmap</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;jet&quot;</span><span class="p">,</span>
        <span class="n">num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">vmin</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">vmax</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">add_points</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">grid_visible</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">contour_levels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
        <span class="n">figsize</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Plot the surrogate model for two dimensions.</span>

<span class="sd">        Creates a 2x2 plot showing:</span>
<span class="sd">        - Top left: 3D surface of predictions</span>
<span class="sd">        - Top right: 3D surface of prediction uncertainty</span>
<span class="sd">        - Bottom left: Contour plot of predictions with evaluated points</span>
<span class="sd">        - Bottom right: Contour plot of prediction uncertainty</span>

<span class="sd">        Args:</span>
<span class="sd">            i (int, optional): Index of the first dimension to plot. Defaults to 0.</span>
<span class="sd">            j (int, optional): Index of the second dimension to plot. Defaults to 1.</span>
<span class="sd">            show (bool, optional): If True, displays the plot immediately. Defaults to True.</span>
<span class="sd">            alpha (float, optional): Transparency of the 3D surface plots (0=transparent, 1=opaque).</span>
<span class="sd">                Defaults to 0.8.</span>
<span class="sd">            var_name (list of str, optional): Names for each dimension. If None, uses instance var_name.</span>
<span class="sd">                Defaults to None.</span>
<span class="sd">            cmap (str, optional): Matplotlib colormap name. Defaults to &#39;jet&#39;.</span>
<span class="sd">            num (int, optional): Number of grid points per dimension for mesh grid. Defaults to 100.</span>
<span class="sd">            vmin (float, optional): Minimum value for color scale. If None, determined from data.</span>
<span class="sd">                Defaults to None.</span>
<span class="sd">            vmax (float, optional): Maximum value for color scale. If None, determined from data.</span>
<span class="sd">                Defaults to None.</span>
<span class="sd">            add_points (bool, optional): If True, overlay evaluated points on contour plots.</span>
<span class="sd">                Defaults to True.</span>
<span class="sd">            grid_visible (bool, optional): If True, show grid lines on contour plots. Defaults to True.</span>
<span class="sd">            contour_levels (int, optional): Number of contour levels. Defaults to 30.</span>
<span class="sd">            figsize (tuple of int, optional): Figure size in inches (width, height). Defaults to (12, 10).</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If optimization hasn&#39;t been run yet, or if i, j are invalid.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; def sphere(X):</span>
<span class="sd">            ...     return np.sum(X**2, axis=1)</span>
<span class="sd">            &gt;&gt;&gt; # Example 1: Using var_name in constructor</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=sphere, bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...                 max_iter=10, n_initial=5, var_name=[&#39;x1&#39;, &#39;x2&#39;])</span>
<span class="sd">            &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">            &gt;&gt;&gt; opt.plot_surrogate(i=0, j=1)  # Uses instance var_name</span>
<span class="sd">            &gt;&gt;&gt; # Example 2: Override var_name for this plot</span>
<span class="sd">            &gt;&gt;&gt; opt.plot_surrogate(i=0, j=1, var_name=[&#39;custom1&#39;, &#39;custom2&#39;])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Validation</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No optimization data available. Run optimize() first.&quot;</span><span class="p">)</span>

        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">k</span> <span class="ow">or</span> <span class="n">j</span> <span class="o">&gt;=</span> <span class="n">k</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dimensions i=</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> and j=</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s2"> must be less than n_dim=</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">j</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Dimensions i and j must be different.&quot;</span><span class="p">)</span>

        <span class="c1"># Use instance var_name if not provided</span>
        <span class="k">if</span> <span class="n">var_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">var_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span>

        <span class="c1"># Generate mesh grid</span>
        <span class="n">X_i</span><span class="p">,</span> <span class="n">X_j</span><span class="p">,</span> <span class="n">grid_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_mesh_grid</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span>

        <span class="c1"># Predict on grid</span>
        <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">grid_points</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">Z_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_i</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">Z_std</span> <span class="o">=</span> <span class="n">y_std</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_i</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="c1"># Create figure</span>
        <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>

        <span class="c1"># Plot 1: 3D surface of predictions</span>
        <span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s2">&quot;3d&quot;</span><span class="p">)</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">X_i</span><span class="p">,</span> <span class="n">X_j</span><span class="p">,</span> <span class="n">Z_pred</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Prediction Surface&quot;</span><span class="p">)</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">var_name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">var_name</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">var_name</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">if</span> <span class="n">var_name</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s2">&quot;Prediction&quot;</span><span class="p">)</span>

        <span class="c1"># Plot 2: 3D surface of prediction uncertainty</span>
        <span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s2">&quot;3d&quot;</span><span class="p">)</span>
        <span class="n">ax2</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">X_i</span><span class="p">,</span> <span class="n">X_j</span><span class="p">,</span> <span class="n">Z_std</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
        <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Prediction Uncertainty Surface&quot;</span><span class="p">)</span>
        <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">var_name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">var_name</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">var_name</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">if</span> <span class="n">var_name</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">ax2</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s2">&quot;Std. Dev.&quot;</span><span class="p">)</span>

        <span class="c1"># Plot 3: Contour of predictions</span>
        <span class="n">ax3</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>
        <span class="n">contour3</span> <span class="o">=</span> <span class="n">ax3</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span>
            <span class="n">X_i</span><span class="p">,</span> <span class="n">X_j</span><span class="p">,</span> <span class="n">Z_pred</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="n">contour_levels</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span>
        <span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">contour3</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax3</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">add_points</span><span class="p">:</span>
            <span class="n">ax3</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">[:,</span> <span class="n">j</span><span class="p">],</span>
                <span class="n">c</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span>
                <span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
                <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
                <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Evaluated points&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">ax3</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Prediction Contour&quot;</span><span class="p">)</span>
        <span class="n">ax3</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">var_name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">var_name</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">ax3</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">var_name</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">if</span> <span class="n">var_name</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">ax3</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">visible</span><span class="o">=</span><span class="n">grid_visible</span><span class="p">)</span>

        <span class="c1"># Plot 4: Contour of prediction uncertainty</span>
        <span class="n">ax4</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">224</span><span class="p">)</span>
        <span class="n">contour4</span> <span class="o">=</span> <span class="n">ax4</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">X_i</span><span class="p">,</span> <span class="n">X_j</span><span class="p">,</span> <span class="n">Z_std</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="n">contour_levels</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">contour4</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax4</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">add_points</span><span class="p">:</span>
            <span class="n">ax4</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">[:,</span> <span class="n">j</span><span class="p">],</span>
                <span class="n">c</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span>
                <span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
                <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
                <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Evaluated points&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">ax4</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">ax4</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Uncertainty Contour&quot;</span><span class="p">)</span>
        <span class="n">ax4</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">var_name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">var_name</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">ax4</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">var_name</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">if</span> <span class="n">var_name</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">ax4</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">visible</span><span class="o">=</span><span class="n">grid_visible</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">show</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_mesh_grid</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate a mesh grid for two dimensions, filling others with mean values.</span>

<span class="sd">        Args:</span>
<span class="sd">            i (int): Index of the first dimension to vary.</span>
<span class="sd">            j (int): Index of the second dimension to vary.</span>
<span class="sd">            num (int, optional): Number of grid points per dimension. Defaults to 100.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: A tuple containing:</span>
<span class="sd">                - X_i (ndarray): Meshgrid for dimension i.</span>
<span class="sd">                - X_j (ndarray): Meshgrid for dimension j.</span>
<span class="sd">                - grid_points (ndarray): Grid points for prediction, shape (num*num, n_dim).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span>
        <span class="n">mean_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Create grid for dimensions i and j</span>
        <span class="n">x_i</span> <span class="o">=</span> <span class="n">linspace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">upper</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">num</span><span class="o">=</span><span class="n">num</span><span class="p">)</span>
        <span class="n">x_j</span> <span class="o">=</span> <span class="n">linspace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">upper</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">num</span><span class="o">=</span><span class="n">num</span><span class="p">)</span>
        <span class="n">X_i</span><span class="p">,</span> <span class="n">X_j</span> <span class="o">=</span> <span class="n">meshgrid</span><span class="p">(</span><span class="n">x_i</span><span class="p">,</span> <span class="n">x_j</span><span class="p">)</span>

        <span class="c1"># Initialize grid points with mean values</span>
        <span class="n">grid_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">mean_values</span><span class="p">,</span> <span class="p">(</span><span class="n">X_i</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">grid_points</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_i</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="n">grid_points</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_j</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

        <span class="c1"># Apply type constraints</span>
        <span class="n">grid_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repair_non_numeric</span><span class="p">(</span><span class="n">grid_points</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">X_i</span><span class="p">,</span> <span class="n">X_j</span><span class="p">,</span> <span class="n">grid_points</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_experiment_filename</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate experiment filename from prefix.</span>

<span class="sd">        Args:</span>
<span class="sd">            prefix (str): Prefix for the filename.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: Filename with &#39;_exp.pkl&#39; suffix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">prefix</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;experiment_exp.pkl&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_exp.pkl&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_result_filename</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate result filename from prefix.</span>

<span class="sd">        Args:</span>
<span class="sd">            prefix (str): Prefix for the filename.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: Filename with &#39;_res.pkl&#39; suffix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">prefix</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;result_res.pkl&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_res.pkl&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_close_and_del_tensorboard_writer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Close and delete TensorBoard writer to prepare for pickling.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;tb_writer&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="k">pass</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_pickle_safe_optimizer</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">unpickleables</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;file_io&quot;</span><span class="p">,</span> <span class="n">verbosity</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;SpotOptim&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a pickle-safe copy of the optimizer.</span>

<span class="sd">        This method creates a copy of the optimizer instance with unpickleable components removed</span>
<span class="sd">        or set to None to enable safe serialization.</span>

<span class="sd">        Args:</span>
<span class="sd">            unpickleables (str): Type of unpickleable components to exclude.</span>
<span class="sd">                - &quot;file_io&quot;: Excludes only file I/O components (tb_writer) and fun</span>
<span class="sd">                - &quot;all&quot;: Excludes file I/O, fun, surrogate, and lhs_sampler</span>
<span class="sd">                Defaults to &quot;file_io&quot;.</span>
<span class="sd">            verbosity (int): Verbosity level (0=silent, 1=basic, 2=detailed). Defaults to 0.</span>

<span class="sd">        Returns:</span>
<span class="sd">            SpotOptim: A copy of the optimizer with unpickleable components removed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Always exclude fun and tb_writer (can&#39;t reliably pickle lambda/local functions)</span>
        <span class="c1"># Determine which additional attributes to exclude</span>
        <span class="k">if</span> <span class="n">unpickleables</span> <span class="o">==</span> <span class="s2">&quot;file_io&quot;</span><span class="p">:</span>
            <span class="n">unpickleable_attrs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;tb_writer&quot;</span><span class="p">,</span> <span class="s2">&quot;fun&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">unpickleable_attrs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;tb_writer&quot;</span><span class="p">,</span> <span class="s2">&quot;fun&quot;</span><span class="p">,</span> <span class="s2">&quot;surrogate&quot;</span><span class="p">,</span> <span class="s2">&quot;lhs_sampler&quot;</span><span class="p">]</span>

        <span class="c1"># Prepare picklable state dictionary</span>
        <span class="n">picklable_state</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">unpickleable_attrs</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># Test if attribute can be pickled</span>
                    <span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="n">pickle</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>
                    <span class="n">picklable_state</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                    <span class="k">if</span> <span class="n">verbosity</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Attribute &#39;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">&#39; is picklable and will be included.&quot;</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">verbosity</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Attribute &#39;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">&#39; is not picklable and will be excluded: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>
                    <span class="k">continue</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">verbosity</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Attribute &#39;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">&#39; explicitly excluded from pickling.&quot;</span><span class="p">)</span>

        <span class="c1"># Create new instance with picklable state</span>
        <span class="n">picklable_instance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="fm">__new__</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">)</span>
        <span class="n">picklable_instance</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">picklable_state</span><span class="p">)</span>

        <span class="c1"># Set excluded attributes to None</span>
        <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">unpickleable_attrs</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">picklable_instance</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="n">picklable_instance</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">picklable_instance</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save_experiment</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;experiment&quot;</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">overwrite</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">unpickleables</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;all&quot;</span><span class="p">,</span>
        <span class="n">verbosity</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save the experiment configuration to a pickle file.</span>

<span class="sd">        An experiment contains the optimizer configuration needed to run optimization,</span>
<span class="sd">        but excludes the results. This is useful for defining experiments locally and</span>
<span class="sd">        executing them on remote machines.</span>

<span class="sd">        The experiment includes:</span>
<span class="sd">        - Bounds, variable types, variable names</span>
<span class="sd">        - Optimization parameters (max_iter, n_initial, etc.)</span>
<span class="sd">        - Surrogate and acquisition settings</span>
<span class="sd">        - Random seed</span>

<span class="sd">        The experiment excludes:</span>
<span class="sd">        - Function evaluations (X_, y_)</span>
<span class="sd">        - Optimization results</span>
<span class="sd">        - Objective function (must be re-attached after loading)</span>

<span class="sd">        Args:</span>
<span class="sd">            filename (str, optional): Filename for the experiment file. If None, generates</span>
<span class="sd">                from prefix. Defaults to None.</span>
<span class="sd">            prefix (str): Prefix for auto-generated filename. Defaults to &quot;experiment&quot;.</span>
<span class="sd">            path (str, optional): Directory path to save the file. If None, saves in current</span>
<span class="sd">                directory. Creates directory if it doesn&#39;t exist. Defaults to None.</span>
<span class="sd">            overwrite (bool): If True, overwrites existing file. If False, raises error if</span>
<span class="sd">                file exists. Defaults to True.</span>
<span class="sd">            unpickleables (str): Components to exclude for pickling:</span>
<span class="sd">                - &quot;all&quot;: Excludes fun, surrogate, lhs_sampler, tb_writer (experiment only)</span>
<span class="sd">                - &quot;file_io&quot;: Excludes only tb_writer (lighter exclusion)</span>
<span class="sd">                Defaults to &quot;all&quot;.</span>
<span class="sd">            verbosity (int): Verbosity level (0=silent, 1=basic, 2=detailed). Defaults to 0.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Define experiment locally</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     max_iter=30,</span>
<span class="sd">            ...     n_initial=10,</span>
<span class="sd">            ...     seed=42</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Save experiment (without results)</span>
<span class="sd">            &gt;&gt;&gt; opt.save_experiment(prefix=&quot;sphere_opt&quot;)</span>
<span class="sd">            Experiment saved to sphere_opt_exp.pkl</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # On remote machine: load and run</span>
<span class="sd">            &gt;&gt;&gt; # opt_remote = SpotOptim.load_experiment(&quot;sphere_opt_exp.pkl&quot;)</span>
<span class="sd">            &gt;&gt;&gt; # opt_remote.fun = objective_function  # Re-attach function</span>
<span class="sd">            &gt;&gt;&gt; # result = opt_remote.optimize()</span>
<span class="sd">            &gt;&gt;&gt; # opt_remote.save_result(prefix=&quot;sphere_opt&quot;)  # Save results</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Close TensorBoard writer before pickling</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_close_and_del_tensorboard_writer</span><span class="p">()</span>

        <span class="c1"># Create pickle-safe copy</span>
        <span class="n">optimizer_copy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_pickle_safe_optimizer</span><span class="p">(</span>
            <span class="n">unpickleables</span><span class="o">=</span><span class="n">unpickleables</span><span class="p">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="n">verbosity</span>
        <span class="p">)</span>

        <span class="c1"># Determine filename</span>
        <span class="k">if</span> <span class="n">filename</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_experiment_filename</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span>

        <span class="c1"># Add path if provided</span>
        <span class="k">if</span> <span class="n">path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
                <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>

        <span class="c1"># Check for existing file</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">overwrite</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">FileExistsError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;File </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2"> already exists. Use overwrite=True to overwrite.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Save to pickle file</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
                <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">optimizer_copy</span><span class="p">,</span> <span class="n">handle</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="n">pickle</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Experiment saved to </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error during pickling: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save_result</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;result&quot;</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">overwrite</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">verbosity</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save the complete optimization results to a pickle file.</span>

<span class="sd">        A result contains all information from a completed optimization run, including</span>
<span class="sd">        the experiment configuration and all evaluation results. This is useful for</span>
<span class="sd">        saving completed runs for later analysis.</span>

<span class="sd">        The result includes everything in an experiment plus:</span>
<span class="sd">        - All evaluated points (X_)</span>
<span class="sd">        - All function values (y_)</span>
<span class="sd">        - Best point and best value</span>
<span class="sd">        - Iteration count</span>
<span class="sd">        - Success rate statistics</span>
<span class="sd">        - Noise statistics (if applicable)</span>

<span class="sd">        Args:</span>
<span class="sd">            filename (str, optional): Filename for the result file. If None, generates</span>
<span class="sd">                from prefix. Defaults to None.</span>
<span class="sd">            prefix (str): Prefix for auto-generated filename. Defaults to &quot;result&quot;.</span>
<span class="sd">            path (str, optional): Directory path to save the file. If None, saves in current</span>
<span class="sd">                directory. Creates directory if it doesn&#39;t exist. Defaults to None.</span>
<span class="sd">            overwrite (bool): If True, overwrites existing file. If False, raises error if</span>
<span class="sd">                file exists. Defaults to True.</span>
<span class="sd">            verbosity (int): Verbosity level (0=silent, 1=basic, 2=detailed). Defaults to 0.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Run optimization</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     max_iter=30,</span>
<span class="sd">            ...     n_initial=10,</span>
<span class="sd">            ...     seed=42</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Save complete results</span>
<span class="sd">            &gt;&gt;&gt; opt.save_result(prefix=&quot;sphere_opt&quot;)</span>
<span class="sd">            Result saved to sphere_opt_res.pkl</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Later: load and analyze</span>
<span class="sd">            &gt;&gt;&gt; # opt_loaded = SpotOptim.load_result(&quot;sphere_opt_res.pkl&quot;)</span>
<span class="sd">            &gt;&gt;&gt; # print(&quot;Best value:&quot;, opt_loaded.best_y_)</span>
<span class="sd">            &gt;&gt;&gt; # opt_loaded.plot_surrogate()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Use save_experiment with file_io unpickleables to preserve results</span>
        <span class="k">if</span> <span class="n">filename</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_result_filename</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">save_experiment</span><span class="p">(</span>
            <span class="n">filename</span><span class="o">=</span><span class="n">filename</span><span class="p">,</span>
            <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">overwrite</span><span class="o">=</span><span class="n">overwrite</span><span class="p">,</span>
            <span class="n">unpickleables</span><span class="o">=</span><span class="s2">&quot;file_io&quot;</span><span class="p">,</span>
            <span class="n">verbosity</span><span class="o">=</span><span class="n">verbosity</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Update message</span>
        <span class="k">if</span> <span class="n">path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">full_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">full_path</span> <span class="o">=</span> <span class="n">filename</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Result saved to </span><span class="si">{</span><span class="n">full_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reinitialize_components</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reinitialize components that were excluded during pickling.</span>

<span class="sd">        This method recreates the surrogate model and LHS sampler that were</span>
<span class="sd">        excluded when saving an experiment or result.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Reinitialize LHS sampler if needed</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;lhs_sampler&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">lhs_sampler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lhs_sampler</span> <span class="o">=</span> <span class="n">LatinHypercube</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="c1"># Reinitialize surrogate if needed</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;surrogate&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">kernel</span> <span class="o">=</span> <span class="n">ConstantKernel</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span> <span class="o">*</span> <span class="n">Matern</span><span class="p">(</span>
                <span class="n">length_scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">),</span>
                <span class="n">length_scale_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">1e-2</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">),</span>
                <span class="n">nu</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span>
                <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span>
                <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
                <span class="n">normalize_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_experiment</span><span class="p">(</span><span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;SpotOptim&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load an experiment configuration from a pickle file.</span>

<span class="sd">        Loads an experiment that was saved with save_experiment(). The loaded optimizer</span>
<span class="sd">        will have the configuration but not the objective function (which must be</span>
<span class="sd">        re-attached) or results.</span>

<span class="sd">        Args:</span>
<span class="sd">            filename (str): Path to the experiment pickle file.</span>

<span class="sd">        Returns:</span>
<span class="sd">            SpotOptim: Loaded optimizer instance (without fun attached).</span>

<span class="sd">        Raises:</span>
<span class="sd">            FileNotFoundError: If the specified file doesn&#39;t exist.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Load experiment</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim.load_experiment(&quot;sphere_opt_exp.pkl&quot;)</span>
<span class="sd">            Loaded experiment from sphere_opt_exp.pkl</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Re-attach objective function</span>
<span class="sd">            &gt;&gt;&gt; opt.fun = lambda X: np.sum(X**2, axis=1)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Run optimization</span>
<span class="sd">            &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Experiment file not found: </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded experiment from </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Reinitialize components that were excluded</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">_reinitialize_components</span><span class="p">()</span>

            <span class="k">return</span> <span class="n">optimizer</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error loading experiment: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_result</span><span class="p">(</span><span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;SpotOptim&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load complete optimization results from a pickle file.</span>

<span class="sd">        Loads results that were saved with save_result(). The loaded optimizer</span>
<span class="sd">        will have both configuration and all optimization results.</span>

<span class="sd">        Args:</span>
<span class="sd">            filename (str): Path to the result pickle file.</span>

<span class="sd">        Returns:</span>
<span class="sd">            SpotOptim: Loaded optimizer instance with complete results.</span>

<span class="sd">        Raises:</span>
<span class="sd">            FileNotFoundError: If the specified file doesn&#39;t exist.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Load results</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim.load_result(&quot;sphere_opt_res.pkl&quot;)</span>
<span class="sd">            Loaded result from sphere_opt_res.pkl</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Analyze results</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Best point:&quot;, opt.best_x_)</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Best value:&quot;, opt.best_y_)</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Total evaluations:&quot;, opt.counter)</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Success rate:&quot;, opt.success_rate)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Continue optimization if needed</span>
<span class="sd">            &gt;&gt;&gt; # opt.fun = lambda X: np.sum(X**2, axis=1)  # Re-attach if continuing</span>
<span class="sd">            &gt;&gt;&gt; # opt.max_iter = 50  # Increase budget</span>
<span class="sd">            &gt;&gt;&gt; # result = opt.optimize()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Result file not found: </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded result from </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Reinitialize components that were excluded</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">_reinitialize_components</span><span class="p">()</span>

            <span class="k">return</span> <span class="n">optimizer</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error loading result: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.load_experiment" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load_experiment</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#spotoptim.SpotOptim.SpotOptim.load_experiment" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Load an experiment configuration from a pickle file.</p>
<p>Loads an experiment that was saved with save_experiment(). The loaded optimizer
will have the configuration but not the objective function (which must be
re-attached) or results.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>filename</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path to the experiment pickle file.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>SpotOptim</code></td>            <td>
                  <code><a class="autorefs autorefs-internal" title="SpotOptim (spotoptim.SpotOptim.SpotOptim)" href="#spotoptim.SpotOptim.SpotOptim">SpotOptim</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Loaded optimizer instance (without fun attached).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="FileNotFoundError">FileNotFoundError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If the specified file doesn&rsquo;t exist.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Load experiment</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="o">.</span><span class="n">load_experiment</span><span class="p">(</span><span class="s2">&quot;sphere_opt_exp.pkl&quot;</span><span class="p">)</span>
<span class="go">Loaded experiment from sphere_opt_exp.pkl</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Re-attach objective function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">fun</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Run optimization</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2226</span>
<span class="normal">2227</span>
<span class="normal">2228</span>
<span class="normal">2229</span>
<span class="normal">2230</span>
<span class="normal">2231</span>
<span class="normal">2232</span>
<span class="normal">2233</span>
<span class="normal">2234</span>
<span class="normal">2235</span>
<span class="normal">2236</span>
<span class="normal">2237</span>
<span class="normal">2238</span>
<span class="normal">2239</span>
<span class="normal">2240</span>
<span class="normal">2241</span>
<span class="normal">2242</span>
<span class="normal">2243</span>
<span class="normal">2244</span>
<span class="normal">2245</span>
<span class="normal">2246</span>
<span class="normal">2247</span>
<span class="normal">2248</span>
<span class="normal">2249</span>
<span class="normal">2250</span>
<span class="normal">2251</span>
<span class="normal">2252</span>
<span class="normal">2253</span>
<span class="normal">2254</span>
<span class="normal">2255</span>
<span class="normal">2256</span>
<span class="normal">2257</span>
<span class="normal">2258</span>
<span class="normal">2259</span>
<span class="normal">2260</span>
<span class="normal">2261</span>
<span class="normal">2262</span>
<span class="normal">2263</span>
<span class="normal">2264</span>
<span class="normal">2265</span>
<span class="normal">2266</span>
<span class="normal">2267</span>
<span class="normal">2268</span>
<span class="normal">2269</span>
<span class="normal">2270</span>
<span class="normal">2271</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">load_experiment</span><span class="p">(</span><span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;SpotOptim&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load an experiment configuration from a pickle file.</span>

<span class="sd">    Loads an experiment that was saved with save_experiment(). The loaded optimizer</span>
<span class="sd">    will have the configuration but not the objective function (which must be</span>
<span class="sd">    re-attached) or results.</span>

<span class="sd">    Args:</span>
<span class="sd">        filename (str): Path to the experiment pickle file.</span>

<span class="sd">    Returns:</span>
<span class="sd">        SpotOptim: Loaded optimizer instance (without fun attached).</span>

<span class="sd">    Raises:</span>
<span class="sd">        FileNotFoundError: If the specified file doesn&#39;t exist.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Load experiment</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim.load_experiment(&quot;sphere_opt_exp.pkl&quot;)</span>
<span class="sd">        Loaded experiment from sphere_opt_exp.pkl</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Re-attach objective function</span>
<span class="sd">        &gt;&gt;&gt; opt.fun = lambda X: np.sum(X**2, axis=1)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Run optimization</span>
<span class="sd">        &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Experiment file not found: </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded experiment from </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Reinitialize components that were excluded</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">_reinitialize_components</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">optimizer</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error loading experiment: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.load_result" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load_result</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#spotoptim.SpotOptim.SpotOptim.load_result" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Load complete optimization results from a pickle file.</p>
<p>Loads results that were saved with save_result(). The loaded optimizer
will have both configuration and all optimization results.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>filename</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path to the result pickle file.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>SpotOptim</code></td>            <td>
                  <code><a class="autorefs autorefs-internal" title="SpotOptim (spotoptim.SpotOptim.SpotOptim)" href="#spotoptim.SpotOptim.SpotOptim">SpotOptim</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Loaded optimizer instance with complete results.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="FileNotFoundError">FileNotFoundError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If the specified file doesn&rsquo;t exist.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Load results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="o">.</span><span class="n">load_result</span><span class="p">(</span><span class="s2">&quot;sphere_opt_res.pkl&quot;</span><span class="p">)</span>
<span class="go">Loaded result from sphere_opt_res.pkl</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Analyze results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best point:&quot;</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">best_x_</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best value:&quot;</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">best_y_</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total evaluations:&quot;</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">counter</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Success rate:&quot;</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">success_rate</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Continue optimization if needed</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># opt.fun = lambda X: np.sum(X**2, axis=1)  # Re-attach if continuing</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># opt.max_iter = 50  # Increase budget</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result = opt.optimize()</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2273</span>
<span class="normal">2274</span>
<span class="normal">2275</span>
<span class="normal">2276</span>
<span class="normal">2277</span>
<span class="normal">2278</span>
<span class="normal">2279</span>
<span class="normal">2280</span>
<span class="normal">2281</span>
<span class="normal">2282</span>
<span class="normal">2283</span>
<span class="normal">2284</span>
<span class="normal">2285</span>
<span class="normal">2286</span>
<span class="normal">2287</span>
<span class="normal">2288</span>
<span class="normal">2289</span>
<span class="normal">2290</span>
<span class="normal">2291</span>
<span class="normal">2292</span>
<span class="normal">2293</span>
<span class="normal">2294</span>
<span class="normal">2295</span>
<span class="normal">2296</span>
<span class="normal">2297</span>
<span class="normal">2298</span>
<span class="normal">2299</span>
<span class="normal">2300</span>
<span class="normal">2301</span>
<span class="normal">2302</span>
<span class="normal">2303</span>
<span class="normal">2304</span>
<span class="normal">2305</span>
<span class="normal">2306</span>
<span class="normal">2307</span>
<span class="normal">2308</span>
<span class="normal">2309</span>
<span class="normal">2310</span>
<span class="normal">2311</span>
<span class="normal">2312</span>
<span class="normal">2313</span>
<span class="normal">2314</span>
<span class="normal">2315</span>
<span class="normal">2316</span>
<span class="normal">2317</span>
<span class="normal">2318</span>
<span class="normal">2319</span>
<span class="normal">2320</span>
<span class="normal">2321</span>
<span class="normal">2322</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">load_result</span><span class="p">(</span><span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;SpotOptim&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load complete optimization results from a pickle file.</span>

<span class="sd">    Loads results that were saved with save_result(). The loaded optimizer</span>
<span class="sd">    will have both configuration and all optimization results.</span>

<span class="sd">    Args:</span>
<span class="sd">        filename (str): Path to the result pickle file.</span>

<span class="sd">    Returns:</span>
<span class="sd">        SpotOptim: Loaded optimizer instance with complete results.</span>

<span class="sd">    Raises:</span>
<span class="sd">        FileNotFoundError: If the specified file doesn&#39;t exist.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Load results</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim.load_result(&quot;sphere_opt_res.pkl&quot;)</span>
<span class="sd">        Loaded result from sphere_opt_res.pkl</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Analyze results</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Best point:&quot;, opt.best_x_)</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Best value:&quot;, opt.best_y_)</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Total evaluations:&quot;, opt.counter)</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Success rate:&quot;, opt.success_rate)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Continue optimization if needed</span>
<span class="sd">        &gt;&gt;&gt; # opt.fun = lambda X: np.sum(X**2, axis=1)  # Re-attach if continuing</span>
<span class="sd">        &gt;&gt;&gt; # opt.max_iter = 50  # Increase budget</span>
<span class="sd">        &gt;&gt;&gt; # result = opt.optimize()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Result file not found: </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded result from </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Reinitialize components that were excluded</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">_reinitialize_components</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">optimizer</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error loading result: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.optimize" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">optimize</span><span class="p">(</span><span class="n">X0</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.optimize" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run the optimization process.</p>
<p>The optimization terminates when either:
- Total function evaluations reach max_iter (including initial design), OR
- Runtime exceeds max_time minutes</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>X0</code>
            </td>
            <td>
                  <code><span title="ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Initial design points, shape (n_initial, n_features).
If None, generates space-filling design. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>OptimizeResult</code></td>            <td>
                  <code><span title="scipy.optimize.OptimizeResult">OptimizeResult</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optimization result with fields:
- x: best point found
- fun: best function value
- nfev: number of function evaluations (including initial design)
- nit: number of sequential optimization iterations (after initial design)
- success: whether optimization succeeded
- message: termination message indicating reason for stopping
- X: all evaluated points
- y: all function values</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 1: Budget-based termination</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Will perform 10 initial + 20 sequential iterations = 30 total evaluations</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 2: Time-based termination</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="n">expensive_objective</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
<span class="gp">... </span>                <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">max_time</span><span class="o">=</span><span class="mf">5.0</span><span class="p">)</span>  <span class="c1"># 5 minutes max</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Will stop after 5 minutes OR 1000 evaluations, whichever comes first</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1544</span>
<span class="normal">1545</span>
<span class="normal">1546</span>
<span class="normal">1547</span>
<span class="normal">1548</span>
<span class="normal">1549</span>
<span class="normal">1550</span>
<span class="normal">1551</span>
<span class="normal">1552</span>
<span class="normal">1553</span>
<span class="normal">1554</span>
<span class="normal">1555</span>
<span class="normal">1556</span>
<span class="normal">1557</span>
<span class="normal">1558</span>
<span class="normal">1559</span>
<span class="normal">1560</span>
<span class="normal">1561</span>
<span class="normal">1562</span>
<span class="normal">1563</span>
<span class="normal">1564</span>
<span class="normal">1565</span>
<span class="normal">1566</span>
<span class="normal">1567</span>
<span class="normal">1568</span>
<span class="normal">1569</span>
<span class="normal">1570</span>
<span class="normal">1571</span>
<span class="normal">1572</span>
<span class="normal">1573</span>
<span class="normal">1574</span>
<span class="normal">1575</span>
<span class="normal">1576</span>
<span class="normal">1577</span>
<span class="normal">1578</span>
<span class="normal">1579</span>
<span class="normal">1580</span>
<span class="normal">1581</span>
<span class="normal">1582</span>
<span class="normal">1583</span>
<span class="normal">1584</span>
<span class="normal">1585</span>
<span class="normal">1586</span>
<span class="normal">1587</span>
<span class="normal">1588</span>
<span class="normal">1589</span>
<span class="normal">1590</span>
<span class="normal">1591</span>
<span class="normal">1592</span>
<span class="normal">1593</span>
<span class="normal">1594</span>
<span class="normal">1595</span>
<span class="normal">1596</span>
<span class="normal">1597</span>
<span class="normal">1598</span>
<span class="normal">1599</span>
<span class="normal">1600</span>
<span class="normal">1601</span>
<span class="normal">1602</span>
<span class="normal">1603</span>
<span class="normal">1604</span>
<span class="normal">1605</span>
<span class="normal">1606</span>
<span class="normal">1607</span>
<span class="normal">1608</span>
<span class="normal">1609</span>
<span class="normal">1610</span>
<span class="normal">1611</span>
<span class="normal">1612</span>
<span class="normal">1613</span>
<span class="normal">1614</span>
<span class="normal">1615</span>
<span class="normal">1616</span>
<span class="normal">1617</span>
<span class="normal">1618</span>
<span class="normal">1619</span>
<span class="normal">1620</span>
<span class="normal">1621</span>
<span class="normal">1622</span>
<span class="normal">1623</span>
<span class="normal">1624</span>
<span class="normal">1625</span>
<span class="normal">1626</span>
<span class="normal">1627</span>
<span class="normal">1628</span>
<span class="normal">1629</span>
<span class="normal">1630</span>
<span class="normal">1631</span>
<span class="normal">1632</span>
<span class="normal">1633</span>
<span class="normal">1634</span>
<span class="normal">1635</span>
<span class="normal">1636</span>
<span class="normal">1637</span>
<span class="normal">1638</span>
<span class="normal">1639</span>
<span class="normal">1640</span>
<span class="normal">1641</span>
<span class="normal">1642</span>
<span class="normal">1643</span>
<span class="normal">1644</span>
<span class="normal">1645</span>
<span class="normal">1646</span>
<span class="normal">1647</span>
<span class="normal">1648</span>
<span class="normal">1649</span>
<span class="normal">1650</span>
<span class="normal">1651</span>
<span class="normal">1652</span>
<span class="normal">1653</span>
<span class="normal">1654</span>
<span class="normal">1655</span>
<span class="normal">1656</span>
<span class="normal">1657</span>
<span class="normal">1658</span>
<span class="normal">1659</span>
<span class="normal">1660</span>
<span class="normal">1661</span>
<span class="normal">1662</span>
<span class="normal">1663</span>
<span class="normal">1664</span>
<span class="normal">1665</span>
<span class="normal">1666</span>
<span class="normal">1667</span>
<span class="normal">1668</span>
<span class="normal">1669</span>
<span class="normal">1670</span>
<span class="normal">1671</span>
<span class="normal">1672</span>
<span class="normal">1673</span>
<span class="normal">1674</span>
<span class="normal">1675</span>
<span class="normal">1676</span>
<span class="normal">1677</span>
<span class="normal">1678</span>
<span class="normal">1679</span>
<span class="normal">1680</span>
<span class="normal">1681</span>
<span class="normal">1682</span>
<span class="normal">1683</span>
<span class="normal">1684</span>
<span class="normal">1685</span>
<span class="normal">1686</span>
<span class="normal">1687</span>
<span class="normal">1688</span>
<span class="normal">1689</span>
<span class="normal">1690</span>
<span class="normal">1691</span>
<span class="normal">1692</span>
<span class="normal">1693</span>
<span class="normal">1694</span>
<span class="normal">1695</span>
<span class="normal">1696</span>
<span class="normal">1697</span>
<span class="normal">1698</span>
<span class="normal">1699</span>
<span class="normal">1700</span>
<span class="normal">1701</span>
<span class="normal">1702</span>
<span class="normal">1703</span>
<span class="normal">1704</span>
<span class="normal">1705</span>
<span class="normal">1706</span>
<span class="normal">1707</span>
<span class="normal">1708</span>
<span class="normal">1709</span>
<span class="normal">1710</span>
<span class="normal">1711</span>
<span class="normal">1712</span>
<span class="normal">1713</span>
<span class="normal">1714</span>
<span class="normal">1715</span>
<span class="normal">1716</span>
<span class="normal">1717</span>
<span class="normal">1718</span>
<span class="normal">1719</span>
<span class="normal">1720</span>
<span class="normal">1721</span>
<span class="normal">1722</span>
<span class="normal">1723</span>
<span class="normal">1724</span>
<span class="normal">1725</span>
<span class="normal">1726</span>
<span class="normal">1727</span>
<span class="normal">1728</span>
<span class="normal">1729</span>
<span class="normal">1730</span>
<span class="normal">1731</span>
<span class="normal">1732</span>
<span class="normal">1733</span>
<span class="normal">1734</span>
<span class="normal">1735</span>
<span class="normal">1736</span>
<span class="normal">1737</span>
<span class="normal">1738</span>
<span class="normal">1739</span>
<span class="normal">1740</span>
<span class="normal">1741</span>
<span class="normal">1742</span>
<span class="normal">1743</span>
<span class="normal">1744</span>
<span class="normal">1745</span>
<span class="normal">1746</span>
<span class="normal">1747</span>
<span class="normal">1748</span>
<span class="normal">1749</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">optimize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X0</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OptimizeResult</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run the optimization process.</span>

<span class="sd">    The optimization terminates when either:</span>
<span class="sd">    - Total function evaluations reach max_iter (including initial design), OR</span>
<span class="sd">    - Runtime exceeds max_time minutes</span>

<span class="sd">    Args:</span>
<span class="sd">        X0 (ndarray, optional): Initial design points, shape (n_initial, n_features).</span>
<span class="sd">            If None, generates space-filling design. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        OptimizeResult: Optimization result with fields:</span>
<span class="sd">            - x: best point found</span>
<span class="sd">            - fun: best function value</span>
<span class="sd">            - nfev: number of function evaluations (including initial design)</span>
<span class="sd">            - nit: number of sequential optimization iterations (after initial design)</span>
<span class="sd">            - success: whether optimization succeeded</span>
<span class="sd">            - message: termination message indicating reason for stopping</span>
<span class="sd">            - X: all evaluated points</span>
<span class="sd">            - y: all function values</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; # Example 1: Budget-based termination</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(fun=objective, bounds=bounds, max_iter=30, n_initial=10)</span>
<span class="sd">        &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">        &gt;&gt;&gt; # Will perform 10 initial + 20 sequential iterations = 30 total evaluations</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 2: Time-based termination</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(fun=expensive_objective, bounds=bounds,</span>
<span class="sd">        ...                 max_iter=1000, max_time=5.0)  # 5 minutes max</span>
<span class="sd">        &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">        &gt;&gt;&gt; # Will stop after 5 minutes OR 1000 evaluations, whichever comes first</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Generate or use provided initial design</span>
    <span class="k">if</span> <span class="n">X0</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">X0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_initial_design</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">X0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">X0</span><span class="p">)</span>
        <span class="c1"># If X0 is in full dimensions and we have dimension reduction, reduce it</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span> <span class="ow">and</span> <span class="n">X0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">):</span>
            <span class="n">X0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_red_dim</span><span class="p">(</span><span class="n">X0</span><span class="p">)</span>
        <span class="n">X0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repair_non_numeric</span><span class="p">(</span><span class="n">X0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">)</span>

    <span class="c1"># Repeat initial design points if repeats_initial &gt; 1</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">repeats_initial</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">X0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">X0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">repeats_initial</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Evaluate initial design</span>
    <span class="n">y0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate_function</span><span class="p">(</span><span class="n">X0</span><span class="p">)</span>

    <span class="c1"># Update success rate BEFORE updating storage (initial design - all should be successes since starting from scratch)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_update_success_rate</span><span class="p">(</span><span class="n">y0</span><span class="p">)</span>

    <span class="c1"># Initialize storage</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="o">=</span> <span class="n">X0</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">y0</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Update stats after initial design</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">update_stats</span><span class="p">()</span>

    <span class="c1"># Log initial design to TensorBoard</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_write_tensorboard_hparams</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_write_tensorboard_scalars</span><span class="p">()</span>

    <span class="c1"># Initial best</span>
    <span class="n">best_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">[</span><span class="n">best_idx</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">[</span><span class="n">best_idx</span><span class="p">]</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Initial best: f(x) = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">, mean best: f(x) = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">min_mean_y</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initial best: f(x) = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Start timer for max_time check</span>
    <span class="n">timeout_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="c1"># Main optimization loop</span>
    <span class="c1"># Termination: continue while (total_evals &lt; max_iter) AND (elapsed_time &lt; max_time)</span>
    <span class="k">while</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
        <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">timeout_start</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_time</span> <span class="o">*</span> <span class="mi">60</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Fit surrogate (use mean_y if noise, otherwise y_)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_fit_surrogate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean_X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_y</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_fit_surrogate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>

        <span class="c1"># OCBA: Compute optimal budget allocation for noisy functions</span>
        <span class="c1"># This determines which existing design points should be re-evaluated</span>
        <span class="n">X_ocba</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">ocba_delta</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Check conditions for OCBA (need variance &gt; 0 and at least 3 points)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">):</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Warning: OCBA skipped (need &gt;2 points with variance &gt; 0)&quot;</span>
                    <span class="p">)</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">):</span>
                <span class="c1"># Get OCBA allocation</span>
                <span class="n">X_ocba</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_ocba_X</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">mean_X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ocba_delta</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="ow">and</span> <span class="n">X_ocba</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  OCBA: Adding </span><span class="si">{</span><span class="n">X_ocba</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> re-evaluation(s)&quot;</span><span class="p">)</span>

        <span class="c1"># Suggest next point</span>
        <span class="n">x_next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_suggest_next_point</span><span class="p">()</span>

        <span class="c1"># Repeat next point if repeats_surrogate &gt; 1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">repeats_surrogate</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">x_next_repeated</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
                <span class="n">x_next</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">repeats_surrogate</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x_next_repeated</span> <span class="o">=</span> <span class="n">x_next</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Append OCBA points to new design points (if applicable)</span>
        <span class="k">if</span> <span class="n">X_ocba</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x_next_repeated</span> <span class="o">=</span> <span class="n">append</span><span class="p">(</span><span class="n">X_ocba</span><span class="p">,</span> <span class="n">x_next_repeated</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Evaluate next point(s) including OCBA points</span>
        <span class="n">y_next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate_function</span><span class="p">(</span><span class="n">x_next_repeated</span><span class="p">)</span>

        <span class="c1"># Update success rate BEFORE updating storage (so it compares against previous best)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_success_rate</span><span class="p">(</span><span class="n">y_next</span><span class="p">)</span>

        <span class="c1"># Update storage</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">,</span> <span class="n">x_next_repeated</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">,</span> <span class="n">y_next</span><span class="p">)</span>

        <span class="c1"># Update stats</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_stats</span><span class="p">()</span>

        <span class="c1"># Log to TensorBoard</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Log each new evaluation</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_next</span><span class="p">)):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_write_tensorboard_hparams</span><span class="p">(</span><span class="n">x_next_repeated</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_next</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_write_tensorboard_scalars</span><span class="p">()</span>

        <span class="c1"># Update best</span>
        <span class="n">current_best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y_next</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">current_best</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="p">:</span>
            <span class="n">best_idx_in_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">y_next</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span> <span class="o">=</span> <span class="n">x_next_repeated</span><span class="p">[</span><span class="n">best_idx_in_new</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span> <span class="o">=</span> <span class="n">current_best</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span><span class="si">}</span><span class="s2">: New best f(x) = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">, mean best: f(x) = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">min_mean_y</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span><span class="si">}</span><span class="s2">: New best f(x) = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span><span class="p">:</span>
                <span class="n">mean_y_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_next</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span><span class="si">}</span><span class="s2">: mean f(x) = </span><span class="si">{</span><span class="n">mean_y_new</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span><span class="si">}</span><span class="s2">: f(x) = </span><span class="si">{</span><span class="n">y_next</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Expand results to full dimensions if needed</span>
    <span class="n">best_x_full</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to_all_dim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span>
        <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span>
    <span class="p">)</span>
    <span class="n">X_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_all_dim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span>

    <span class="c1"># Determine termination reason</span>
    <span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">timeout_start</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">:</span>
        <span class="n">message</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Optimization terminated: maximum evaluations (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="si">}</span><span class="s2">) reached&quot;</span>
    <span class="k">elif</span> <span class="n">elapsed_time</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_time</span> <span class="o">*</span> <span class="mi">60</span><span class="p">:</span>
        <span class="n">message</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Optimization terminated: time limit (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> min) reached&quot;</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">message</span> <span class="o">=</span> <span class="s2">&quot;Optimization finished successfully&quot;</span>

    <span class="c1"># Close TensorBoard writer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_close_tensorboard_writer</span><span class="p">()</span>

    <span class="c1"># Return scipy-style result</span>
    <span class="k">return</span> <span class="n">OptimizeResult</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">best_x_full</span><span class="p">,</span>
        <span class="n">fun</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="p">,</span>
        <span class="n">nfev</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">),</span>
        <span class="n">nit</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span><span class="p">,</span>
        <span class="n">success</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">message</span><span class="o">=</span><span class="n">message</span><span class="p">,</span>
        <span class="n">X</span><span class="o">=</span><span class="n">X_full</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.plot_surrogate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">plot_surrogate</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">j</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">var_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;jet&#39;</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">add_points</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">grid_visible</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">contour_levels</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.plot_surrogate" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Plot the surrogate model for two dimensions.</p>
<p>Creates a 2x2 plot showing:
- Top left: 3D surface of predictions
- Top right: 3D surface of prediction uncertainty
- Bottom left: Contour plot of predictions with evaluated points
- Bottom right: Contour plot of prediction uncertainty</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>i</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Index of the first dimension to plot. Defaults to 0.</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>j</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Index of the second dimension to plot. Defaults to 1.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>show</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, displays the plot immediately. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>alpha</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Transparency of the 3D surface plots (0=transparent, 1=opaque).
Defaults to 0.8.</p>
              </div>
            </td>
            <td>
                  <code>0.8</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>var_name</code>
            </td>
            <td>
                  <code>list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Names for each dimension. If None, uses instance var_name.
Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>cmap</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Matplotlib colormap name. Defaults to &lsquo;jet&rsquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;jet&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of grid points per dimension for mesh grid. Defaults to 100.</p>
              </div>
            </td>
            <td>
                  <code>100</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>vmin</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Minimum value for color scale. If None, determined from data.
Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>vmax</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum value for color scale. If None, determined from data.
Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>add_points</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, overlay evaluated points on contour plots.
Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>grid_visible</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, show grid lines on contour plots. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>contour_levels</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of contour levels. Defaults to 30.</p>
              </div>
            </td>
            <td>
                  <code>30</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>figsize</code>
            </td>
            <td>
                  <code>tuple of int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Figure size in inches (width, height). Defaults to (12, 10).</p>
              </div>
            </td>
            <td>
                  <code>(12, 10)</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If optimization hasn&rsquo;t been run yet, or if i, j are invalid.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">sphere</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 1: Using var_name in constructor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="n">sphere</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>                <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_initial</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">var_name</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">j</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Uses instance var_name</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 2: Override var_name for this plot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">j</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">var_name</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;custom1&#39;</span><span class="p">,</span> <span class="s1">&#39;custom2&#39;</span><span class="p">])</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1751</span>
<span class="normal">1752</span>
<span class="normal">1753</span>
<span class="normal">1754</span>
<span class="normal">1755</span>
<span class="normal">1756</span>
<span class="normal">1757</span>
<span class="normal">1758</span>
<span class="normal">1759</span>
<span class="normal">1760</span>
<span class="normal">1761</span>
<span class="normal">1762</span>
<span class="normal">1763</span>
<span class="normal">1764</span>
<span class="normal">1765</span>
<span class="normal">1766</span>
<span class="normal">1767</span>
<span class="normal">1768</span>
<span class="normal">1769</span>
<span class="normal">1770</span>
<span class="normal">1771</span>
<span class="normal">1772</span>
<span class="normal">1773</span>
<span class="normal">1774</span>
<span class="normal">1775</span>
<span class="normal">1776</span>
<span class="normal">1777</span>
<span class="normal">1778</span>
<span class="normal">1779</span>
<span class="normal">1780</span>
<span class="normal">1781</span>
<span class="normal">1782</span>
<span class="normal">1783</span>
<span class="normal">1784</span>
<span class="normal">1785</span>
<span class="normal">1786</span>
<span class="normal">1787</span>
<span class="normal">1788</span>
<span class="normal">1789</span>
<span class="normal">1790</span>
<span class="normal">1791</span>
<span class="normal">1792</span>
<span class="normal">1793</span>
<span class="normal">1794</span>
<span class="normal">1795</span>
<span class="normal">1796</span>
<span class="normal">1797</span>
<span class="normal">1798</span>
<span class="normal">1799</span>
<span class="normal">1800</span>
<span class="normal">1801</span>
<span class="normal">1802</span>
<span class="normal">1803</span>
<span class="normal">1804</span>
<span class="normal">1805</span>
<span class="normal">1806</span>
<span class="normal">1807</span>
<span class="normal">1808</span>
<span class="normal">1809</span>
<span class="normal">1810</span>
<span class="normal">1811</span>
<span class="normal">1812</span>
<span class="normal">1813</span>
<span class="normal">1814</span>
<span class="normal">1815</span>
<span class="normal">1816</span>
<span class="normal">1817</span>
<span class="normal">1818</span>
<span class="normal">1819</span>
<span class="normal">1820</span>
<span class="normal">1821</span>
<span class="normal">1822</span>
<span class="normal">1823</span>
<span class="normal">1824</span>
<span class="normal">1825</span>
<span class="normal">1826</span>
<span class="normal">1827</span>
<span class="normal">1828</span>
<span class="normal">1829</span>
<span class="normal">1830</span>
<span class="normal">1831</span>
<span class="normal">1832</span>
<span class="normal">1833</span>
<span class="normal">1834</span>
<span class="normal">1835</span>
<span class="normal">1836</span>
<span class="normal">1837</span>
<span class="normal">1838</span>
<span class="normal">1839</span>
<span class="normal">1840</span>
<span class="normal">1841</span>
<span class="normal">1842</span>
<span class="normal">1843</span>
<span class="normal">1844</span>
<span class="normal">1845</span>
<span class="normal">1846</span>
<span class="normal">1847</span>
<span class="normal">1848</span>
<span class="normal">1849</span>
<span class="normal">1850</span>
<span class="normal">1851</span>
<span class="normal">1852</span>
<span class="normal">1853</span>
<span class="normal">1854</span>
<span class="normal">1855</span>
<span class="normal">1856</span>
<span class="normal">1857</span>
<span class="normal">1858</span>
<span class="normal">1859</span>
<span class="normal">1860</span>
<span class="normal">1861</span>
<span class="normal">1862</span>
<span class="normal">1863</span>
<span class="normal">1864</span>
<span class="normal">1865</span>
<span class="normal">1866</span>
<span class="normal">1867</span>
<span class="normal">1868</span>
<span class="normal">1869</span>
<span class="normal">1870</span>
<span class="normal">1871</span>
<span class="normal">1872</span>
<span class="normal">1873</span>
<span class="normal">1874</span>
<span class="normal">1875</span>
<span class="normal">1876</span>
<span class="normal">1877</span>
<span class="normal">1878</span>
<span class="normal">1879</span>
<span class="normal">1880</span>
<span class="normal">1881</span>
<span class="normal">1882</span>
<span class="normal">1883</span>
<span class="normal">1884</span>
<span class="normal">1885</span>
<span class="normal">1886</span>
<span class="normal">1887</span>
<span class="normal">1888</span>
<span class="normal">1889</span>
<span class="normal">1890</span>
<span class="normal">1891</span>
<span class="normal">1892</span>
<span class="normal">1893</span>
<span class="normal">1894</span>
<span class="normal">1895</span>
<span class="normal">1896</span>
<span class="normal">1897</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">plot_surrogate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">i</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">j</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">show</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
    <span class="n">var_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">cmap</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;jet&quot;</span><span class="p">,</span>
    <span class="n">num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">vmin</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">vmax</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">add_points</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">grid_visible</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">contour_levels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
    <span class="n">figsize</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Plot the surrogate model for two dimensions.</span>

<span class="sd">    Creates a 2x2 plot showing:</span>
<span class="sd">    - Top left: 3D surface of predictions</span>
<span class="sd">    - Top right: 3D surface of prediction uncertainty</span>
<span class="sd">    - Bottom left: Contour plot of predictions with evaluated points</span>
<span class="sd">    - Bottom right: Contour plot of prediction uncertainty</span>

<span class="sd">    Args:</span>
<span class="sd">        i (int, optional): Index of the first dimension to plot. Defaults to 0.</span>
<span class="sd">        j (int, optional): Index of the second dimension to plot. Defaults to 1.</span>
<span class="sd">        show (bool, optional): If True, displays the plot immediately. Defaults to True.</span>
<span class="sd">        alpha (float, optional): Transparency of the 3D surface plots (0=transparent, 1=opaque).</span>
<span class="sd">            Defaults to 0.8.</span>
<span class="sd">        var_name (list of str, optional): Names for each dimension. If None, uses instance var_name.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        cmap (str, optional): Matplotlib colormap name. Defaults to &#39;jet&#39;.</span>
<span class="sd">        num (int, optional): Number of grid points per dimension for mesh grid. Defaults to 100.</span>
<span class="sd">        vmin (float, optional): Minimum value for color scale. If None, determined from data.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        vmax (float, optional): Maximum value for color scale. If None, determined from data.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        add_points (bool, optional): If True, overlay evaluated points on contour plots.</span>
<span class="sd">            Defaults to True.</span>
<span class="sd">        grid_visible (bool, optional): If True, show grid lines on contour plots. Defaults to True.</span>
<span class="sd">        contour_levels (int, optional): Number of contour levels. Defaults to 30.</span>
<span class="sd">        figsize (tuple of int, optional): Figure size in inches (width, height). Defaults to (12, 10).</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If optimization hasn&#39;t been run yet, or if i, j are invalid.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; def sphere(X):</span>
<span class="sd">        ...     return np.sum(X**2, axis=1)</span>
<span class="sd">        &gt;&gt;&gt; # Example 1: Using var_name in constructor</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(fun=sphere, bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...                 max_iter=10, n_initial=5, var_name=[&#39;x1&#39;, &#39;x2&#39;])</span>
<span class="sd">        &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">        &gt;&gt;&gt; opt.plot_surrogate(i=0, j=1)  # Uses instance var_name</span>
<span class="sd">        &gt;&gt;&gt; # Example 2: Override var_name for this plot</span>
<span class="sd">        &gt;&gt;&gt; opt.plot_surrogate(i=0, j=1, var_name=[&#39;custom1&#39;, &#39;custom2&#39;])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Validation</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No optimization data available. Run optimize() first.&quot;</span><span class="p">)</span>

    <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">k</span> <span class="ow">or</span> <span class="n">j</span> <span class="o">&gt;=</span> <span class="n">k</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dimensions i=</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> and j=</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s2"> must be less than n_dim=</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">j</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Dimensions i and j must be different.&quot;</span><span class="p">)</span>

    <span class="c1"># Use instance var_name if not provided</span>
    <span class="k">if</span> <span class="n">var_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">var_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span>

    <span class="c1"># Generate mesh grid</span>
    <span class="n">X_i</span><span class="p">,</span> <span class="n">X_j</span><span class="p">,</span> <span class="n">grid_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_mesh_grid</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span>

    <span class="c1"># Predict on grid</span>
    <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">grid_points</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">Z_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_i</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">Z_std</span> <span class="o">=</span> <span class="n">y_std</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_i</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="c1"># Create figure</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>

    <span class="c1"># Plot 1: 3D surface of predictions</span>
    <span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s2">&quot;3d&quot;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">X_i</span><span class="p">,</span> <span class="n">X_j</span><span class="p">,</span> <span class="n">Z_pred</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Prediction Surface&quot;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">var_name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">var_name</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">var_name</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">if</span> <span class="n">var_name</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s2">&quot;Prediction&quot;</span><span class="p">)</span>

    <span class="c1"># Plot 2: 3D surface of prediction uncertainty</span>
    <span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s2">&quot;3d&quot;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">X_i</span><span class="p">,</span> <span class="n">X_j</span><span class="p">,</span> <span class="n">Z_std</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Prediction Uncertainty Surface&quot;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">var_name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">var_name</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">var_name</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">if</span> <span class="n">var_name</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s2">&quot;Std. Dev.&quot;</span><span class="p">)</span>

    <span class="c1"># Plot 3: Contour of predictions</span>
    <span class="n">ax3</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>
    <span class="n">contour3</span> <span class="o">=</span> <span class="n">ax3</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span>
        <span class="n">X_i</span><span class="p">,</span> <span class="n">X_j</span><span class="p">,</span> <span class="n">Z_pred</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="n">contour_levels</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">contour3</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax3</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">add_points</span><span class="p">:</span>
        <span class="n">ax3</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">[:,</span> <span class="n">j</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span>
            <span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
            <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
            <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Evaluated points&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">ax3</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Prediction Contour&quot;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">var_name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">var_name</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">var_name</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">if</span> <span class="n">var_name</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">visible</span><span class="o">=</span><span class="n">grid_visible</span><span class="p">)</span>

    <span class="c1"># Plot 4: Contour of prediction uncertainty</span>
    <span class="n">ax4</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">224</span><span class="p">)</span>
    <span class="n">contour4</span> <span class="o">=</span> <span class="n">ax4</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">X_i</span><span class="p">,</span> <span class="n">X_j</span><span class="p">,</span> <span class="n">Z_std</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="n">contour_levels</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">contour4</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax4</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">add_points</span><span class="p">:</span>
        <span class="n">ax4</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">[:,</span> <span class="n">j</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span>
            <span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
            <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
            <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Evaluated points&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">ax4</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Uncertainty Contour&quot;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">var_name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">var_name</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">var_name</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">if</span> <span class="n">var_name</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">visible</span><span class="o">=</span><span class="n">grid_visible</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">show</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.save_experiment" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save_experiment</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;experiment&#39;</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">unpickleables</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.save_experiment" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Save the experiment configuration to a pickle file.</p>
<p>An experiment contains the optimizer configuration needed to run optimization,
but excludes the results. This is useful for defining experiments locally and
executing them on remote machines.</p>
<p>The experiment includes:
- Bounds, variable types, variable names
- Optimization parameters (max_iter, n_initial, etc.)
- Surrogate and acquisition settings
- Random seed</p>
<p>The experiment excludes:
- Function evaluations (X_, y_)
- Optimization results
- Objective function (must be re-attached after loading)</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>filename</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Filename for the experiment file. If None, generates
from prefix. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prefix</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Prefix for auto-generated filename. Defaults to &ldquo;experiment&rdquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;experiment&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>path</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Directory path to save the file. If None, saves in current
directory. Creates directory if it doesn&rsquo;t exist. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>overwrite</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, overwrites existing file. If False, raises error if
file exists. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>unpickleables</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Components to exclude for pickling:
- &ldquo;all&rdquo;: Excludes fun, surrogate, lhs_sampler, tb_writer (experiment only)
- &ldquo;file_io&rdquo;: Excludes only tb_writer (lighter exclusion)
Defaults to &ldquo;all&rdquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;all&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>verbosity</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Verbosity level (0=silent, 1=basic, 2=detailed). Defaults to 0.</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>None</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Define experiment locally</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Save experiment (without results)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">save_experiment</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;sphere_opt&quot;</span><span class="p">)</span>
<span class="go">Experiment saved to sphere_opt_exp.pkl</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># On remote machine: load and run</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># opt_remote = SpotOptim.load_experiment(&quot;sphere_opt_exp.pkl&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># opt_remote.fun = objective_function  # Re-attach function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result = opt_remote.optimize()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># opt_remote.save_result(prefix=&quot;sphere_opt&quot;)  # Save results</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2026</span>
<span class="normal">2027</span>
<span class="normal">2028</span>
<span class="normal">2029</span>
<span class="normal">2030</span>
<span class="normal">2031</span>
<span class="normal">2032</span>
<span class="normal">2033</span>
<span class="normal">2034</span>
<span class="normal">2035</span>
<span class="normal">2036</span>
<span class="normal">2037</span>
<span class="normal">2038</span>
<span class="normal">2039</span>
<span class="normal">2040</span>
<span class="normal">2041</span>
<span class="normal">2042</span>
<span class="normal">2043</span>
<span class="normal">2044</span>
<span class="normal">2045</span>
<span class="normal">2046</span>
<span class="normal">2047</span>
<span class="normal">2048</span>
<span class="normal">2049</span>
<span class="normal">2050</span>
<span class="normal">2051</span>
<span class="normal">2052</span>
<span class="normal">2053</span>
<span class="normal">2054</span>
<span class="normal">2055</span>
<span class="normal">2056</span>
<span class="normal">2057</span>
<span class="normal">2058</span>
<span class="normal">2059</span>
<span class="normal">2060</span>
<span class="normal">2061</span>
<span class="normal">2062</span>
<span class="normal">2063</span>
<span class="normal">2064</span>
<span class="normal">2065</span>
<span class="normal">2066</span>
<span class="normal">2067</span>
<span class="normal">2068</span>
<span class="normal">2069</span>
<span class="normal">2070</span>
<span class="normal">2071</span>
<span class="normal">2072</span>
<span class="normal">2073</span>
<span class="normal">2074</span>
<span class="normal">2075</span>
<span class="normal">2076</span>
<span class="normal">2077</span>
<span class="normal">2078</span>
<span class="normal">2079</span>
<span class="normal">2080</span>
<span class="normal">2081</span>
<span class="normal">2082</span>
<span class="normal">2083</span>
<span class="normal">2084</span>
<span class="normal">2085</span>
<span class="normal">2086</span>
<span class="normal">2087</span>
<span class="normal">2088</span>
<span class="normal">2089</span>
<span class="normal">2090</span>
<span class="normal">2091</span>
<span class="normal">2092</span>
<span class="normal">2093</span>
<span class="normal">2094</span>
<span class="normal">2095</span>
<span class="normal">2096</span>
<span class="normal">2097</span>
<span class="normal">2098</span>
<span class="normal">2099</span>
<span class="normal">2100</span>
<span class="normal">2101</span>
<span class="normal">2102</span>
<span class="normal">2103</span>
<span class="normal">2104</span>
<span class="normal">2105</span>
<span class="normal">2106</span>
<span class="normal">2107</span>
<span class="normal">2108</span>
<span class="normal">2109</span>
<span class="normal">2110</span>
<span class="normal">2111</span>
<span class="normal">2112</span>
<span class="normal">2113</span>
<span class="normal">2114</span>
<span class="normal">2115</span>
<span class="normal">2116</span>
<span class="normal">2117</span>
<span class="normal">2118</span>
<span class="normal">2119</span>
<span class="normal">2120</span>
<span class="normal">2121</span>
<span class="normal">2122</span>
<span class="normal">2123</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">save_experiment</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;experiment&quot;</span><span class="p">,</span>
    <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">unpickleables</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;all&quot;</span><span class="p">,</span>
    <span class="n">verbosity</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save the experiment configuration to a pickle file.</span>

<span class="sd">    An experiment contains the optimizer configuration needed to run optimization,</span>
<span class="sd">    but excludes the results. This is useful for defining experiments locally and</span>
<span class="sd">    executing them on remote machines.</span>

<span class="sd">    The experiment includes:</span>
<span class="sd">    - Bounds, variable types, variable names</span>
<span class="sd">    - Optimization parameters (max_iter, n_initial, etc.)</span>
<span class="sd">    - Surrogate and acquisition settings</span>
<span class="sd">    - Random seed</span>

<span class="sd">    The experiment excludes:</span>
<span class="sd">    - Function evaluations (X_, y_)</span>
<span class="sd">    - Optimization results</span>
<span class="sd">    - Objective function (must be re-attached after loading)</span>

<span class="sd">    Args:</span>
<span class="sd">        filename (str, optional): Filename for the experiment file. If None, generates</span>
<span class="sd">            from prefix. Defaults to None.</span>
<span class="sd">        prefix (str): Prefix for auto-generated filename. Defaults to &quot;experiment&quot;.</span>
<span class="sd">        path (str, optional): Directory path to save the file. If None, saves in current</span>
<span class="sd">            directory. Creates directory if it doesn&#39;t exist. Defaults to None.</span>
<span class="sd">        overwrite (bool): If True, overwrites existing file. If False, raises error if</span>
<span class="sd">            file exists. Defaults to True.</span>
<span class="sd">        unpickleables (str): Components to exclude for pickling:</span>
<span class="sd">            - &quot;all&quot;: Excludes fun, surrogate, lhs_sampler, tb_writer (experiment only)</span>
<span class="sd">            - &quot;file_io&quot;: Excludes only tb_writer (lighter exclusion)</span>
<span class="sd">            Defaults to &quot;all&quot;.</span>
<span class="sd">        verbosity (int): Verbosity level (0=silent, 1=basic, 2=detailed). Defaults to 0.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Define experiment locally</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...     max_iter=30,</span>
<span class="sd">        ...     n_initial=10,</span>
<span class="sd">        ...     seed=42</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Save experiment (without results)</span>
<span class="sd">        &gt;&gt;&gt; opt.save_experiment(prefix=&quot;sphere_opt&quot;)</span>
<span class="sd">        Experiment saved to sphere_opt_exp.pkl</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # On remote machine: load and run</span>
<span class="sd">        &gt;&gt;&gt; # opt_remote = SpotOptim.load_experiment(&quot;sphere_opt_exp.pkl&quot;)</span>
<span class="sd">        &gt;&gt;&gt; # opt_remote.fun = objective_function  # Re-attach function</span>
<span class="sd">        &gt;&gt;&gt; # result = opt_remote.optimize()</span>
<span class="sd">        &gt;&gt;&gt; # opt_remote.save_result(prefix=&quot;sphere_opt&quot;)  # Save results</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Close TensorBoard writer before pickling</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_close_and_del_tensorboard_writer</span><span class="p">()</span>

    <span class="c1"># Create pickle-safe copy</span>
    <span class="n">optimizer_copy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_pickle_safe_optimizer</span><span class="p">(</span>
        <span class="n">unpickleables</span><span class="o">=</span><span class="n">unpickleables</span><span class="p">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="n">verbosity</span>
    <span class="p">)</span>

    <span class="c1"># Determine filename</span>
    <span class="k">if</span> <span class="n">filename</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_experiment_filename</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span>

    <span class="c1"># Add path if provided</span>
    <span class="k">if</span> <span class="n">path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>

    <span class="c1"># Check for existing file</span>
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">overwrite</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">FileExistsError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;File </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2"> already exists. Use overwrite=True to overwrite.&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Save to pickle file</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">optimizer_copy</span><span class="p">,</span> <span class="n">handle</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="n">pickle</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Experiment saved to </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error during pickling: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.save_result" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save_result</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;result&#39;</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.save_result" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Save the complete optimization results to a pickle file.</p>
<p>A result contains all information from a completed optimization run, including
the experiment configuration and all evaluation results. This is useful for
saving completed runs for later analysis.</p>
<p>The result includes everything in an experiment plus:
- All evaluated points (X_)
- All function values (y_)
- Best point and best value
- Iteration count
- Success rate statistics
- Noise statistics (if applicable)</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>filename</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Filename for the result file. If None, generates
from prefix. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prefix</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Prefix for auto-generated filename. Defaults to &ldquo;result&rdquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;result&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>path</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Directory path to save the file. If None, saves in current
directory. Creates directory if it doesn&rsquo;t exist. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>overwrite</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, overwrites existing file. If False, raises error if
file exists. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>verbosity</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Verbosity level (0=silent, 1=basic, 2=detailed). Defaults to 0.</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>None</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Run optimization</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Save complete results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">save_result</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;sphere_opt&quot;</span><span class="p">)</span>
<span class="go">Result saved to sphere_opt_res.pkl</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Later: load and analyze</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># opt_loaded = SpotOptim.load_result(&quot;sphere_opt_res.pkl&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># print(&quot;Best value:&quot;, opt_loaded.best_y_)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># opt_loaded.plot_surrogate()</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2125</span>
<span class="normal">2126</span>
<span class="normal">2127</span>
<span class="normal">2128</span>
<span class="normal">2129</span>
<span class="normal">2130</span>
<span class="normal">2131</span>
<span class="normal">2132</span>
<span class="normal">2133</span>
<span class="normal">2134</span>
<span class="normal">2135</span>
<span class="normal">2136</span>
<span class="normal">2137</span>
<span class="normal">2138</span>
<span class="normal">2139</span>
<span class="normal">2140</span>
<span class="normal">2141</span>
<span class="normal">2142</span>
<span class="normal">2143</span>
<span class="normal">2144</span>
<span class="normal">2145</span>
<span class="normal">2146</span>
<span class="normal">2147</span>
<span class="normal">2148</span>
<span class="normal">2149</span>
<span class="normal">2150</span>
<span class="normal">2151</span>
<span class="normal">2152</span>
<span class="normal">2153</span>
<span class="normal">2154</span>
<span class="normal">2155</span>
<span class="normal">2156</span>
<span class="normal">2157</span>
<span class="normal">2158</span>
<span class="normal">2159</span>
<span class="normal">2160</span>
<span class="normal">2161</span>
<span class="normal">2162</span>
<span class="normal">2163</span>
<span class="normal">2164</span>
<span class="normal">2165</span>
<span class="normal">2166</span>
<span class="normal">2167</span>
<span class="normal">2168</span>
<span class="normal">2169</span>
<span class="normal">2170</span>
<span class="normal">2171</span>
<span class="normal">2172</span>
<span class="normal">2173</span>
<span class="normal">2174</span>
<span class="normal">2175</span>
<span class="normal">2176</span>
<span class="normal">2177</span>
<span class="normal">2178</span>
<span class="normal">2179</span>
<span class="normal">2180</span>
<span class="normal">2181</span>
<span class="normal">2182</span>
<span class="normal">2183</span>
<span class="normal">2184</span>
<span class="normal">2185</span>
<span class="normal">2186</span>
<span class="normal">2187</span>
<span class="normal">2188</span>
<span class="normal">2189</span>
<span class="normal">2190</span>
<span class="normal">2191</span>
<span class="normal">2192</span>
<span class="normal">2193</span>
<span class="normal">2194</span>
<span class="normal">2195</span>
<span class="normal">2196</span>
<span class="normal">2197</span>
<span class="normal">2198</span>
<span class="normal">2199</span>
<span class="normal">2200</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">save_result</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;result&quot;</span><span class="p">,</span>
    <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">verbosity</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save the complete optimization results to a pickle file.</span>

<span class="sd">    A result contains all information from a completed optimization run, including</span>
<span class="sd">    the experiment configuration and all evaluation results. This is useful for</span>
<span class="sd">    saving completed runs for later analysis.</span>

<span class="sd">    The result includes everything in an experiment plus:</span>
<span class="sd">    - All evaluated points (X_)</span>
<span class="sd">    - All function values (y_)</span>
<span class="sd">    - Best point and best value</span>
<span class="sd">    - Iteration count</span>
<span class="sd">    - Success rate statistics</span>
<span class="sd">    - Noise statistics (if applicable)</span>

<span class="sd">    Args:</span>
<span class="sd">        filename (str, optional): Filename for the result file. If None, generates</span>
<span class="sd">            from prefix. Defaults to None.</span>
<span class="sd">        prefix (str): Prefix for auto-generated filename. Defaults to &quot;result&quot;.</span>
<span class="sd">        path (str, optional): Directory path to save the file. If None, saves in current</span>
<span class="sd">            directory. Creates directory if it doesn&#39;t exist. Defaults to None.</span>
<span class="sd">        overwrite (bool): If True, overwrites existing file. If False, raises error if</span>
<span class="sd">            file exists. Defaults to True.</span>
<span class="sd">        verbosity (int): Verbosity level (0=silent, 1=basic, 2=detailed). Defaults to 0.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Run optimization</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...     max_iter=30,</span>
<span class="sd">        ...     n_initial=10,</span>
<span class="sd">        ...     seed=42</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Save complete results</span>
<span class="sd">        &gt;&gt;&gt; opt.save_result(prefix=&quot;sphere_opt&quot;)</span>
<span class="sd">        Result saved to sphere_opt_res.pkl</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Later: load and analyze</span>
<span class="sd">        &gt;&gt;&gt; # opt_loaded = SpotOptim.load_result(&quot;sphere_opt_res.pkl&quot;)</span>
<span class="sd">        &gt;&gt;&gt; # print(&quot;Best value:&quot;, opt_loaded.best_y_)</span>
<span class="sd">        &gt;&gt;&gt; # opt_loaded.plot_surrogate()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Use save_experiment with file_io unpickleables to preserve results</span>
    <span class="k">if</span> <span class="n">filename</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_result_filename</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">save_experiment</span><span class="p">(</span>
        <span class="n">filename</span><span class="o">=</span><span class="n">filename</span><span class="p">,</span>
        <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
        <span class="n">overwrite</span><span class="o">=</span><span class="n">overwrite</span><span class="p">,</span>
        <span class="n">unpickleables</span><span class="o">=</span><span class="s2">&quot;file_io&quot;</span><span class="p">,</span>
        <span class="n">verbosity</span><span class="o">=</span><span class="n">verbosity</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Update message</span>
    <span class="k">if</span> <span class="n">path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">full_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">full_path</span> <span class="o">=</span> <span class="n">filename</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Result saved to </span><span class="si">{</span><span class="n">full_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.to_all_dim" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">to_all_dim</span><span class="p">(</span><span class="n">X_red</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.to_all_dim" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Expand reduced-dimensional points to full-dimensional representation.</p>
<p>This method restores points from the reduced optimization space to the
full-dimensional space by inserting fixed values for constant dimensions.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>X_red</code>
            </td>
            <td>
                  <code><span title="ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Points in reduced space, shape (n_samples, n_reduced_dims).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>ndarray</code></td>            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Points in full space, shape (n_samples, n_original_dims).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create problem with one fixed dimension</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>  <span class="c1"># x1 is fixed at 2</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">3</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_red</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]])</span>  <span class="c1"># Only x0 and x2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_full</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">to_all_dim</span><span class="p">(</span><span class="n">X_red</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_full</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(2, 3)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_full</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Middle dimension should be 2.0</span>
<span class="go">array([2., 2.])</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">to_all_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_red</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Expand reduced-dimensional points to full-dimensional representation.</span>

<span class="sd">    This method restores points from the reduced optimization space to the</span>
<span class="sd">    full-dimensional space by inserting fixed values for constant dimensions.</span>

<span class="sd">    Args:</span>
<span class="sd">        X_red (ndarray): Points in reduced space, shape (n_samples, n_reduced_dims).</span>

<span class="sd">    Returns:</span>
<span class="sd">        ndarray: Points in full space, shape (n_samples, n_original_dims).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; # Create problem with one fixed dimension</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">        ...     bounds=[(-5, 5), (2, 2), (-5, 5)],  # x1 is fixed at 2</span>
<span class="sd">        ...     max_iter=1,</span>
<span class="sd">        ...     n_initial=3</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; X_red = np.array([[1.0, 3.0], [2.0, 4.0]])  # Only x0 and x2</span>
<span class="sd">        &gt;&gt;&gt; X_full = opt.to_all_dim(X_red)</span>
<span class="sd">        &gt;&gt;&gt; X_full.shape</span>
<span class="sd">        (2, 3)</span>
<span class="sd">        &gt;&gt;&gt; X_full[:, 1]  # Middle dimension should be 2.0</span>
<span class="sd">        array([2., 2.])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span><span class="p">:</span>
        <span class="c1"># No reduction occurred, return as-is</span>
        <span class="k">return</span> <span class="n">X_red</span>

    <span class="c1"># Number of samples and full dimensions</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X_red</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">n_full_dims</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">)</span>

    <span class="c1"># Initialize full-dimensional array</span>
    <span class="n">X_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_full_dims</span><span class="p">))</span>

    <span class="c1"># Track index in reduced array</span>
    <span class="n">red_idx</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Fill in values dimension by dimension</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_full_dims</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="c1"># Fixed dimension: use stored value</span>
            <span class="n">X_full</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_lower</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Varying dimension: use value from reduced array</span>
            <span class="n">X_full</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_red</span><span class="p">[:,</span> <span class="n">red_idx</span><span class="p">]</span>
            <span class="n">red_idx</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">X_full</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.to_red_dim" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">to_red_dim</span><span class="p">(</span><span class="n">X_full</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.to_red_dim" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Reduce full-dimensional points to optimization space.</p>
<p>This method removes fixed dimensions from full-dimensional points,
extracting only the varying dimensions used in optimization.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>X_full</code>
            </td>
            <td>
                  <code><span title="ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Points in full space, shape (n_samples, n_original_dims).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>ndarray</code></td>            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Points in reduced space, shape (n_samples, n_reduced_dims).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create problem with one fixed dimension</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>  <span class="c1"># x1 is fixed at 2</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">3</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_red</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">to_red_dim</span><span class="p">(</span><span class="n">X_full</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_red</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(2, 2)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">X_red</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">]]))</span>
<span class="go">True</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">to_red_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_full</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Reduce full-dimensional points to optimization space.</span>

<span class="sd">    This method removes fixed dimensions from full-dimensional points,</span>
<span class="sd">    extracting only the varying dimensions used in optimization.</span>

<span class="sd">    Args:</span>
<span class="sd">        X_full (ndarray): Points in full space, shape (n_samples, n_original_dims).</span>

<span class="sd">    Returns:</span>
<span class="sd">        ndarray: Points in reduced space, shape (n_samples, n_reduced_dims).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; # Create problem with one fixed dimension</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">        ...     bounds=[(-5, 5), (2, 2), (-5, 5)],  # x1 is fixed at 2</span>
<span class="sd">        ...     max_iter=1,</span>
<span class="sd">        ...     n_initial=3</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; X_full = np.array([[1.0, 2.0, 3.0], [4.0, 2.0, 5.0]])</span>
<span class="sd">        &gt;&gt;&gt; X_red = opt.to_red_dim(X_full)</span>
<span class="sd">        &gt;&gt;&gt; X_red.shape</span>
<span class="sd">        (2, 2)</span>
<span class="sd">        &gt;&gt;&gt; np.array_equal(X_red, np.array([[1.0, 3.0], [4.0, 5.0]]))</span>
<span class="sd">        True</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span><span class="p">:</span>
        <span class="c1"># No reduction occurred, return as-is</span>
        <span class="k">return</span> <span class="n">X_full</span>

    <span class="c1"># Select only non-fixed dimensions</span>
    <span class="k">return</span> <span class="n">X_full</span><span class="p">[:,</span> <span class="o">~</span><span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.update_stats" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">update_stats</span><span class="p">()</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.update_stats" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Update optimization statistics.</p>
<p>Updates:
1. <code>min_y</code>: Minimum y value found so far
2. <code>min_X</code>: X value corresponding to minimum y
3. <code>counter</code>: Total number of function evaluations</p>
<p>Note: <code>success_rate</code> is updated separately via <code>_update_success_rate()</code> method,
which is called after each batch of function evaluations.</p>
<p>If <code>noise</code> is True (repeats &gt; 1), additionally computes:
1. <code>mean_X</code>: Unique design points (aggregated from repeated evaluations)
2. <code>mean_y</code>: Mean y values per design point
3. <code>var_y</code>: Variance of y values per design point
4. <code>min_mean_X</code>: X value of the best mean y value
5. <code>min_mean_y</code>: Best mean y value
6. <code>min_var_y</code>: Variance of the best mean y value</p>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Without noise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>                <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>                <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_initial</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">25.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">update_stats</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">min_y</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">min_X</span>
<span class="go">array([0, 1])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">counter</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># With noise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt_noise</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>                      <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>                      <span class="n">repeats_initial</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt_noise</span><span class="o">.</span><span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt_noise</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">25.0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt_noise</span><span class="o">.</span><span class="n">update_stats</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt_noise</span><span class="o">.</span><span class="n">min_y</span>
<span class="go">4.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt_noise</span><span class="o">.</span><span class="n">mean_y</span>
<span class="go">array([ 5., 25.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt_noise</span><span class="o">.</span><span class="n">var_y</span>
<span class="go">array([1., 0.])</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">update_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Update optimization statistics.</span>

<span class="sd">    Updates:</span>
<span class="sd">    1. `min_y`: Minimum y value found so far</span>
<span class="sd">    2. `min_X`: X value corresponding to minimum y</span>
<span class="sd">    3. `counter`: Total number of function evaluations</span>

<span class="sd">    Note: `success_rate` is updated separately via `_update_success_rate()` method,</span>
<span class="sd">    which is called after each batch of function evaluations.</span>

<span class="sd">    If `noise` is True (repeats &gt; 1), additionally computes:</span>
<span class="sd">    1. `mean_X`: Unique design points (aggregated from repeated evaluations)</span>
<span class="sd">    2. `mean_y`: Mean y values per design point</span>
<span class="sd">    3. `var_y`: Variance of y values per design point</span>
<span class="sd">    4. `min_mean_X`: X value of the best mean y value</span>
<span class="sd">    5. `min_mean_y`: Best mean y value</span>
<span class="sd">    6. `min_var_y`: Variance of the best mean y value</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; # Without noise</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">        ...                 bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...                 max_iter=10, n_initial=5)</span>
<span class="sd">        &gt;&gt;&gt; opt.X_ = np.array([[1, 2], [3, 4], [0, 1]])</span>
<span class="sd">        &gt;&gt;&gt; opt.y_ = np.array([5.0, 25.0, 1.0])</span>
<span class="sd">        &gt;&gt;&gt; opt.update_stats()</span>
<span class="sd">        &gt;&gt;&gt; opt.min_y</span>
<span class="sd">        1.0</span>
<span class="sd">        &gt;&gt;&gt; opt.min_X</span>
<span class="sd">        array([0, 1])</span>
<span class="sd">        &gt;&gt;&gt; opt.counter</span>
<span class="sd">        3</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # With noise</span>
<span class="sd">        &gt;&gt;&gt; opt_noise = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">        ...                       bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...                       repeats_initial=2)</span>
<span class="sd">        &gt;&gt;&gt; opt_noise.X_ = np.array([[1, 2], [1, 2], [3, 4]])</span>
<span class="sd">        &gt;&gt;&gt; opt_noise.y_ = np.array([4.0, 6.0, 25.0])</span>
<span class="sd">        &gt;&gt;&gt; opt_noise.update_stats()</span>
<span class="sd">        &gt;&gt;&gt; opt_noise.min_y</span>
<span class="sd">        4.0</span>
<span class="sd">        &gt;&gt;&gt; opt_noise.mean_y</span>
<span class="sd">        array([ 5., 25.])</span>
<span class="sd">        &gt;&gt;&gt; opt_noise.var_y</span>
<span class="sd">        array([1., 0.])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span>

    <span class="c1"># Basic stats</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">min_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">min_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>

    <span class="c1"># Aggregated stats for noisy functions</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_mean_var</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span>
        <span class="p">)</span>
        <span class="c1"># X value of the best mean y value so far</span>
        <span class="n">best_mean_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean_y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_X</span><span class="p">[</span><span class="n">best_mean_idx</span><span class="p">]</span>
        <span class="c1"># Best mean y value so far</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_y</span><span class="p">[</span><span class="n">best_mean_idx</span><span class="p">]</span>
        <span class="c1"># Variance of the best mean y value so far</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_var_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_y</span><span class="p">[</span><span class="n">best_mean_idx</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2004 - 2025
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://twitter.com/bartzbeielstein" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M459.4 151.7c.3 4.5.3 9.1.3 13.6 0 138.7-105.6 298.6-298.6 298.6-59.5 0-114.7-17.2-161.1-47.1 8.4 1 16.6 1.3 25.3 1.3 49.1 0 94.2-16.6 130.3-44.8-46.1-1-84.8-31.2-98.1-72.8 6.5 1 13 1.6 19.8 1.6 9.4 0 18.8-1.3 27.6-3.6-48.1-9.7-84.1-52-84.1-103v-1.3c14 7.8 30.2 12.7 47.4 13.3-28.3-18.8-46.8-51-46.8-87.4 0-19.5 5.2-37.4 14.3-53C87.4 130.8 165 172.4 252.1 176.9c-1.6-7.8-2.6-15.9-2.6-24C249.5 95.1 296.3 48 354.4 48c30.2 0 57.5 12.7 76.7 33.1 23.7-4.5 46.5-13.3 66.6-25.3-7.8 24.4-24.4 44.8-46.1 57.8 21.1-2.3 41.6-8.1 60.4-16.2-14.3 20.8-32.2 39.3-52.6 54.3"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/in/thomas-bartz-beielstein-3157b541/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["content.code.copy", "navigation.instant", "navigation.indexes", "navigation.path", "navigation.prune", "navigation.expand"], "search": "../../../assets/javascripts/workers/search.7a47a382.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.e71a0d61.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>